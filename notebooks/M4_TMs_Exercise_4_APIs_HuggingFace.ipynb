{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+MLntlirfmXUeV49Ny9w2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M4_TMs_Exercise_4_APIs_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/openai-python.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuipJVfHZDyS",
        "outputId": "64f4967b-0cd7-486e-da06-124605f59da2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNnG1xbRYl_5",
        "outputId": "1785249d-d48d-43bd-a2c5-aec3fd8c3658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'NEGATIVE', 'score': 0.9810278415679932}, {'label': 'POSITIVE', 'score': 0.018972132354974747}]]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Define the API endpoint and parameters\n",
        "endpoint = 'https://api-inference.huggingface.co/models/distilbert-base-uncased-finetuned-sst-2-english'\n",
        "headers = {'Authorization': 'Bearer Your Token'}\n",
        "payload = {'inputs': 'This is a test sentence.'}\n",
        "\n",
        "# Send the request to the API endpoint\n",
        "response = requests.post(endpoint, headers=headers, json=payload)\n",
        "\n",
        "# Print the prediction result\n",
        "result = response.json()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your Token\"\n"
      ],
      "metadata": {
        "id": "wDQyIq7Yn4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI API client\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Define the prompt to generate text from\n",
        "# prompt = \"The quick brown fox jumps over the lazy dog.\"\n",
        "prompt = \"The quick brown fox jumps\"\n",
        "\n",
        "# Generate text using the GPT-2 model from Hugging Face\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=50,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        ")\n",
        "\n",
        "# Print the generated text\n",
        "print(response.choices[0].text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BVuPX5po2dY",
        "outputId": "22b40942-d92c-4790-ca9d-59a1455a902c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " over the lazy dog.\n",
            "\n",
            "The quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    }
  ]
}