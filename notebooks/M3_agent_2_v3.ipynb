{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_agent_2_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjwPPkCJ4C2R"
      },
      "source": [
        "# Exploring Additional Agents in LangChain\n",
        "\n",
        "LangChain offers a variety of agents designed to handle different types of tasks and interactions. In this notebook, we'll explore several additional agents to showcase the versatility and power of LangChain."
      ],
      "id": "FjwPPkCJ4C2R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrNGV8t74C2S"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the necessary packages and import the required modules."
      ],
      "id": "FrNGV8t74C2S"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UnJPcOo4C2S",
        "outputId": "e9008cbf-01bb-44db-d843-e06cbb124999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install langchain openai pandas faiss-cpu duckduckgo-search --q\n",
        "!pip install -qU langchain openai sqlalchemy wikipedia langchain_community --q\n",
        "# Note: Restart the kernel after installation."
      ],
      "id": "-UnJPcOo4C2S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNKNvIxa4C2T"
      },
      "source": [
        "### Import Modules"
      ],
      "id": "BNKNvIxa4C2T"
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-7Yml0F4gug",
        "outputId": "df182557-3090-4709-8306-daa04a544db9"
      },
      "id": "H-7Yml0F4gug",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_experimental --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZdhEtnT5bVb",
        "outputId": "6cb6e369-c34f-4549-cefc-d9de5f299b7f"
      },
      "id": "5ZdhEtnT5bVb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/209.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BkFkamx04C2T"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent # Import from the correct location\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.agents.agent_toolkits import VectorStoreToolkit\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Define the LLM (Language Model) using OpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")"
      ],
      "id": "BkFkamx04C2T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwRCewXv4C2T"
      },
      "source": [
        "### Helper Functions and Data\n",
        "\n",
        "We'll define a helper function `count_tokens` and some sample data required for the agents."
      ],
      "id": "FwRCewXv4C2T"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4-us6oYq4C2T"
      },
      "outputs": [],
      "source": [
        "def count_tokens(agent, prompt):\n",
        "    response = agent.run(prompt)\n",
        "    # Simplified token count (approximate)\n",
        "    tokens = len(prompt.split()) + len(response.split())\n",
        "    print(response)\n",
        "    print(f\"Spent a total of {tokens} tokens\")\n",
        "    return response\n",
        "\n",
        "# Sample movie data for Pandas DataFrame Agent\n",
        "movies_data = [\n",
        "    {'title': 'Inception', 'director': 'Christopher Nolan', 'rating': 8.8},\n",
        "    {'title': 'Interstellar', 'director': 'Christopher Nolan', 'rating': 8.6},\n",
        "    {'title': 'The Dark Knight', 'director': 'Christopher Nolan', 'rating': 9.0},\n",
        "    {'title': 'Pulp Fiction', 'director': 'Quentin Tarantino', 'rating': 8.9},\n",
        "    {'title': 'Django Unchained', 'director': 'Quentin Tarantino', 'rating': 8.4}\n",
        "]"
      ],
      "id": "4-us6oYq4C2T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0WEuBtY4C2U"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Structured Chat Agent\n",
        "\n",
        "**Description:**\n",
        "The Structured Chat Agent leverages OpenAI's structured output capabilities to interact with tools in a more controlled and predictable manner. It uses the `StructuredChatAgent` to define the structure of the conversation, ensuring that the agent's responses adhere to a specific format.\n",
        "\n",
        "**Use Cases:**\n",
        "- When you need the agent to produce outputs in a specific structure or format.\n",
        "- Useful in applications where the consistency of the response format is critical, such as generating JSON responses or filling out forms."
      ],
      "id": "y0WEuBtY4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JkJKkQJ4C2U"
      },
      "source": [
        "**Example:**"
      ],
      "id": "7JkJKkQJ4C2U"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4Z3Wp-4C2U",
        "outputId": "77cf2c00-aada-437d-b032-23de9e9c4f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"Bitcoin price\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLive price of Bitcoin is $98,099.82 with a market cap of $1,941.05B USD. Discover current price, trading volume, chart history, and more. Bitcoin (BTC) price, live charts, news and more. Bitcoin to USD price is updated in real time. Learn about Bitcoin, receive market updates and more. The live price of Bitcoin is $ 98,641.38 per (BTC / USD) with a current market cap of $ 1,951.73B USD. 24-hour trading volume is $ 73.56B USD. BTC to USD price is updated in real-time. Bitcoin is -0.38% in the last 24 hours with a circulating supply of 19.79M. The Kitco Bitcoin price index provides the latest Bitcoin price in US Dollars using an average from the world's leading exchanges. Bitcoin is climbing this week. The current price of Bitcoin is $98,217.41 per BTC. With a circulating supply of 19,786,887 BTC, it means that Bitcoin has a total market cap of $1,939,511,204,287.17. The amount of Bitcoin traded has risen by $5,204,614,823.01 in the last 24 hours, which is a 10.51% increase. Additionally, in the last day ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I have found the current price of Bitcoin and its recent performance. I can provide a brief summary of its recent performance.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The current price of Bitcoin is $98,099.82 with a market cap of $1,941.05B USD. In the last 24 hours, Bitcoin has seen a 10.51% increase in trading volume and is currently at -0.38% in the market. Its circulating supply is 19.79M and its total market cap is $1,939,511,204,287.17.\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The current price of Bitcoin is $98,099.82 with a market cap of $1,941.05B USD. In the last 24 hours, Bitcoin has seen a 10.51% increase in trading volume and is currently at -0.38% in the market. Its circulating supply is 19.79M and its total market cap is $1,939,511,204,287.17.\n",
            "Spent a total of 66 tokens\n"
          ]
        }
      ],
      "source": [
        "# Structured Chat Agent Example\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "# Define a custom prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    template=\"\"\"\n",
        "    You are a structured chat agent. Please respond to the user's query in the following JSON format:\n",
        "    {{\n",
        "        \"Price\": \"The price here\",\n",
        "        \"summary\": \"summary of the recent performance\" # Provide a brief summary\n",
        "    }}\n",
        "\n",
        "    Here are some examples:\n",
        "\n",
        "    User Query: What is the price of gold and what is the recent performance?\n",
        "    Response:\n",
        "    {{\n",
        "        \"Price\": \"$1,900\",\n",
        "        \"summary\": \"Gold prices have been relatively stable recently.\"\n",
        "    }}\n",
        "\n",
        "    User Query: I want to know about Tesla stock, how is it doing?\n",
        "    Response:\n",
        "    {{\n",
        "        \"Price\": \"$250\",\n",
        "        \"summary\": \"Tesla stock has experienced significant growth this year.\"\n",
        "    }}\n",
        "\n",
        "    User Query: {input}\n",
        "    Response:\n",
        "    JSON:\n",
        "        {{\n",
        "        \"Price\": \"The price here\",\n",
        "        \"summary\": \"summary of the recent performance\" # Provide a brief summary\n",
        "    }}\n",
        "    \"\"\" # Added \"JSON:\" to explicitly instruct the LLM to return JSON output\n",
        ")\n",
        "\n",
        "# Define the tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=search.run,\n",
        "        description=\"Useful for answering questions about current events or the current state of the world.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "# Initialize the agent\n",
        "structured_chat_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    max_iterations=2,\n",
        "    agent_kwargs={'prompt': prompt.template}\n",
        ")\n",
        "\n",
        "# Test the agent\n",
        "result = count_tokens(\n",
        "    structured_chat_agent,\n",
        "    \"What is the current price of Bitcoin, and can you provide a brief summary of its recent performance?\"\n",
        ")"
      ],
      "id": "xk4Z3Wp-4C2U"
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1-oqWfqbQpjm",
        "outputId": "8bd6efbd-b17f-4470-f9a2-5e969d4288c5"
      },
      "id": "1-oqWfqbQpjm",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current price of Bitcoin is $98,099.82 with a market cap of $1,941.05B USD. In the last 24 hours, Bitcoin has seen a 10.51% increase in trading volume and is currently at -0.38% in the market. Its circulating supply is 19.79M and its total market cap is $1,939,511,204,287.17.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZe0Hbmf4C2U"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```\n",
        "> Entering new AgentExecutor chain...\n",
        "...\n",
        "\n",
        "Final Answer: {\n",
        "  \"price\": \"$34,000\",\n",
        "  \"summary\": \"Bitcoin has seen a steady increase in value over the past month due to market optimism.\"\n",
        "}\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 350 tokens\n",
        "```"
      ],
      "id": "kZe0Hbmf4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUe7a4Dx4C2U"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. OpenAI Functions Agent\n",
        "\n",
        "**Description:**\n",
        "With the introduction of OpenAI's function calling capabilities, the OpenAI Functions Agent can perform actions by calling functions defined in code. This allows for more robust integrations with external systems and can handle complex tasks that require precise operations.\n",
        "\n",
        "**Use Cases:**\n",
        "- When you need the agent to interact with APIs or execute specific functions based on user queries.\n",
        "- Useful for applications like booking appointments, performing calculations, or manipulating data."
      ],
      "id": "BUe7a4Dx4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVv1y2894C2U"
      },
      "source": [
        "**Example:**"
      ],
      "id": "RVv1y2894C2U"
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Functions Agent Example for CalendarManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "# Define custom functions\n",
        "def schedule_event(event_details: str) -> str:\n",
        "    \"\"\"\n",
        "    Schedules a new calendar event based on the provided details.\n",
        "\n",
        "    Args:\n",
        "        event_details (str): A description of the event to be scheduled.\n",
        "\n",
        "    Returns:\n",
        "        str: Confirmation message for the scheduled event.\n",
        "    \"\"\"\n",
        "    # In a real application, you would integrate with a calendar API here.\n",
        "    # For simplicity, we'll just return a confirmation message.\n",
        "    return f\"Event scheduled: {event_details}\"\n",
        "\n",
        "def list_events(unused_input: str = \"\") -> str: # Modified function signature\n",
        "    \"\"\"\n",
        "    Lists all scheduled calendar events.\n",
        "\n",
        "    Args:\n",
        "        unused_input (str, optional): Unused input string. Defaults to \"\".\n",
        "\n",
        "    Returns:\n",
        "        str: A list of scheduled events.\n",
        "    \"\"\"\n",
        "    # In a real application, you would retrieve events from a calendar API.\n",
        "    # For simplicity, we'll return a static list.\n",
        "    return \"You have the following events scheduled:\\n1. Team Meeting at 10 AM\\n2. Doctor Appointment at 3 PM\"\n",
        "\n",
        "# Define Tools for the agent\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"ScheduleEvent\",\n",
        "        func=schedule_event,\n",
        "        description=\"Schedules a new calendar event based on the provided details.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ListEvents\",\n",
        "        func=list_events,\n",
        "        description=\"Lists all your scheduled calendar events.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Initialize the agent with the defined tools\n",
        "calendar_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")\n",
        "\n",
        "# Test the agent by running a query\n",
        "def main():\n",
        "    # Example queries\n",
        "    queries = [\n",
        "        \"Schedule a meeting with John tomorrow at 2 PM.\",\n",
        "        \"What are my events for today?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(f\"\\nUser Query: {query}\")\n",
        "        result = calendar_agent.run(query)\n",
        "        print(\"Agent Response:\", result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWOjA94W6ETa",
        "outputId": "d47bff18-dc22-4669-c729-f53097a0778b"
      },
      "id": "lWOjA94W6ETa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Query: Schedule a meeting with John tomorrow at 2 PM.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ScheduleEvent` with `Meeting with John at 2 PM tomorrow`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mEvent scheduled: Meeting with John at 2 PM tomorrow\u001b[0m\u001b[32;1m\u001b[1;3mI have successfully scheduled a meeting with John tomorrow at 2 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent Response: I have successfully scheduled a meeting with John tomorrow at 2 PM.\n",
            "\n",
            "User Query: What are my events for today?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ListEvents` with `today`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mYou have the following events scheduled:\n",
            "1. Team Meeting at 10 AM\n",
            "2. Doctor Appointment at 3 PM\u001b[0m\u001b[32;1m\u001b[1;3mYou have the following events scheduled for today:\n",
            "1. Team Meeting at 10 AM\n",
            "2. Doctor Appointment at 3 PM\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent Response: You have the following events scheduled for today:\n",
            "1. Team Meeting at 10 AM\n",
            "2. Doctor Appointment at 3 PM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZowTDpa4C2U"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Pandas DataFrame Agent\n",
        "\n",
        "**Description:**\n",
        "The Pandas DataFrame Agent is designed to interact with Pandas DataFrames, allowing the LLM to perform data analysis tasks directly on tabular data. It can answer questions about the data, perform aggregations, and generate plots.\n",
        "\n",
        "**Use Cases:**\n",
        "- When working with datasets and you want to query or analyze the data using natural language.\n",
        "- Useful in data analysis, reporting, and exploratory data analysis tasks."
      ],
      "id": "KZowTDpa4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXYOZ3PI4C2U"
      },
      "source": [
        "**Example:**\n",
        "\n",
        "Suppose we have a DataFrame containing movie data."
      ],
      "id": "OXYOZ3PI4C2U"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjoxHrW69Pta",
        "outputId": "9688ac45-c3f8-4eda-c512-97ceb3361627"
      },
      "id": "TjoxHrW69Pta",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas DataFrame Agent Example\n",
        "import pandas as pd\n",
        "\n",
        "# Sample movie data\n",
        "df = pd.DataFrame(movies_data)"
      ],
      "metadata": {
        "id": "rjovCjBf-UX4"
      },
      "id": "rjovCjBf-UX4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "import pandas as pd\n",
        "\n",
        "agent_executor = create_pandas_dataframe_agent(\n",
        "    llm,\n",
        "    df,\n",
        "    allow_dangerous_code=True,\n",
        "    verbose=True,\n",
        "    max_iterations=2\n",
        ")"
      ],
      "metadata": {
        "id": "8HZ5oU_n9Ge6"
      },
      "id": "8HZ5oU_n9Ge6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Sw6UgW4C2U",
        "outputId": "07d282f2-91d3-45fa-bcbd-6eb9345de845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To find the average rating of movies directed by Christopher Nolan, we need to filter the dataframe for movies directed by him and then calculate the average of their ratings.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['director'] == 'Christopher Nolan']['rating'].mean()\u001b[0m\u001b[36;1m\u001b[1;3m8.799999999999999\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The average rating of movies directed by Christopher Nolan is 8.8\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The average rating of movies directed by Christopher Nolan is 8.8\n",
            "Spent a total of 22 tokens\n"
          ]
        }
      ],
      "source": [
        "# Test the agent\n",
        "result = count_tokens(\n",
        "    agent_executor,\n",
        "    \"What is the average rating of movies directed by Christopher Nolan?\"\n",
        ")"
      ],
      "id": "Z3Sw6UgW4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz3cT0tW4C2U"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```\n",
        "> Entering new AgentExecutor chain...\n",
        "...\n",
        "\n",
        "Final Answer: The average rating of movies directed by Christopher Nolan is 8.8.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 220 tokens\n",
        "```"
      ],
      "id": "sz3cT0tW4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8xGfrgo4C2U"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Vector Store Agent\n",
        "\n",
        "**Description:**\n",
        "The Vector Store Agent interacts with vector databases to perform semantic searches based on embeddings. This is particularly useful when dealing with unstructured text data.\n",
        "\n",
        "**Use Cases:**\n",
        "- When you need to find documents or pieces of information that are semantically similar to a query.\n",
        "- Useful in applications like document retrieval, question answering over a knowledge base, and content recommendation."
      ],
      "id": "y8xGfrgo4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXJU25-f4C2U"
      },
      "source": [
        "**Example:**"
      ],
      "id": "CXJU25-f4C2U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVQD7TMt4C2U",
        "outputId": "7642178c-4705-436b-c559-680563c299e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use movies_collection since I only need the movie title.\n",
            "Action: movies_collection\n",
            "Action Input: \"What is a movie about dreams?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Inception\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Inception\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: Inception\n",
            "Token Count: 1\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "# !pip install langchain openai chromadb sentence_transformers --quiet\n",
        "\n",
        "# Import necessary modules\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents.agent_toolkits import VectorStoreToolkit, VectorStoreInfo\n",
        "from langchain.llms import OpenAI\n",
        "import os\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"The Shawshank Redemption is a movie about hope and friendship.\",\n",
        "    \"The Godfather focuses on the Italian-American mafia.\",\n",
        "    \"Inception explores complex concepts of dreams within dreams.\"\n",
        "]\n",
        "\n",
        "# Initialize embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "# Create Chroma vector store from texts\n",
        "vectorstore = Chroma.from_texts(\n",
        "    texts=documents,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"movies_collection\"\n",
        ")\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Create VectorStoreInfo\n",
        "vectorstore_info = VectorStoreInfo(\n",
        "    name=\"movies_collection\",\n",
        "    description=\"A collection of movie descriptions\",\n",
        "    vectorstore=vectorstore\n",
        ")\n",
        "\n",
        "# Initialize the VectorStoreToolkit with the llm\n",
        "toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info, llm=llm)\n",
        "\n",
        "# Initialize the agent\n",
        "vectorstore_agent = initialize_agent(\n",
        "    tools=toolkit.get_tools(),\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    max_iterations=2\n",
        ")\n",
        "\n",
        "# Define the count_tokens function\n",
        "def count_tokens(agent, query):\n",
        "    response = agent.run(query)\n",
        "    token_count = len(response.split())\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Token Count: {token_count}\")\n",
        "    return response\n",
        "\n",
        "# Test the agent\n",
        "result = count_tokens(\n",
        "    vectorstore_agent,\n",
        "    \"Find a movie about dreams.\"\n",
        ")\n"
      ],
      "id": "RVQD7TMt4C2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyTWULt_4C2V"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```\n",
        "> Entering new AgentExecutor chain...\n",
        "...\n",
        "\n",
        "Final Answer: \"Inception\" is a movie that explores complex concepts of dreams within dreams.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 280 tokens\n",
        "```"
      ],
      "id": "lyTWULt_4C2V"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}