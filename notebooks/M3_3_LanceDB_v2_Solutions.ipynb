{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_3_LanceDB_v2_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTzN-m4_hUo0"
      },
      "source": [
        "![](https://lancedb.github.io/lancedb/assets/ecosystem-illustration.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx241F9hhr5V"
      },
      "source": [
        "LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrieval, filtering and management of embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGzZTq1bhSfM",
        "outputId": "67ecc29a-a6a5-4f48-de6c-ed745dde78c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install lancedb --q\n",
        "!pip install pypdf --q\n",
        "# !pip install -qqq chromadb==0.4.10 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.299 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3QPenRzrhX99"
      },
      "outputs": [],
      "source": [
        "import lancedb\n",
        "\n",
        "uri = \"/content/data/sample-lancedb\"\n",
        "db = lancedb.connect(uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QFr9jZuUhgCD"
      },
      "outputs": [],
      "source": [
        "table = db.create_table(\"my_table\",\n",
        "                        data=[{\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n",
        "                              {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MFjYLUYjhh9H"
      },
      "outputs": [],
      "source": [
        "result = table.search([100, 100]).limit(2).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SJeCOKwdhik1",
        "outputId": "5d5b15fc-db71-415f-9482-2f8359a1c6e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'vector': [5.900000095367432, 26.5],\n",
              "  'item': 'bar',\n",
              "  'price': 20.0,\n",
              "  '_distance': 14257.0595703125},\n",
              " {'vector': [3.0999999046325684, 4.099999904632568],\n",
              "  'item': 'foo',\n",
              "  'price': 10.0,\n",
              "  '_distance': 18586.421875}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwMy0VxPGog7"
      },
      "source": [
        "# Implementing a Vector Database for Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JGbb32o1xArw",
        "outputId": "ce033f76-8203-4925-f165-9c596ecdd9c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "loader = PyPDFLoader(\"/content/attention.pdf\")\n",
        "\n",
        "docs = loader.load()\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF1OOWyZyiy4"
      },
      "source": [
        "The Markdown file we're loading is the original Attention paper: \"Attention is all you need!\". Let's see how we can use the RecursiveCharacterTextSplitter to split the document into smaller chunks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oc_ER7Nyx7FG",
        "outputId": "1f71243f-a532-4c11-87b3-83f23cdfa7a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEP3dr5Jyk6K"
      },
      "source": [
        "Splitting the document into chunks is required due to the limited number of tokens a LLM can look at once (4096 for Llama 2). Next, we'll use the HuggingFaceEmbeddings class to create embeddings for the chunks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DFL6v_CVDFUa"
      },
      "outputs": [],
      "source": [
        "import lancedb\n",
        "from langchain.vectorstores import LanceDB\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "\n",
        "uri = \"/content/data/paper-lancedb-\"\n",
        "db = lancedb.connect(uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y90jw_mLB9R6"
      },
      "outputs": [],
      "source": [
        "# We will use HuggingFace embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WDEsH5wFDAF"
      },
      "outputs": [],
      "source": [
        "table = db.create_table(\n",
        "    \"paper_table\",\n",
        "    data=[\n",
        "        {\n",
        "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
        "            \"text\": \"Hello World\",\n",
        "            \"id\": \"1\",\n",
        "        }\n",
        "    ],\n",
        "    mode=\"overwrite\",\n",
        ")\n",
        "\n",
        "docsearch = LanceDB.from_documents(texts[5:20], embeddings, connection=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ydqZeToFjsb"
      },
      "outputs": [],
      "source": [
        "retriever = docsearch.as_retriever(search_kwargs={'k': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvcMnV02EuLZ"
      },
      "outputs": [],
      "source": [
        "retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3bjGnjjFQUl"
      },
      "outputs": [],
      "source": [
        "texts[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0aEnSm1FNlV"
      },
      "outputs": [],
      "source": [
        "result = table.search(embeddings.embed_query(texts[0].page_content)).limit(2).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnRSARRhFlyh"
      },
      "outputs": [],
      "source": [
        "result[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j9bhHa8HUHd"
      },
      "source": [
        "## Exercise 1: Create a LanceDB for Two Papers and Load Each into a Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEhBoYw8IjsS"
      },
      "outputs": [],
      "source": [
        "table = db.create_table(\n",
        "    \"paper_table_1\",\n",
        "    data=[\n",
        "        {\n",
        "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
        "            \"text\": \"Hello World\",\n",
        "            \"id\": \"1\",\n",
        "        }\n",
        "    ],\n",
        "    mode=\"overwrite\",\n",
        ")\n",
        "\n",
        "docsearch = LanceDB.from_documents(texts[5:10], embeddings, connection=table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd5ipYd7IvdL"
      },
      "outputs": [],
      "source": [
        "table = db.create_table(\n",
        "    \"paper_table_2\",\n",
        "    data=[\n",
        "        {\n",
        "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
        "            \"text\": \"Hello World\",\n",
        "            \"id\": \"1\",\n",
        "        }\n",
        "    ],\n",
        "    mode=\"overwrite\",\n",
        ")\n",
        "\n",
        "docsearch = LanceDB.from_documents(texts[10:15], embeddings, connection=table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Ro7fPmHLGY"
      },
      "source": [
        "# ChromaDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZo8JjuJGkkT"
      },
      "source": [
        "![](https://images.datacamp.com/image/upload/v1693482377/image4_7b6910cd7c.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0BeHxeGypah"
      },
      "source": [
        "In the spirit of using free tools, we're also using free embeddings hosted by HuggingFace. We'll use Chroma database to store/cache the embeddings and make it easy to search them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOPi0DWfzBaJ"
      },
      "source": [
        "To combine the LLM with the database, we'll use the RetrievalQA chain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGOZDRrwF5fl"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq chromadb==0.4.10 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Zjb7JiymgP"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")\n",
        "results = db.similarity_search(\"Transformer models\", k=2)\n",
        "print(results[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Hzk8WlF28c"
      },
      "outputs": [],
      "source": [
        "results[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0BUI-hhKM1N"
      },
      "source": [
        "## Exercise 2: Create a ChromaDB for Two Papers and Load Each into a collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snnfZ3cFGa4t"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(texts[5:10], embeddings, persist_directory=\"db_1\", collection_name='paper_1')\n",
        "results = db.similarity_search(\"Transformer models\", k=2)\n",
        "print(results[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emkU6iAVJ2EK"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(texts[5:10], embeddings, persist_directory=\"db_1\", collection_name='paper_2')\n",
        "results = db.similarity_search(\"Transformer models\", k=2)\n",
        "print(results[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ZB-o3AJ64J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}