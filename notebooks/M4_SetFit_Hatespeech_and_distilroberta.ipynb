{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw4OUl/iOH5SQW9+pAZn5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M4_SetFit_Hatespeech_and_distilroberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SetFit (25 examples) vs BERT (1000 examples)\n",
        "\n",
        "In this tutorial, we perform hate speech classification using SetFit and BERT. We read tweets from a CSV file and balance the number of samples in each class. Then, we split the data into a training set and a testing set.\n",
        "\n",
        "We use a pre-trained SetFit model to train on the training set and evaluate its performance on the testing set. Code for pushing the model to ðŸ¤— hub is provided but commented out. Next, we fine-tune a pre-trained BERT model on the training set and evaluate its performance on the testing set. We  save the fine-tuned model.\n",
        "\n",
        "We evaluate using a classification report that includes precision, recall, F1 score, and support for each class."
      ],
      "metadata": {
        "id": "DbORaC1h2Ms7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install setfit -q"
      ],
      "metadata": {
        "id": "TWpjPn6057vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, pipeline, AutoModelForSequenceClassification\n",
        "from sentence_transformers.losses import CosineSimilarityLoss\n",
        "from datasets import Dataset, load_dataset\n",
        "from setfit import SetFitModel, SetFitTrainer, sample_dataset"
      ],
      "metadata": {
        "id": "Lj_6lmfH5-Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data\n",
        "\n",
        "The code reads in the hate speech dataset from a given URL using the `pandas` library, and creates a pandas dataframe with the 'text' and 'label' columns.\n"
      ],
      "metadata": {
        "id": "N6dPXTFD_ChP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PREPPING THE DATA ##\n",
        "\n",
        "# Read in the data from a CSV file\n",
        "data = pd.read_csv('https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/twitter_hate.zip')\n",
        "\n",
        "# Rename and reorder the columns\n",
        "data_df = pd.DataFrame({'label':data['class'], 'text':data['tweet']})\n",
        "\n"
      ],
      "metadata": {
        "id": "uoGO__hc595B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing Sample Imbalance\n",
        "\n",
        "The `RandomUnderSampler` from the `imblearn` library is used to fix any sample imbalance in the dataset by undersampling the overrepresented class.\n",
        "\n",
        "## Splitting Data\n",
        "\n",
        "The `train_test_split` method from the `datasets` library is used to split the dataset into a training set and a testing set.\n"
      ],
      "metadata": {
        "id": "tQ_lZk7h_LP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix sample imbalance using RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "data_df_res, y_res = rus.fit_resample(data_df, data_df['label'])\n",
        "\n",
        "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(data_df_res)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "dataset = dataset.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "sBtvKCtH_GH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the few-shot regime by sampling 25 examples per class in the training set\n",
        "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=25)\n",
        "eval_dataset = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "XsMBuBog6RlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SetFit Model\n",
        "\n",
        "The `train_setfit` function takes in a training dataset and an evaluation dataset, trains a SetFit model on the training dataset, evaluates the model on the evaluation dataset, and returns the trained model and evaluation metrics.\n",
        "\n",
        "This here is a version of SetFit with a sklearn-classification-head. It is also possible to add a neural layer for to the SBERT model. Check out the original example for that here: https://github.com/huggingface/setfit \n"
      ],
      "metadata": {
        "id": "X7dsGOX0_WIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained SBERT model from Hugging Face model hub\n",
        "model_setfit = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
        "\n",
        "# Create SetFitTrainer and train the SetFit model\n",
        "trainer_setfit = SetFitTrainer(\n",
        "    model=model_setfit,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    loss_class=CosineSimilarityLoss,\n",
        "    metric=\"accuracy\",\n",
        "    batch_size=16,\n",
        "    num_iterations=20, # The number of text pairs to generate for contrastive learning\n",
        "    num_epochs=1, # The number of epochs to use for contrastive learning\n",
        "    column_mapping={\"text\": \"text\", \"label\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
        ")\n",
        "trainer_setfit.train()"
      ],
      "metadata": {
        "id": "5U3_-sTeX9BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the trained SetFit model on the testing dataset\n",
        "metrics_setfit = trainer_setfit.evaluate()\n",
        "\n",
        "preds_setfit = model_setfit(eval_dataset['text'])\n",
        "target_names = ['hate', 'offense', 'nothing']\n",
        "print(classification_report(eval_dataset['label'], preds_setfit, target_names=target_names))\n",
        "\n",
        "# Save the trained SetFit model to the HF hub\n",
        "# trainer_setfit.push_to_hub(\"my-awesome-setfit-model\")\n",
        "\n",
        "# Download from Hub and run inference\n",
        "# model_setfit = SetFitModel.from_pretrained(\"myname/my-awesome-setfit-model\")\n",
        "# Run inference\n",
        "# preds = model_setfit([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst ðŸ¤®\"])"
      ],
      "metadata": {
        "id": "DBvwqwNl83MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code involves loading a pre-trained BERT model and tokenizer and using them to fine-tune the model for text classification tasks. The fine-tuning process involves preparing the datasets for fine-tuning the BERT model, setting up the Trainer for the fine-tuned BERT model, and training it. Once the model is trained, it is saved to the local file system along with the tokenizer for later use. The saved model and tokenizer are then used to perform text classification on the testing set, and the output labels are converted to match the labels in the original dataset. Finally, the performance of the fine-tuned BERT model is evaluated using the `classification_report` function. \n",
        "\n",
        "The `pipeline` function is useful for quickly performing text classification without the need for a custom inference script. The `Trainer` class from the Hugging Face `transformers` library is useful for training the fine-tuned BERT model, and the `compute_metrics` function is useful for computing the evaluation metrics for the fine-tuned BERT model. The `save_pretrained` function is useful for saving the fine-tuned BERT model and tokenizer to the local file system for later use, and the `load_pretrained` function is useful for loading the fine-tuned BERT model and tokenizer from the local file system for future machine learning tasks.\n"
      ],
      "metadata": {
        "id": "4cxUq3AIwoA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained BERT model and tokenizer\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model_bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                                num_labels=3,\n",
        "                                                                ignore_mismatched_sizes=True).to('cuda')"
      ],
      "metadata": {
        "id": "mq6YBndv8-Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that here we are only using 1000 examples to finetune BERT. We use all 858 available observations from the test set for evaluation.\n",
        "Since that is not a proper model development pipeline, we use the test-dataset for evaluation, which is otherwise not a good practice...\n"
      ],
      "metadata": {
        "id": "Z8gEodstx6iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the datasets for fine-tuning the BERT model\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer_bert(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(858))"
      ],
      "metadata": {
        "id": "D6pFDaAF9BRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments\n",
        "training_args = TrainingArguments(output_dir=\"bert_trainer\")\n",
        "\n",
        "# Define the evaluation metric for the fine-tuned BERT model\n",
        "metric_bert = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Set up the Trainer for the fine-tuned BERT model and train it\n",
        "trainer_bert = Trainer(\n",
        "    model=model_bert,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_bert.train()\n",
        "\n",
        "# Save the fine-tuned BERT model and tokenizer to the local file system\n",
        "model_bert.save_pretrained('model_bert')\n",
        "tokenizer_bert.save_pretrained('model_bert')"
      ],
      "metadata": {
        "id": "NHp2kJUT9i_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This saved model could now be pushed to HF hub...or elsewhere"
      ],
      "metadata": {
        "id": "BdhBWuCi3-yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the saved fine-tuned BERT model and tokenizer to perform text classification on the testing set\n",
        "classifier = pipeline(\"text-classification\", model=\"model_bert\", device=0)\n",
        "preds_bert = classifier(eval_dataset['text'])"
      ],
      "metadata": {
        "id": "OLFmjbCEDQF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the output labels to match the labels in the original dataset\n",
        "preds_bert_num = [x['label'] for x in preds_bert]\n",
        "mapping = {'LABEL_0':0,'LABEL_1':1,'LABEL_2':2}\n",
        "preds_bert_num = [mapping[x] for x in preds_bert_num]\n",
        "\n",
        "# Print the classification report for the fine-tuned BERT model\n",
        "target_names = ['hate', 'offense', 'nothing']\n",
        "print(classification_report(eval_dataset['label'], preds_bert_num, target_names=target_names))"
      ],
      "metadata": {
        "id": "xqzyb_nO6-fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}