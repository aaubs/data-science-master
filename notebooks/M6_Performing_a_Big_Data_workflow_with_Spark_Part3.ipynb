{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXFJdDK20820586I/bgKoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M6_Performing_a_Big_Data_workflow_with_Spark_Part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYROXU43UTio"
      },
      "source": [
        "# Advanced Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxJEmdqAUTio"
      },
      "source": [
        "### Spark Catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEh1md8iUTio"
      },
      "outputs": [],
      "source": [
        "# If you have used Spark for a while now, this is a good time to learn about spark Catalog.\n",
        "# you can also totally skip this section since it is totally independed of what follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz-D9jU_UTio",
        "outputId": "eb549149-a919-431a-c1b6-dc5aff080751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Database(name='default', description='default database', locationUri='file:/content/spark-warehouse')]"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ],
      "source": [
        "# get all the databases in the database. \n",
        "spark.catalog.listDatabases()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xhMh1ls5UTio",
        "outputId": "472f7f62-f9b5-46f6-c8e4-7ba856fc462c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'default'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 271
        }
      ],
      "source": [
        "# get the name of the current database\n",
        "spark.catalog.currentDatabase()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU7cQKdoUTip",
        "outputId": "2a4f68fe-6cdc-4477-d61a-1cbe0679b81b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='df_test', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='mytable', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ],
      "source": [
        "## lists tables\n",
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSH4dg69UTip"
      },
      "outputs": [],
      "source": [
        "# add a table to the catalog\n",
        "df_train.createOrReplaceTempView(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvsunqnHUTip",
        "outputId": "cbb66624-21c8-4bbd-d210-dcee3012ed5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='df_test', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='df_train', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='mytable', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ],
      "source": [
        "# list tables\n",
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsgnwCbyUTip"
      },
      "outputs": [],
      "source": [
        "# Caching\n",
        "# cached table \"df_train\"\n",
        "spark.catalog.cacheTable(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-KNPBSRUTip",
        "outputId": "773f79ac-8bc6-4f6c-e34f-8b292d736044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ],
      "source": [
        "# checks if the table is cached\n",
        "spark.catalog.isCached(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrENR_IhUTip",
        "outputId": "f5ab2681-e33f-4655-8841-cdeb7c8a4f01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ],
      "source": [
        "spark.catalog.isCached(\"df_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E5bjDAmUTip"
      },
      "outputs": [],
      "source": [
        "# lets cahche df_test as well\n",
        "spark.catalog.cacheTable(\"df_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW9gWQyiUTip",
        "outputId": "46547363-abd7-4d06-eee5-3dea37487d59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ],
      "source": [
        "spark.catalog.isCached(\"df_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoWzagtAUTiq"
      },
      "outputs": [],
      "source": [
        "# let's uncache df_train\n",
        "spark.catalog.uncacheTable(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8e7wp9EUTiq",
        "outputId": "a44325f6-48a3-4d59-8bce-a416da559cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ],
      "source": [
        "spark.catalog.isCached(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuFI_7VNUTiq",
        "outputId": "5e9b2f2d-8ce6-400f-d061-1e7e288806f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ],
      "source": [
        "spark.catalog.isCached(\"df_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0m7VEAEUTiq"
      },
      "outputs": [],
      "source": [
        "# How about clearing all cached tables at once. \n",
        "spark.catalog.clearCache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dCUjcxrUTiq",
        "outputId": "4cb22780-8961-4ee0-cfb4-344e10389e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ],
      "source": [
        "spark.catalog.isCached(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKYT6cIIUTiq"
      },
      "outputs": [],
      "source": [
        "# creating a global temp view\n",
        "df_train.createGlobalTempView(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_T7DpKvUTiq",
        "outputId": "935fe939-ccba-4179-de3a-ffac4217c375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+-----------+\n",
            "|  namespace|viewName|isTemporary|\n",
            "+-----------+--------+-----------+\n",
            "|global_temp|df_train|       true|\n",
            "|           | df_test|       true|\n",
            "|           |df_train|       true|\n",
            "|           | mytable|       true|\n",
            "+-----------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# listing all views in global_temp\n",
        "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5idzW9UUTiq",
        "outputId": "b74c38c7-9933-4001-b848-82455bad9e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ],
      "source": [
        "# dropping a table. \n",
        "spark.catalog.dropGlobalTempView(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXnvZ4xUTir",
        "outputId": "f7444b37-cddd-43e9-8b13-1d127a2240ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-----------+\n",
            "|namespace|viewName|isTemporary|\n",
            "+---------+--------+-----------+\n",
            "|         | df_test|       true|\n",
            "|         |df_train|       true|\n",
            "|         | mytable|       true|\n",
            "+---------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# checking that global temp view is dropped.\n",
        "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXoJ2BIgUTir",
        "outputId": "418a0908-a63e-4884-bbf3-1d9f195f8ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ],
      "source": [
        "spark.catalog.dropTempView(\"df_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jw3EEVpUTir",
        "outputId": "9716f793-f0c3-4c73-bb91-c5bb064de60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-----------+\n",
            "|namespace|viewName|isTemporary|\n",
            "+---------+--------+-----------+\n",
            "|         | df_test|       true|\n",
            "|         | mytable|       true|\n",
            "+---------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# checking that global temp view is dropped.\n",
        "spark.sql(\"SHOW VIEWS IN global_temp;\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsd2WQHwUTir",
        "outputId": "ade1f689-c535-4cc2-a954-ee47fd1720d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-----------+\n",
            "|namespace|viewName|isTemporary|\n",
            "+---------+--------+-----------+\n",
            "|         | df_test|       true|\n",
            "|         | mytable|       true|\n",
            "+---------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SHOW VIEWS\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhc2Yb2QUTir"
      },
      "source": [
        "## Dealing with Missing Values\n",
        "### Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltGav-IYUTir"
      },
      "outputs": [],
      "source": [
        "# filling the null values in cabin with \"N\".\n",
        "# df.fillna(value, subset=[]);\n",
        "df_train = df_train.na.fill('N', subset=['Cabin'])\n",
        "df_test = df_test.na.fill('N', subset=['Cabin'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwTQdRxaUTir"
      },
      "source": [
        "### Fare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4oARuz9UTir",
        "outputId": "f10ac623-2b2b-4985-9c45-34f506987ad0",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## how do we find out the rows with missing values?\n",
        "# we can use .where(condition) with .isNull()\n",
        "df_test.where(df_test['Fare'].isNull()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uulvZcZFUTir"
      },
      "source": [
        "Here, We can take the average of the **Fare** column to fill in the NaN value. However, for the sake of learning and practicing, we will try something else. We can take the average of the values where **Pclass** is ***3***, **Sex** is ***male*** and **Embarked** is ***S***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI0gQhYjUTis"
      },
      "outputs": [],
      "source": [
        "missing_value = df_test.filter(\n",
        "    (df_test['Pclass'] == 3) &\n",
        "    (df_test.Embarked == 'S') &\n",
        "    (df_test.Sex == \"male\")\n",
        ")\n",
        "## filling in the null value in the fare column using Fare mean. \n",
        "df_test = df_test.na.fill(\n",
        "    missing_value.select(mean('Fare')).collect()[0][0],\n",
        "    subset=['Fare']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiXye11yUTis",
        "outputId": "0f3c430f-1402-4a6c-e334-b18a5675e896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checking\n",
        "df_test.where(df_test['Fare'].isNull()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAGtuzqwUTis"
      },
      "source": [
        "### Embarked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SdZR6SSUTis",
        "outputId": "7c0d2684-42d4-448f-dae8-e26bc0c06cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+-------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|               Name|   Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+-------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "|         62|       1|     1|Icard, Miss. Amelie|female|38.0|    0|    0|113572|80.0|  B28|    null|\n",
            "+-----------+--------+------+-------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_train.where(df_train['Embarked'].isNull()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C31111uAUTis"
      },
      "outputs": [],
      "source": [
        "## Replacing the null values in the Embarked column with the mode. \n",
        "df_train = df_train.na.fill('C', subset=['Embarked'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoYj1A4cUTis",
        "outputId": "cf749693-250d-49bd-b5bc-fa43cc48496f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## checking\n",
        "df_train.where(df_train['Embarked'].isNull()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixWNtxEHUTis",
        "outputId": "68ef5be4-7499-422b-8859-7df0136dbaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "|        830|       1|     1|Stone, Mrs. Georg...|female|62.0|    0|    0|113572|80.0|  B28|    null|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_test.where(df_test.Embarked.isNull()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdJ0DKvvUTis"
      },
      "source": [
        "## Feature Engineering\n",
        "### Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efigpn2_UTis"
      },
      "outputs": [],
      "source": [
        "## this is a code to create a wrapper for function, that works for both python and Pyspark.\n",
        "from typing import Callable\n",
        "from pyspark.sql import Column\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType, IntegerType, ArrayType, DataType\n",
        "class py_or_udf:\n",
        "    def __init__(self, returnType : DataType=StringType()):\n",
        "        self.spark_udf_type = returnType\n",
        "        \n",
        "    def __call__(self, func : Callable):\n",
        "        def wrapped_func(*args, **kwargs):\n",
        "            if any([isinstance(arg, Column) for arg in args]) or \\\n",
        "                any([isinstance(vv, Column) for vv in kwargs.values()]):\n",
        "                return udf(func, self.spark_udf_type)(*args, **kwargs)\n",
        "            else:\n",
        "                return func(*args, **kwargs)\n",
        "        return wrapped_func\n",
        "\n",
        "    \n",
        "@py_or_udf(returnType=StringType())\n",
        "def first_char(col):\n",
        "    return col[0]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwwE7Ig5UTis"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn('Cabin', first_char(df_train['Cabin']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY-Zt90tUTit"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.withColumn('Cabin', first_char(df_test['Cabin']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "dCFSYm9EUTit",
        "outputId": "6d490ac3-45a0-4ea9-aae0-abd26f95420a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500     N        S  \n",
              "1      0          PC 17599  71.2833     C        C  \n",
              "2      0  STON/O2. 3101282   7.9250     N        S  \n",
              "3      0            113803  53.1000     C        S  \n",
              "4      0            373450   8.0500     N        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10082f74-3dad-4bbf-bbb2-19104f047c24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10082f74-3dad-4bbf-bbb2-19104f047c24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10082f74-3dad-4bbf-bbb2-19104f047c24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10082f74-3dad-4bbf-bbb2-19104f047c24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ],
      "source": [
        "df_train.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puoI6uckUTit"
      },
      "source": [
        "We can use the average of the fare column We can use pyspark's ***groupby*** function to get the mean fare of each cabin letter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMMC49a5UTit",
        "outputId": "8e7919df-44c3-4a50-b31a-f997598d7fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+\n",
            "|Cabin|         avg(Fare)|\n",
            "+-----+------------------+\n",
            "|    F|20.112033333333333|\n",
            "|    E|53.944447619047615|\n",
            "|    T|              35.5|\n",
            "|    B| 94.72019230769232|\n",
            "|    D| 59.19123157894737|\n",
            "|    C|102.14492608695654|\n",
            "|    A|43.487500000000004|\n",
            "|    N|19.307918358531317|\n",
            "|    G|          13.58125|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_train.groupBy('Cabin').mean(\"Fare\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChcH1OKeUTit"
      },
      "source": [
        "Now, these mean can help us determine the unknown cabins, if we compare each unknown cabin rows with the given mean's above. Let's write a simple function so that we can give cabin names based on the means. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdhoPhOcUTit"
      },
      "outputs": [],
      "source": [
        "@py_or_udf(returnType=StringType())\n",
        "def cabin_estimator(i):\n",
        "    \"\"\"Grouping cabin feature by the first letter\"\"\"\n",
        "    a = 0\n",
        "    if i<16:\n",
        "        a = \"G\"\n",
        "    elif i>=16 and i<27:\n",
        "        a = \"F\"\n",
        "    elif i>=27 and i<38:\n",
        "        a = \"T\"\n",
        "    elif i>=38 and i<47:\n",
        "        a = \"A\"\n",
        "    elif i>= 47 and i<53:\n",
        "        a = \"E\"\n",
        "    elif i>= 53 and i<54:\n",
        "        a = \"D\"\n",
        "    elif i>=54 and i<116:\n",
        "        a = 'C'\n",
        "    else:\n",
        "        a = \"B\"\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-csuzlUqUTit"
      },
      "outputs": [],
      "source": [
        "## separating data where Cabin == 'N', remeber we used 'N' for Null. \n",
        "df_withN = df_train.filter(df_train['Cabin'] == 'N')\n",
        "df2 = df_train.filter(df_train['Cabin'] != 'N')\n",
        "\n",
        "## replacing 'N' using cabin estimated function. \n",
        "df_withN = df_withN.withColumn('Cabin', cabin_estimator(df_withN['Fare']))\n",
        "\n",
        "# putting the dataframe back together. \n",
        "df_train = df_withN.union(df2).orderBy('PassengerId') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXeG2rM5UTit"
      },
      "outputs": [],
      "source": [
        "#let's do the same for test set\n",
        "df_testN = df_test.filter(df_test['Cabin'] == 'N')\n",
        "df_testNoN = df_test.filter(df_test['Cabin'] != 'N')\n",
        "df_testN = df_testN.withColumn('Cabin', cabin_estimator(df_testN['Fare']))\n",
        "df_test = df_testN.union(df_testNoN).orderBy('PassengerId')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRwVf6fVUTit"
      },
      "source": [
        "### Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gLIB3ZzUTit"
      },
      "outputs": [],
      "source": [
        "## creating UDF functions\n",
        "@py_or_udf(returnType=IntegerType())\n",
        "def name_length(name):\n",
        "    return len(name)\n",
        "\n",
        "\n",
        "@py_or_udf(returnType=StringType())\n",
        "def name_length_group(size):\n",
        "    a = ''\n",
        "    if (size <=20):\n",
        "        a = 'short'\n",
        "    elif (size <=35):\n",
        "        a = 'medium'\n",
        "    elif (size <=45):\n",
        "        a = 'good'\n",
        "    else:\n",
        "        a = 'long'\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYjJbYvKUTiu"
      },
      "outputs": [],
      "source": [
        "## getting the name length from name. \n",
        "df_train = df_train.withColumn(\"name_length\", name_length(df_train['Name']))\n",
        "\n",
        "## grouping based on name length. \n",
        "df_train = df_train.withColumn(\"nLength_group\", name_length_group(df_train['name_length']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thA8aucHUTiu"
      },
      "outputs": [],
      "source": [
        "## Let's do the same for test set. \n",
        "df_test = df_test.withColumn(\"name_length\", name_length(df_test['Name']))\n",
        "\n",
        "df_test = df_test.withColumn(\"nLength_group\", name_length_group(df_test['name_length']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZQx5mr3UTiu"
      },
      "source": [
        "### Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id-FvlJsUTiu"
      },
      "outputs": [],
      "source": [
        "## this function helps getting the title from the name. \n",
        "@py_or_udf(returnType=StringType())\n",
        "def get_title(name):\n",
        "    return name.split('.')[0].split(',')[1].strip()\n",
        "\n",
        "df_train = df_train.withColumn(\"title\", get_title(df_train['Name']))\n",
        "df_test = df_test.withColumn('title', get_title(df_test['Name']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXgYL50BUTiu"
      },
      "outputs": [],
      "source": [
        "## we are writing a function that can help us modify title column\n",
        "@py_or_udf(returnType=StringType())\n",
        "def fuse_title1(feature):\n",
        "    \"\"\"\n",
        "    This function helps modifying the title column\n",
        "    \"\"\"\n",
        "    if feature in ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col', 'Rev', 'Dona', 'Dr']:\n",
        "        return 'rare'\n",
        "    elif feature in ['Ms', 'Mlle']:\n",
        "        return 'Miss'\n",
        "    elif feature == 'Mme':\n",
        "        return 'Mrs'\n",
        "    else:\n",
        "        return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z690V3TyUTiu"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn(\"title\", fuse_title1(df_train[\"title\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUiMABKtUTiu"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.withColumn(\"title\", fuse_title1(df_test['title']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkbZl3GXUTiu",
        "outputId": "247f0ff3-b66d-4333-c6e5-163a628d3cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mr' 'Mrs' 'Miss' 'Master' 'rare']\n",
            "['Mrs' 'Mr' 'Miss' 'rare' 'Master']\n"
          ]
        }
      ],
      "source": [
        "print(df_train.toPandas()['title'].unique())\n",
        "print(df_test.toPandas()['title'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhnGabOfUTiv"
      },
      "source": [
        "### family_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fU6BHlxUTiv"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn(\"family_size\", df_train['SibSp']+df_train['Parch'])\n",
        "df_test = df_test.withColumn(\"family_size\", df_test['SibSp']+df_test['Parch'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pv5fGSdUTiv"
      },
      "outputs": [],
      "source": [
        "## bin the family size. \n",
        "@py_or_udf(returnType=StringType())\n",
        "def family_group(size):\n",
        "    \"\"\"\n",
        "    This funciton groups(loner, small, large) family based on family size\n",
        "    \"\"\"\n",
        "    \n",
        "    a = ''\n",
        "    if (size <= 1):\n",
        "        a = 'loner'\n",
        "    elif (size <= 4):\n",
        "        a = 'small'\n",
        "    else:\n",
        "        a = 'large'\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSTago3YUTiv"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn(\"family_group\", family_group(df_train['family_size']))\n",
        "df_test = df_test.withColumn(\"family_group\", family_group(df_test['family_size']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56IwtHVMUTiv"
      },
      "source": [
        "### is_alone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnQlh4o_UTiv"
      },
      "outputs": [],
      "source": [
        "@py_or_udf(returnType=IntegerType())\n",
        "def is_alone(num):\n",
        "    if num<2:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mxZhDcmUTiv"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn(\"is_alone\", is_alone(df_train['family_size']))\n",
        "df_test = df_test.withColumn(\"is_alone\", is_alone(df_test[\"family_size\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDt5VMRUTiv"
      },
      "source": [
        "### ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1vY8uuhUTiv"
      },
      "outputs": [],
      "source": [
        "## dropping ticket column\n",
        "df_train = df_train.drop('ticket')\n",
        "df_test = df_test.drop(\"ticket\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAIDopGUTiv"
      },
      "source": [
        "### calculated_fare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRy0e0GBUTiw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import expr, col, when, coalesce, lit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csd4z2rIUTiz"
      },
      "outputs": [],
      "source": [
        "## here I am using a something similar to if and else statement, \n",
        "#when(condition, value_when_condition_met).otherwise(alt_condition)\n",
        "df_train = df_train.withColumn(\n",
        "    \"calculated_fare\", \n",
        "    when((col(\"Fare\")/col(\"family_size\")).isNull(), col('Fare'))\n",
        "    .otherwise((col(\"Fare\")/col(\"family_size\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1IC4j1LUTiz"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.withColumn(\n",
        "    \"calculated_fare\", \n",
        "    when((col(\"Fare\")/col(\"family_size\")).isNull(), col('Fare'))\n",
        "    .otherwise((col(\"Fare\")/col(\"family_size\"))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE2fqr8aUTi0"
      },
      "source": [
        "### fare_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfvETnFFUTi0"
      },
      "outputs": [],
      "source": [
        "@py_or_udf(returnType=StringType())\n",
        "def fare_group(fare):\n",
        "    \"\"\"\n",
        "    This function creates a fare group based on the fare provided\n",
        "    \"\"\"\n",
        "    \n",
        "    a= ''\n",
        "    if fare <= 4:\n",
        "        a = 'Very_low'\n",
        "    elif fare <= 10:\n",
        "        a = 'low'\n",
        "    elif fare <= 20:\n",
        "        a = 'mid'\n",
        "    elif fare <= 45:\n",
        "        a = 'high'\n",
        "    else:\n",
        "        a = \"very_high\"\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bboOV8g6UTi0"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.withColumn(\"fare_group\", fare_group(col(\"Fare\")))\n",
        "df_test = df_test.withColumn(\"fare_group\", fare_group(col(\"Fare\")))"
      ]
    }
  ]
}