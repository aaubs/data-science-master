{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M2_hatespeech_nlp_explainer_tm_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31w7INhskhWu"
      },
      "source": [
        "Trigger warning: This notebook contains words or language that are considered profane, vulgar, or offensive by some."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ClxNmEW8-L"
      },
      "outputs": [],
      "source": [
        "# Install the tweet-preprocessor library (used for cleaning and preprocessing tweets)\n",
        "!pip install tweet-preprocessor -q\n",
        "\n",
        "# Install the latest version of gensim (a library for topic modeling and document similarity analysis)\n",
        "!pip install -q -U gensim\n",
        "\n",
        "# Install pyLDAvis (a Python library for interactive topic model visualization)\n",
        "!pip install -q pyLDAvis\n",
        "\n",
        "# Force reinstall numpy to version 1.22.4. This is currently necessary to ensure compatibility or fix certain issues.\n",
        "!pip install --force-reinstall -q numpy==1.22.4\n",
        "\n",
        "# Install LIME (Local Interpretable Model-Agnostic Explanations), a library for explaining machine learning model predictions\n",
        "!pip install -q lime\n",
        "\n",
        "# Install or update the imbalanced-learn library, useful for dealing with imbalanced datasets\n",
        "!pip install -U imbalanced-learn -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMGBKNqTRcNu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import preprocessor as prepro # twitter prepro\n",
        "from tqdm.notebook import tqdm #progress bar\n",
        "\n",
        "import spacy #spacy for quick language prepro\n",
        "nlp = spacy.load('en_core_web_sm') #instantiating English module\n",
        "\n",
        "# sampling, splitting\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# loading ML libraries\n",
        "from sklearn.pipeline import make_pipeline #pipeline creation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #transforms text to sparse matrix\n",
        "from sklearn.linear_model import LogisticRegression #Logit model\n",
        "from sklearn.metrics import classification_report #that's self explanatory\n",
        "from sklearn.decomposition import TruncatedSVD #dimensionality reduction\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import altair as alt #viz\n",
        "\n",
        "#explainability\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from collections import OrderedDict\n",
        "\n",
        "# topic modeling\n",
        "\n",
        "from gensim.corpora.dictionary import Dictionary # Import the dictionary builder\n",
        "from gensim.models import LdaMulticore # we'll use the faster multicore version of LDA\n",
        "\n",
        "# Import pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting rid of annoying warnings from ipykernel\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "cv5R8X2ZO2eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsQWaTU41ksj"
      },
      "outputs": [],
      "source": [
        "# prepro settings\n",
        "prepro.set_options(prepro.OPT.URL, prepro.OPT.NUMBER, prepro.OPT.RESERVED, prepro.OPT.MENTION, prepro.OPT.SMILEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3-rBov_TJuV"
      },
      "outputs": [],
      "source": [
        "# open file\n",
        "data = pd.read_csv('https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/twitter_hate.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUhjywn2gBz0"
      },
      "outputs": [],
      "source": [
        "#basic cleanup only for tweets\n",
        "data['text_clean'] = data['tweet'].map(lambda t: prepro.clean(t))\n",
        "data['text_clean'] = data['text_clean'].str.replace('#','')\n",
        "data['text_clean'] = data['text_clean'].str.replace('rt','')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QmceSunZ_Lf"
      },
      "source": [
        "Spacy basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvye6QPVU5tB"
      },
      "outputs": [],
      "source": [
        "text = \"this is a sentence about how much i would like to have a break in spanish they call it pausa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjvHcGNfVAr3"
      },
      "outputs": [],
      "source": [
        "text_list = text.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ebkHILVJnN"
      },
      "outputs": [],
      "source": [
        "' '.join(text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPBBKrUDVZPT"
      },
      "outputs": [],
      "source": [
        "text_spacy = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww9zZrnQVdmD"
      },
      "outputs": [],
      "source": [
        "[(word.lemma_, word.pos_) for word in text_spacy if not word.is_stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5ZldFmpWxmq"
      },
      "outputs": [],
      "source": [
        "text_spacy.vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4koNHO5a9zu"
      },
      "outputs": [],
      "source": [
        "text_spacy = nlp('Aalborg Univ. is a nice place where Donaldo Trump has never been.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj2VaiZebHHB"
      },
      "outputs": [],
      "source": [
        "[(token, token.label_) for token in text_spacy.ents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_r_uMJDaD9f"
      },
      "source": [
        "back to the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijwe4ks92cTn"
      },
      "outputs": [],
      "source": [
        "# run progress bar and clean up using spacy but without some heavy parts of the pipeline\n",
        "\n",
        "clean_text = []\n",
        "\n",
        "pbar = tqdm(total=len(data['text_clean']),position=0, leave=True)\n",
        "\n",
        "for text in nlp.pipe(data['text_clean'], disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "\n",
        "  txt = [token.lemma_.lower() for token in text\n",
        "         if token.is_alpha\n",
        "         and not token.is_stop\n",
        "         and not token.is_punct]\n",
        "\n",
        "  clean_text.append(\" \".join(txt))\n",
        "\n",
        "  pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb8RI568dKqj"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(texts: pd.Series, nlp) -> list:\n",
        "    \"\"\"\n",
        "    Preprocess a series of texts.\n",
        "\n",
        "    Parameters:\n",
        "    - texts: A pandas Series containing the text to be preprocessed.\n",
        "    - nlp: A spaCy NLP model.\n",
        "\n",
        "    Returns:\n",
        "    - A list of preprocessed texts.\n",
        "\n",
        "    Steps:\n",
        "    - Clean twitter-specific characters using a predefined 'prepro' method.\n",
        "    - Normalize the text by lowercasing and lemmatizing.\n",
        "    - Remove punctuations, stopwords, and non-alphabet characters.\n",
        "    \"\"\"\n",
        "\n",
        "    # Clean twitter-specific characters and other special characters\n",
        "    texts_cleaned = texts.map(prepro.clean).str.replace('#', '')\n",
        "    texts_cleaned = texts_cleaned.str.replace('#', '')\n",
        "\n",
        "    # Initialize container for the cleaned texts\n",
        "    clean_container = []\n",
        "\n",
        "    # Use tqdm for a progress bar\n",
        "    pbar = tqdm(total=len(texts_cleaned), position=0, leave=True)\n",
        "\n",
        "    # Use spaCy's nlp.pipe for efficient text processing\n",
        "    for doc in nlp.pipe(texts_cleaned, disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "\n",
        "        # Extract lemmatized tokens that are not punctuations, stopwords, or non-alphabetic\n",
        "        tokens = [token.lemma_.lower() for token in doc\n",
        "                  if token.is_alpha and not token.is_stop and not token.is_punct]\n",
        "\n",
        "        clean_container.append(\" \".join(tokens))\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "    return clean_container\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HURoUCsB2kt3"
      },
      "outputs": [],
      "source": [
        "# apply all prepro-pipeline to texts\n",
        "data['text_clean'] = text_prepro(data['tweet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdAqGWwL12Y0"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKUEvg4Q1uFS"
      },
      "outputs": [],
      "source": [
        "# renaming and reordering\n",
        "\n",
        "data_df = pd.DataFrame({'label':data['class'], 'text':data['text_clean']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHympnHCdwJG"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_df.label.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i94Otnud-fiR"
      },
      "outputs": [],
      "source": [
        "# Count and reset index\n",
        "data_chart = data_df.label.value_counts().reset_index().rename(columns={'label': 'Category', 'count': 'N Tweets'})\n",
        "\n",
        "# Replace numerical categories with textual descriptions\n",
        "data_chart['Category'] = data_chart['Category'].map({0: 'hate', 1: 'offensive', 2: 'nothing'})\n",
        "\n",
        "# Plot the chart\n",
        "chart = alt.Chart(data_chart).mark_bar(filled=True).encode(\n",
        "    alt.X('N Tweets:Q', title='N Tweets'),\n",
        "    alt.Y('Category:O', title='Category', sort='-x'),\n",
        "    color=alt.Color('Category:N', legend=alt.Legend(title=\"Label Types\"), scale=alt.Scale(\n",
        "        domain=['hate', 'offensive', 'nothing'],\n",
        "        range=['red', 'orange', 'green']\n",
        "    ))\n",
        ")\n",
        "\n",
        "chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Miz9_kpref"
      },
      "outputs": [],
      "source": [
        "# fixing sample imbalance\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "data_df_res, y_res = rus.fit_resample(data_df, data_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoJRCOfn-YuU"
      },
      "outputs": [],
      "source": [
        "data_df_res['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myvcNFNQf4cA"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set (since we have a new output variable)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_df_res['text'], y_res, test_size = 0.4, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPwp4olReY5a"
      },
      "outputs": [],
      "source": [
        "#instantiate models and \"bundle up as pipeline\"\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "cls = LogisticRegression()\n",
        "\n",
        "pipe = make_pipeline(tfidf, cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6nRa0zkeY0Y"
      },
      "outputs": [],
      "source": [
        "pipe.fit(X_train,y_train) # fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alBRiy43eYtW"
      },
      "outputs": [],
      "source": [
        "# evaluate model performance on training set\n",
        "\n",
        "y_eval = pipe.predict(X_train)\n",
        "report = classification_report(y_train, y_eval)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXQWo_xuhtQ6"
      },
      "outputs": [],
      "source": [
        "# run single prediction\n",
        "\n",
        "t1 = ['you stupid fag bitch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh94Jc4NhyCH"
      },
      "outputs": [],
      "source": [
        "# preprocess\n",
        "\n",
        "t1_p = text_prepro(pd.Series(t1)) # note, we need to pack text up as pd.Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYWUNTSch3KI"
      },
      "outputs": [],
      "source": [
        "# predict\n",
        "\n",
        "pipe.predict(t1_p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's explain the result:\n",
        "\n",
        "class_names = [\"hate\", \"offensive\", 'nothing']\n",
        "\n",
        "explainer = LimeTextExplainer(class_names = class_names)"
      ],
      "metadata": {
        "id": "uFzwS3oUQmJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(t1[0], pipe.predict_proba, num_features = 10, top_labels=3)"
      ],
      "metadata": {
        "id": "MtB2B_yRQwUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "lTJw0TF4QxBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 89"
      ],
      "metadata": {
        "id": "RsJRUV9dRLkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[idx], pipe.predict_proba, num_features = 10, top_labels=3)"
      ],
      "metadata": {
        "id": "F_dp9w8oQ4zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.iloc[idx])"
      ],
      "metadata": {
        "id": "CHsgHEu9RGgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "rGCoDornQ9O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GADnYvq7PGJv"
      },
      "source": [
        "## Let's try a complex (black-box) model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKC9cONAPCq3"
      },
      "outputs": [],
      "source": [
        "#instantiate models and \"bundle up as pipeline\"\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "svd = TruncatedSVD(n_components = 100)\n",
        "cls_xg = XGBClassifier()\n",
        "\n",
        "pipe_xg = make_pipeline(tfidf, svd, cls_xg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7H4C77rPatZ"
      },
      "outputs": [],
      "source": [
        "pipe_xg.fit(X_train,y_train) # fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ188lIqPhS9"
      },
      "outputs": [],
      "source": [
        "# evaluate model performance on training set\n",
        "\n",
        "y_eval = pipe_xg.predict(X_train)\n",
        "report = classification_report(y_train, y_eval)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmQ1aG7-PnCm"
      },
      "outputs": [],
      "source": [
        "# evaluate model performance on test set\n",
        "\n",
        "y_pred = pipe_xg.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 89"
      ],
      "metadata": {
        "id": "uZCoaLprSRCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[idx], pipe_xg.predict_proba, num_features = 10, top_labels=3)"
      ],
      "metadata": {
        "id": "-D62QO6WSRCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.iloc[idx])"
      ],
      "metadata": {
        "id": "kBv50g4uSRCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "Fz8RGlE7SWIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Ip1sP7sD7-"
      },
      "outputs": [],
      "source": [
        "pred_xg = pipe_xg.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIvoln8zsO4Z"
      },
      "outputs": [],
      "source": [
        "X_test_evaluation =pd.DataFrame(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNwtZ03Kscow"
      },
      "outputs": [],
      "source": [
        "X_test_evaluation.index = range(len(X_test_evaluation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8MZCUNLsiyt"
      },
      "outputs": [],
      "source": [
        "X_test_evaluation['y_test'] = list(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPWMjEFHsnuS"
      },
      "outputs": [],
      "source": [
        "X_test_evaluation['pred_xg'] = list(pred_xg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cDwACV-svjU"
      },
      "outputs": [],
      "source": [
        "X_test_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btZCRU6Aszvn"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(X_test_evaluation['y_test'],X_test_evaluation['pred_xg'], normalize='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBf02ghmQEc"
      },
      "source": [
        "## Topic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZiq7pEAWes_"
      },
      "outputs": [],
      "source": [
        "# preprocess texts (we need tokens)\n",
        "tokens = []\n",
        "\n",
        "for text in nlp.pipe(data['text_clean'], disable=[\"ner\"]):\n",
        "  proj_tok = [token.lemma_.lower() for token in text\n",
        "              if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV']\n",
        "              and not token.is_stop\n",
        "              and not token.is_punct]\n",
        "  tokens.append(proj_tok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWy_pCa0ge7P"
      },
      "outputs": [],
      "source": [
        "data['tokens'] = tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H4cdl4ehLPu"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po510P-1obpm"
      },
      "source": [
        "We would like to know what things people are talking about when it is considerede \"hatespeech\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfdEXrJFgqgB"
      },
      "outputs": [],
      "source": [
        "data_hate = data[data['class'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxBNVSFwgrKs"
      },
      "outputs": [],
      "source": [
        "# Create a Dictionary from the articles: dictionary\n",
        "dictionary = Dictionary(data_hate['tokens'])\n",
        "# filter out low-frequency / high-frequency stuff, also limit the vocabulary to max 1000 words\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)\n",
        "# construct corpus using this dictionary\n",
        "corpus = [dictionary.doc2bow(doc) for doc in data_hate['tokens']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR-I1RThhBSd"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "lda_model = LdaMulticore(corpus, id2word=dictionary, num_topics=10, workers = 4, passes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81KTmWw7hCqQ"
      },
      "outputs": [],
      "source": [
        "# Let's try to visualize\n",
        "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfGSNcH5hl_S"
      },
      "outputs": [],
      "source": [
        " # Let's Visualize\n",
        "pyLDAvis.display(lda_display)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKErSFkEhhgyIo3G63fe0l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}