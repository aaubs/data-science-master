{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNORGyxgsKhWD2MYVkiVT8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M2-training-word-vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training customized word embeddings\n",
        "\n",
        "Word embeddings became big around 2013 and are linked to [this paper](https://arxiv.org/abs/1301.3781) with the beautiful title \n",
        "*Efficient Estimation of Word Representations in Vector Space* by Tomas Mokolov et al. coming out of Google. This was the foundation of Word2Vec.\n",
        "\n",
        "The idea behind it is easiest summarized by the following quote: \n",
        "\n",
        "\n",
        "> *You shall know a word by the company it keeps (Firth, J. R. 1957:11)*\n",
        "\n",
        "![](https://ruder.io/content/images/size/w2000/2016/04/word_embeddings_colah.png)\n",
        "\n",
        "Let me start with a fascinating example of word embeddings in practice. Below, you can see a figure from the paper: \n",
        "*Dynamic Word Embeddings for Evolving Semantic Discovery*. Here (in simple terms) the researchers estimated word vectors for from textual inputs in different time-frames. They picked out some terms and person that obviously changed *their company* over the years. Then they look at the relative position of these terms compared to terms that did not change much (anchors). If you are interested in this kind of research, check out [this blog](https://blog.acolyer.org/2018/02/22/dynamic-word-embeddings-for-evolving-semantic-discovery/) that describes the paper briefly or the [original paper](https://arxiv.org/abs/1703.00607).\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2018/02/evolving-word-embeddings-fig-1.jpeg)\n",
        "\n",
        "Word embeddings allow us to create term representations that \"learn\" meaning from semantic and syntactic features. These models take a sequence of sentences as an input and scan for all individual terms that appear in the whole corpus and all their occurrences. Such contextual learning seems to be able to pick up non-trivial conceptual details and it is this class of models that today enable technologies such as chatbots, machine translation and much more.\n",
        "\n",
        "The early word embedding models were Word2Vec and [GloVe](https://nlp.stanford.edu/projects/glove/).\n",
        "In December 2017 Facebook presented [fastText](https://fasttext.cc/) (by the way - by 2017 Tomas Mikolov was working for Facebook and is one of the authors of the [paper](https://arxiv.org/abs/1607.04606) that introduces the research behind fastText). This model extends the idea of Word2Vec, enriching these vectors by information from sub-word elements. What does that mean? Words are not only defined by surrounding words but in addition also by the various syllables that make up the word. Why should that be a good idea? Well, now words such as *apple* and *apples* do not only get similar vectors due to them often sharing context but also because they are composed of the same sub-word elements. This comes in particularly handy when we are dealing with language that have a rich morphology such as Turkish or Russian.  This is also great when working with web-text, which is often messy and misspelt.\n",
        "\n",
        "The current state-of-the-art transformer models go even further and implement context-specificity (a word may change meaning depending on the context in which it occurs)\n",
        "\n",
        "Now the good news: You will find pre-trained vectors from all mentioned models online. They will do great in most cases. However, when working with specific tasks: Some obscure languages and/or specific technical jargon (specific scientific field or industry e.g. finance, insurance), it is nice to know how to train such word-vectors.\n",
        "\n",
        "\n",
        "In this tutorial we will train the \"classic\" Word2Vec model, considering bi-grams. We will also look a bit into data-engineering issues in sequence-training. Finally, we will look at how we can use such models for text representation beyond individual words.\n",
        "\n",
        "## Data\n",
        "\n",
        "The data used here are 10k cooking related posts from Reddit. They come in JSON-lines format and can be either downloaded first or opened via requests.\n",
        "\n",
        "## Plan of attack\n",
        "In this tutorial we will not be using Spacy, as it is not fast enough for use in training of large language models.\n",
        "The intent is to understand training from disk - where the file is not opened (with e.g. pandas) and an object in memory but streamed from disk."
      ],
      "metadata": {
        "id": "VLbsQbzzYlwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S6qffJDvqFVq",
        "outputId": "a5b38ec1-1f6f-4bdb-8f0e-54fe109739ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 15:09:55--  https://raw.githubusercontent.com/aaubs/ds-master/main/data/reddit_r_cooking_sample.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2675456 (2.6M) [text/plain]\n",
            "Saving to: ‘reddit_r_cooking_sample.jsonl’\n",
            "\n",
            "\r          reddit_r_   0%[                    ]       0  --.-KB/s               \rreddit_r_cooking_sa 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-11-01 15:09:56 (169 MB/s) - ‘reddit_r_cooking_sample.jsonl’ saved [2675456/2675456]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download data (optional when training from memory)\n",
        "!wget https://raw.githubusercontent.com/aaubs/ds-master/main/data/reddit_r_cooking_sample.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "id": "k_iGYh4etyYt",
        "outputId": "ecb0a144-8ebc-435d-c3ee-98cfa3966b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# we will use nltk for sentence tokenization\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# we will be using gensim for training\n",
        "import gensim\n",
        "from gensim import utils\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
        "\n",
        "\n",
        "# Logging settings\n",
        "import logging\n",
        "\n",
        "for handler in logging.root.handlers[:]:\n",
        "   logging.root.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "metadata": {
        "id": "maHvkJm-qQqi",
        "outputId": "2a19aada-1fab-42c9-c4b9-2214d53df936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple In-memory training\n",
        "\n",
        "To better understand the training itself we start with simple model training out of memory. All the data will be loaded with pandas.\n",
        "Preprocessing results will also be stored in the dataframe. This is a viable approache up a certain data-size. When going beyond 5M texts (depending on the hardware) that's probably not a good idea.."
      ],
      "metadata": {
        "id": "p-vGObWWc8ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "data = pd.read_json('https://raw.githubusercontent.com/aaubs/ds-master/main/data/reddit_r_cooking_sample.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "dGaq3bGZqUJi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "_BQE_vtjqX-w",
        "outputId": "c2f6eed7-ea7c-4996-b411-8bb0956c8cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Where do you get the mock duck? I've only rece...   \n",
              "1  Microwaves are terrible. Everyone in this sub ...   \n",
              "2  My Pro 500 is going on 18 years old. Thing is ...   \n",
              "3  deglazing works ok. but not as well as on a st...   \n",
              "4  Does Google not exist in Germany? 7g dry is 1....   \n",
              "\n",
              "                                          meta  \n",
              "0  {'section': 'Cooking', 'utc': '1364690064'}  \n",
              "1  {'section': 'Cooking', 'utc': '1368260826'}  \n",
              "2    {'section': 'Cooking', 'utc': 1518485096}  \n",
              "3  {'section': 'Cooking', 'utc': '1413146528'}  \n",
              "4    {'section': 'Cooking', 'utc': 1522171636}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7026730f-7816-4012-adab-f72e0c4d26e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>meta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where do you get the mock duck? I've only rece...</td>\n",
              "      <td>{'section': 'Cooking', 'utc': '1364690064'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Microwaves are terrible. Everyone in this sub ...</td>\n",
              "      <td>{'section': 'Cooking', 'utc': '1368260826'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My Pro 500 is going on 18 years old. Thing is ...</td>\n",
              "      <td>{'section': 'Cooking', 'utc': 1518485096}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>deglazing works ok. but not as well as on a st...</td>\n",
              "      <td>{'section': 'Cooking', 'utc': '1413146528'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does Google not exist in Germany? 7g dry is 1....</td>\n",
              "      <td>{'section': 'Cooking', 'utc': 1522171636}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7026730f-7816-4012-adab-f72e0c4d26e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7026730f-7816-4012-adab-f72e0c4d26e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7026730f-7816-4012-adab-f72e0c4d26e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec uses sentences to train, not paragraphs. Therefore we will need to sentence-tokenize."
      ],
      "metadata": {
        "id": "CDlgZNWsdq0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK tokenizer:\n",
        "sent_tokenize('this is a sentence. also that one.')"
      ],
      "metadata": {
        "id": "WZ3F19r5z3H6",
        "outputId": "c1d53873-0b50-418f-e3ec-3d7efe7c9d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a sentence.', 'also that one.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's apply that to all texts\n",
        "sentences = []\n",
        "for i in data['text']:\n",
        "  sentences.extend(sent_tokenize(i))"
      ],
      "metadata": {
        "id": "2ZRvFTU2zp4p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "id": "iZCwa5lH0Mq1",
        "outputId": "957e68e5-8b58-4a94-bfb4-fb20466bda21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29445"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim has efficient simple preprocessing as part of the utility functions. That works well for most latin-letter texts. Check out [Gensim docos](https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html) for more into."
      ],
      "metadata": {
        "id": "ll1MhWVfeCG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple prepro (tokenization, lowercase, de-accent (otional))\n",
        "sentences_prepro = [utils.simple_preprocess(line) for line in sentences]"
      ],
      "metadata": {
        "id": "hPSpWs_quIO_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not removing stopwords for Word2Vec, as the model actually cares about syntax. One thing that we can do is identifying n-grams (phrases)."
      ],
      "metadata": {
        "id": "sJpPII06ehW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainig a model to identify n-grams\n",
        "phrase_model = Phrases(sentences_prepro, min_count=1, threshold=1, connector_words=ENGLISH_CONNECTOR_WORDS)"
      ],
      "metadata": {
        "id": "zII18gcct_d2",
        "outputId": "b0303101-f5b7-4c1b-f490-594f19b95054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 15:21:05,312 : INFO : collecting all words and their counts\n",
            "2022-11-01 15:21:05,332 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "2022-11-01 15:21:05,700 : INFO : PROGRESS: at sentence #10000, processed 123637 words and 74036 word types\n",
            "2022-11-01 15:21:05,930 : INFO : PROGRESS: at sentence #20000, processed 245368 words and 129436 word types\n",
            "2022-11-01 15:21:06,109 : INFO : collected 176735 token types (unigram + bigrams) from a corpus of 359868 words and 29445 sentences\n",
            "2022-11-01 15:21:06,110 : INFO : merged Phrases<176735 vocab, min_count=1, threshold=1, max_vocab_size=40000000>\n",
            "2022-11-01 15:21:06,115 : INFO : Phrases lifecycle event {'msg': 'built Phrases<176735 vocab, min_count=1, threshold=1, max_vocab_size=40000000> in 0.80s', 'datetime': '2022-11-01T15:21:06.115308', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the model\n",
        "sentences_phrased = [phrase_model[line] for line in sentences_prepro]"
      ],
      "metadata": {
        "id": "osOmQ11HuUtF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick check\n",
        "sentences_phrased[:5]"
      ],
      "metadata": {
        "id": "M_AxSeeQum2F",
        "outputId": "8c206704-4177-43c2-c1ab-6977b6253d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['where_do', 'you_get', 'the', 'mock', 'duck'],\n",
              " ['ve_only', 'recently', 'tried_it', 'in', 'restaurant', 'and', 'loved_it'],\n",
              " ['hoisin', 'we_use', 'for', 'sandwich', 'condiment', 'mixed_with_sriracha'],\n",
              " ['you_could', 'make_those', 'pancakes', 'with', 'another', 'faux', 'meat'],\n",
              " ['some_of_those',\n",
              "  'grain',\n",
              "  'sausages_are',\n",
              "  'really_good',\n",
              "  'and',\n",
              "  'you_can',\n",
              "  'slice_them']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "obviousely, some hyperparameter tuning is needed"
      ],
      "metadata": {
        "id": "_A9-WXqCe5AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adjusting min_count and threshold (that's a value calculated within the model - read docus)\n",
        "phrase_model = Phrases(sentences_prepro, min_count=25, threshold=20, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
        "sentences_phrased = [phrase_model[line] for line in sentences_prepro]\n",
        "sentences_phrased[:5]"
      ],
      "metadata": {
        "id": "TqStLJB5urRA",
        "outputId": "30cf6cdb-4c89-4486-a1c4-52a745aab9ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 15:23:04,636 : INFO : collecting all words and their counts\n",
            "2022-11-01 15:23:04,641 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "2022-11-01 15:23:04,806 : INFO : PROGRESS: at sentence #10000, processed 123637 words and 74036 word types\n",
            "2022-11-01 15:23:04,969 : INFO : PROGRESS: at sentence #20000, processed 245368 words and 129436 word types\n",
            "2022-11-01 15:23:05,155 : INFO : collected 176735 token types (unigram + bigrams) from a corpus of 359868 words and 29445 sentences\n",
            "2022-11-01 15:23:05,158 : INFO : merged Phrases<176735 vocab, min_count=25, threshold=20, max_vocab_size=40000000>\n",
            "2022-11-01 15:23:05,162 : INFO : Phrases lifecycle event {'msg': 'built Phrases<176735 vocab, min_count=25, threshold=20, max_vocab_size=40000000> in 0.53s', 'datetime': '2022-11-01T15:23:05.162199', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['where', 'do', 'you', 'get', 'the', 'mock', 'duck'],\n",
              " ['ve',\n",
              "  'only',\n",
              "  'recently',\n",
              "  'tried',\n",
              "  'it',\n",
              "  'in',\n",
              "  'restaurant',\n",
              "  'and',\n",
              "  'loved',\n",
              "  'it'],\n",
              " ['hoisin',\n",
              "  'we',\n",
              "  'use',\n",
              "  'for',\n",
              "  'sandwich',\n",
              "  'condiment',\n",
              "  'mixed',\n",
              "  'with',\n",
              "  'sriracha'],\n",
              " ['you',\n",
              "  'could',\n",
              "  'make',\n",
              "  'those',\n",
              "  'pancakes',\n",
              "  'with',\n",
              "  'another',\n",
              "  'faux',\n",
              "  'meat'],\n",
              " ['some',\n",
              "  'of',\n",
              "  'those',\n",
              "  'grain',\n",
              "  'sausages',\n",
              "  'are',\n",
              "  'really',\n",
              "  'good',\n",
              "  'and',\n",
              "  'you',\n",
              "  'can',\n",
              "  'slice',\n",
              "  'them']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# did we actually find anything?\n",
        "for phrase, score in phrase_model.find_phrases(sentences_prepro).items():\n",
        "    print(phrase, score)"
      ],
      "metadata": {
        "id": "N0JdwoIpve-A",
        "outputId": "a388daf3-186c-4539-d973-d562e19fa39b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "as_well 27.471339649272448\n",
            "ve_been 41.653628014475565\n",
            "stainless_steel 339.0599520383693\n",
            "your_own 20.223897445413495\n",
            "more_than 20.47408324458768\n",
            "stir_fry 192.49911686782454\n",
            "salt_pepper 31.312819683243973\n",
            "olive_oil 184.98806397708285\n",
            "store_bought 37.18857840249137\n",
            "sour_cream 170.60931322975085\n",
            "ve_never 32.897408361970214\n",
            "slow_cooker 332.58133391235117\n",
            "mashed_potatoes 166.10432330827066\n",
            "thank_you 20.47161354330867\n",
            "tomato_sauce 20.939855748581923\n",
            "they_re 27.604060913705585\n",
            "ve_got 21.553749715437903\n",
            "check_out 30.309552392385527\n",
            "talking_about 51.24875724937863\n",
            "cast_iron 782.157477411027\n",
            "alton_brown 256.58036640165915\n",
            "pulled_pork 112.0196486780152\n",
            "http_www 292.3240096923725\n",
            "com_recipes 21.29508394248534\n",
            "better_than 33.40834415963816\n",
            "don_know 24.0042240154292\n",
            "sous_vide 1497.1500605082697\n",
            "next_time 35.865252904469585\n",
            "grocery_store 213.3450024142926\n",
            "imgur_com 81.90843485169492\n",
            "ground_beef 91.19453044375645\n",
            "grew_up 45.984822202948834\n",
            "make_sure 24.00867902694272\n",
            "chicken_breasts 29.188962816157037\n",
            "chicken_breast 42.88990454618994\n",
            "has_been 28.276186190690467\n",
            "non_stick 246.62336367864975\n",
            "little_bit 29.975005690668645\n",
            "my_wife 27.593286494925838\n",
            "high_heat 44.7203947368421\n",
            "food_processor 66.14746428794211\n",
            "chili_powder 24.752030749120788\n",
            "rice_cooker 36.07271748912206\n",
            "scrambled_eggs 133.56324845948146\n",
            "be_able 40.02815986954355\n",
            "https_www 300.9566237597211\n",
            "youtube_com 35.241276171485545\n",
            "rather_than 83.85831842090992\n",
            "end_up 20.713883875202175\n",
            "lemon_juice 209.30866025166543\n",
            "red_wine 80.15192743764173\n",
            "lime_juice 77.93407562562011\n",
            "brown_sugar 45.76318192349101\n",
            "peanut_butter 59.5200942972609\n",
            "soy_sauce 111.50473186119875\n",
            "sesame_oil 66.39327779373743\n",
            "my_favorite 38.694033935413245\n",
            "my_mom 32.58924522189829\n",
            "cutting_board 338.4231845632641\n",
            "too_much 26.600084208440656\n",
            "white_wine 23.82001725160386\n",
            "dutch_oven 133.8072131598871\n",
            "should_be 23.984295907870774\n",
            "years_ago 128.4038070328393\n",
            "pretty_much 31.305098340658056\n",
            "difference_between 34.61320015667842\n",
            "pressure_cooker 190.61151855047456\n",
            "good_luck 54.79840376665136\n",
            "ice_cream 167.13804148871264\n",
            "instant_pot 97.58558443764865\n",
            "salt_and_pepper 30.632106211869107\n",
            "amp_amp 22.885871711697714\n",
            "room_temperature 30.683159722222225\n",
            "copymethat_com 51.64669783752191\n",
            "crock_pot 79.48147148767764\n",
            "ended_up 23.950428230702514\n",
            "garlic_powder 25.50078327905347\n",
            "coconut_milk 125.34397163120568\n",
            "amazon_com 38.13726067168864\n",
            "black_pepper 84.46117084826761\n",
            "seriouseats_com 33.0386964107677\n",
            "serious_eats 99.85028248587571\n",
            "www_amazon 43.44518190757129\n",
            "pho_pho 871.4107012417822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once sentences are pre-processed (tokenized, list of lists) we can train the model."
      ],
      "metadata": {
        "id": "NRkgZneFfM2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences=sentences_phrased, \n",
        "                               vector_size=300, \n",
        "                               window=5, \n",
        "                               min_count=5, \n",
        "                               workers=4, \n",
        "                               epochs=15)"
      ],
      "metadata": {
        "id": "qWLP480uw2bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check most similar terms\n",
        "model.wv.most_similar('chinese')"
      ],
      "metadata": {
        "id": "Hwirw6wKxSrD",
        "outputId": "29f3ecee-b03f-42f1-e89a-0a7aca97ccc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('indian', 0.8582229614257812),\n",
              " ('mexican', 0.8339536786079407),\n",
              " ('korean', 0.8001686334609985),\n",
              " ('asian', 0.7954041957855225),\n",
              " ('epicurious', 0.7949345111846924),\n",
              " ('japanese', 0.793388843536377),\n",
              " ('cuisine', 0.7755702137947083),\n",
              " ('italian', 0.7742248177528381),\n",
              " ('ethnic', 0.7741429805755615),\n",
              " ('seriouseats_com', 0.7709793448448181)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can call the vector of each word\n",
        "model.wv['kettle']"
      ],
      "metadata": {
        "id": "ox6_ykEZk3Cn",
        "outputId": "73212c6c-0190-4647-9093-6c73dda3cda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01251994, -0.02555312, -0.00687722,  0.00985285,  0.0989612 ,\n",
              "       -0.07703198,  0.02115107,  0.1904423 ,  0.08889545, -0.08537651,\n",
              "        0.06746045,  0.00155182,  0.1027201 ,  0.05648083, -0.05895937,\n",
              "       -0.19863664,  0.15604645, -0.07589505, -0.06632858, -0.08751618,\n",
              "        0.09775511,  0.04701078,  0.05630622, -0.00256222, -0.04699665,\n",
              "       -0.10184593, -0.03058753,  0.01046911, -0.08086667, -0.05634516,\n",
              "       -0.08622472,  0.08457261, -0.13320242,  0.1105662 , -0.05405145,\n",
              "        0.13396268,  0.09342658, -0.14760794, -0.03355089, -0.08638977,\n",
              "       -0.05131674,  0.03127664,  0.0241367 , -0.03394893, -0.08779122,\n",
              "        0.14100365, -0.02802504,  0.16016762, -0.01729349,  0.08059856,\n",
              "        0.11174127, -0.01646334, -0.05063391,  0.00230364, -0.06663819,\n",
              "        0.11572168,  0.20512606, -0.00102523, -0.04778711, -0.1137407 ,\n",
              "       -0.07044202,  0.1035508 ,  0.03851005, -0.00163973,  0.01187798,\n",
              "        0.09902862, -0.02715607,  0.15312704, -0.03289685, -0.17224419,\n",
              "        0.01354668, -0.09764047,  0.18510051, -0.15453258,  0.00651452,\n",
              "        0.10578355,  0.02026195,  0.26190725,  0.02147684,  0.09922756,\n",
              "        0.04288562, -0.05245727,  0.03953849,  0.15340939, -0.02457391,\n",
              "        0.05436904, -0.07076535,  0.11035179,  0.15105076,  0.01937523,\n",
              "        0.06396413,  0.17418563,  0.22539577,  0.02641247,  0.07927907,\n",
              "        0.17310491,  0.18815218, -0.05520078, -0.19215286,  0.0678343 ,\n",
              "       -0.03665632, -0.06338829,  0.1528884 ,  0.07551631,  0.05113436,\n",
              "       -0.02150111,  0.02902888, -0.02574497, -0.10493395, -0.09584778,\n",
              "       -0.02244932, -0.0563064 ,  0.06321274,  0.23022896, -0.04525467,\n",
              "        0.04917315,  0.08448515,  0.1645845 ,  0.14134355, -0.20635952,\n",
              "        0.02930024,  0.12941778, -0.00403852, -0.00372376, -0.08873883,\n",
              "        0.05932041, -0.00708631, -0.01714951,  0.02051444,  0.1320759 ,\n",
              "        0.167455  ,  0.24642953,  0.08504954, -0.3118549 , -0.08870099,\n",
              "        0.20648637, -0.00436764,  0.0895735 , -0.09448794, -0.07335531,\n",
              "       -0.0156035 , -0.05753329, -0.02043852, -0.09083162,  0.1260032 ,\n",
              "       -0.05324448, -0.16689113, -0.12758964,  0.00744908,  0.0203558 ,\n",
              "       -0.08408069, -0.18197952, -0.13341595,  0.02138158, -0.06447555,\n",
              "        0.11935345, -0.07667437, -0.17218813, -0.02301678,  0.18020815,\n",
              "       -0.13752095,  0.06885315, -0.19109495, -0.01400504, -0.05043047,\n",
              "       -0.03073638,  0.14030667, -0.04436354,  0.1119108 ,  0.19141933,\n",
              "       -0.1612514 ,  0.01216922,  0.05333281,  0.09160411, -0.02825551,\n",
              "       -0.13773197,  0.07364561, -0.07377969,  0.06486242, -0.19477026,\n",
              "        0.00702653,  0.09014554, -0.15901434, -0.04877228, -0.18473497,\n",
              "       -0.0783987 ,  0.05136071,  0.13561457,  0.0181129 , -0.08460399,\n",
              "        0.14429642, -0.09354407, -0.11877485,  0.13256094,  0.00447155,\n",
              "       -0.1189136 , -0.06263354, -0.07912057,  0.19569287, -0.08621649,\n",
              "       -0.05502068,  0.1750664 ,  0.00066606, -0.2134903 ,  0.04719484,\n",
              "        0.06752593, -0.05177373,  0.09570575, -0.1395214 ,  0.08627849,\n",
              "        0.0191452 ,  0.06699503,  0.10898168, -0.05365306,  0.01059251,\n",
              "       -0.07263128, -0.1369564 , -0.08776786, -0.0902952 , -0.15715304,\n",
              "       -0.14178681,  0.1173223 ,  0.0004514 ,  0.04989961,  0.02743482,\n",
              "        0.01199742,  0.00704103, -0.06155739, -0.04639525, -0.0140062 ,\n",
              "       -0.00616814, -0.11841661, -0.08571502, -0.00504797, -0.19031343,\n",
              "        0.02186856, -0.00521271, -0.00154338,  0.04077179, -0.18080564,\n",
              "        0.02354007,  0.04009657, -0.08885556, -0.01130262,  0.06898782,\n",
              "       -0.2206935 ,  0.03355522,  0.0568976 , -0.02731834, -0.00931913,\n",
              "        0.07443983, -0.06251868, -0.04849549,  0.03121548, -0.1974426 ,\n",
              "       -0.11619064,  0.14108147, -0.09789348, -0.0257503 , -0.0462068 ,\n",
              "       -0.02432759,  0.023878  ,  0.11016935, -0.11766616, -0.11722221,\n",
              "       -0.02306838,  0.12945521,  0.05483745, -0.19091614, -0.02157103,\n",
              "       -0.0808655 ,  0.17083128, -0.04946207, -0.0561187 ,  0.06070397,\n",
              "        0.22330561,  0.11122253,  0.07924522, -0.10638569, -0.03335142,\n",
              "       -0.0600055 ,  0.01399634,  0.08905643,  0.02409576,  0.02780932,\n",
              "        0.13845195, -0.18553904,  0.11255583, -0.00578471, -0.09237415,\n",
              "       -0.07108361,  0.11588162,  0.02352954, -0.07791276,  0.15339357,\n",
              "        0.12178044, -0.03419766, -0.06565344,  0.15447675, -0.20817623],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vectors.shape"
      ],
      "metadata": {
        "id": "-a6llx8p2CkM",
        "outputId": "faac3eba-b285-4889-8c6d-1f21b1d73d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4857, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from here you can ennter key-word dicts for mapping\n",
        "model.wv.key_to_index"
      ],
      "metadata": {
        "id": "fRwJ5SGQ2gNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Word2Vec from disk\n",
        "\n",
        "Let's assume you want to train a word-embeddding model from disk. You downloaded all of Wikipedia or one of the large (multi GB datasets from Huggingface)"
      ],
      "metadata": {
        "id": "FsCIdl8xlBS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open file (not read yet) from disk\n",
        "texts_reddit = open('/content/reddit_r_cooking_sample.jsonl','r')"
      ],
      "metadata": {
        "id": "3gXWAQ-I3HN_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read single line (this will iterate over the lines)\n",
        "texts_reddit.readline()"
      ],
      "metadata": {
        "id": "2MdG_3wLl_eV",
        "outputId": "ef38f515-9d26-43b7-f831-7d6ff140cd36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"text\":\"My Pro 500 is going on 18 years old. Thing is a tank. Just don\\'t drop it on your toe\",\"meta\":{\"section\":\"Cooking\",\"utc\":1518485096}}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode JSON\n",
        "json.loads(texts_reddit.readline())"
      ],
      "metadata": {
        "id": "AnFNpnG1mC9r",
        "outputId": "39cbbdd5-6a4f-421d-f6de-816b0c26707c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'deglazing works ok. but not as well as on a stainless pan. but yes heating and scrubbing with a nylon brush works pretty good too. also i use a wooden utensil.',\n",
              " 'meta': {'section': 'Cooking', 'utc': '1413146528'}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to turn our comments into sentences (tokenize) and preprocess. No need to do on-the-fly preprocessing 15 times\n",
        "For that we create a new file `sentences.txt`, we tokenize our texts and write all sentences as lines into the new file. Using 1-sentence-per-line in TXTs is a common approach."
      ],
      "metadata": {
        "id": "t9etkw1XlcL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need re-open to start from top\n",
        "texts_reddit = open('/content/reddit_r_cooking_sample.jsonl','r')"
      ],
      "metadata": {
        "id": "s2NwEkMAmgGl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open file\n",
        "with open('sentances.txt','w') as f:\n",
        "  for line in texts_reddit: # iterate over the json-lines with comments (alternative to readline())\n",
        "    line = json.loads(line) # decode json\n",
        "    for sent in sent_tokenize(line['text']): # sent-tokenize\n",
        "      f.write(sent) # write sents into the new file\n",
        "      f.write('\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "cCiWGQUH4SwS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is not easy but important and your first step to writing \"real code\".\n",
        "We need to define something that allows us to retrieve our sentences from the stored file one by one (and start from the beginning after the last one).\n",
        "\n",
        "A class with an `__iter__` function can help here. This becomes an iterator that yields them one by one. `yield` is different from `return`. The latter ends an execution and returns the \"overall\" result of a function. `yield` is called repeatedly."
      ],
      "metadata": {
        "id": "nkKp51UjmmSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/sentances.txt\""
      ],
      "metadata": {
        "id": "10YTGlGW8unx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCorpus:\n",
        "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
        "    def __iter__(self):\n",
        "        for line in open(path):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield utils.simple_preprocess(line)"
      ],
      "metadata": {
        "id": "RxpYOJwS5t3C"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try out how that works"
      ],
      "metadata": {
        "id": "TKymLmULoHuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate a corpus object\n",
        "sentences_disk = MyCorpus()"
      ],
      "metadata": {
        "id": "XXFJhLbz6tXF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a generator (similar to list comprehension but on \"stand-by\")\n",
        "test_gen = (a for a in sentences_disk)"
      ],
      "metadata": {
        "id": "ODb8_s_Rnzmt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# every time we call next, it runs one iteration\n",
        "next(test_gen)"
      ],
      "metadata": {
        "id": "CocqDbqrn_YH",
        "outputId": "e5e46f76-d952-4e87-fb5b-94e0a89479ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['some',\n",
              " 'of',\n",
              " 'those',\n",
              " 'grain',\n",
              " 'sausages',\n",
              " 'are',\n",
              " 'really',\n",
              " 'good',\n",
              " 'and',\n",
              " 'you',\n",
              " 'can',\n",
              " 'slice',\n",
              " 'them']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train our Phrases model from the disk-corpus"
      ],
      "metadata": {
        "id": "VTEy_juLoexu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_disk = MyCorpus()"
      ],
      "metadata": {
        "id": "9k1uK2uWoc4n"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_model = Phrases(sentences_disk, min_count=25, threshold=20, connector_words=ENGLISH_CONNECTOR_WORDS)"
      ],
      "metadata": {
        "id": "kt2v8Gm17j13",
        "outputId": "7c579ebc-4e23-4d32-92c1-676835702c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:07:54,089 : INFO : collecting all words and their counts\n",
            "2022-11-01 16:07:54,092 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "2022-11-01 16:07:54,427 : INFO : PROGRESS: at sentence #10000, processed 123637 words and 74036 word types\n",
            "2022-11-01 16:07:54,792 : INFO : PROGRESS: at sentence #20000, processed 245368 words and 129436 word types\n",
            "2022-11-01 16:07:55,133 : INFO : collected 176735 token types (unigram + bigrams) from a corpus of 359868 words and 29445 sentences\n",
            "2022-11-01 16:07:55,136 : INFO : merged Phrases<176735 vocab, min_count=25, threshold=20, max_vocab_size=40000000>\n",
            "2022-11-01 16:07:55,139 : INFO : Phrases lifecycle event {'msg': 'built Phrases<176735 vocab, min_count=25, threshold=20, max_vocab_size=40000000> in 1.05s', 'datetime': '2022-11-01T16:07:55.139108', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for phrase, score in phrase_model.find_phrases(sentences_disk).items():\n",
        "    print(phrase, score)"
      ],
      "metadata": {
        "id": "gNor6m0Z7upC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀🚀🚀\n",
        "**Efficiency** is key when working from disk.\n",
        "Let's preprocess the inputs using simple-prepro and the phrases model.\n",
        "Since we preprocess our sentences into lists we need to store them using json such that we can load them into python objects, not strings"
      ],
      "metadata": {
        "id": "LBMdBRFOu7ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_disk = MyCorpus()"
      ],
      "metadata": {
        "id": "18xzuBc2vSQJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open new file (txt file with json-input)\n",
        "with open('sentances_phrases.txt','w') as f:\n",
        "  for sent in sentences_disk: # iterate over the json-lines with comments (alternative to readline())\n",
        "    f.write(json.dumps(phrase_model[sent])) # write sents into the new file\n",
        "    f.write('\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "7_pN3cEjvMBd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/sentances_phrases.txt'"
      ],
      "metadata": {
        "id": "hnsk-h8Lxc5z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCorpus_processed:\n",
        "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
        "    def __iter__(self):\n",
        "        for line in open(path):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield json.loads(line)"
      ],
      "metadata": {
        "id": "Lf4mls_KwirG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_disk = MyCorpus_processed()"
      ],
      "metadata": {
        "id": "GNIcwrU0x3KE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or we just add it to the training\n",
        "model = Word2Vec(sentences=sentences_disk, \n",
        "                               vector_size=300, \n",
        "                               window=5, \n",
        "                               min_count=5, \n",
        "                               workers=4, \n",
        "                               epochs=15)"
      ],
      "metadata": {
        "id": "eqH5Ap63_RKI",
        "outputId": "2b0a6b90-6105-4850-88aa-7445798da40c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:12:31,547 : INFO : collecting all words and their counts\n",
            "2022-11-01 16:12:31,564 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-11-01 16:12:31,689 : INFO : PROGRESS: at sentence #10000, processed 121743 words, keeping 9863 word types\n",
            "2022-11-01 16:12:31,820 : INFO : PROGRESS: at sentence #20000, processed 241677 words, keeping 13807 word types\n",
            "2022-11-01 16:12:31,961 : INFO : collected 16762 word types from a corpus of 354479 raw words and 29445 sentences\n",
            "2022-11-01 16:12:31,970 : INFO : Creating a fresh vocabulary\n",
            "2022-11-01 16:12:32,024 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4857 unique words (28.98% of original 16762, drops 11905)', 'datetime': '2022-11-01T16:12:32.023991', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:12:32,027 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 335749 word corpus (94.72% of original 354479, drops 18730)', 'datetime': '2022-11-01T16:12:32.027503', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:12:32,098 : INFO : deleting the raw counts dictionary of 16762 items\n",
            "2022-11-01 16:12:32,102 : INFO : sample=0.001 downsamples 55 most-common words\n",
            "2022-11-01 16:12:32,113 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 258903.2163278526 word corpus (77.1%% of prior 335749)', 'datetime': '2022-11-01T16:12:32.113295', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:12:32,266 : INFO : estimated required memory for 4857 words and 300 dimensions: 14085300 bytes\n",
            "2022-11-01 16:12:32,280 : INFO : resetting layer weights\n",
            "2022-11-01 16:12:32,301 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-01T16:12:32.301087', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'build_vocab'}\n",
            "2022-11-01 16:12:32,310 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 4857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-11-01T16:12:32.310894', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-11-01 16:12:33,321 : INFO : EPOCH 0 - PROGRESS: at 87.33% examples, 225851 words/s, in_qsize 0, out_qsize 1\n",
            "2022-11-01 16:12:33,401 : INFO : EPOCH 0: training on 354479 raw words (258735 effective words) took 1.1s, 239350 effective words/s\n",
            "2022-11-01 16:12:34,463 : INFO : EPOCH 1 - PROGRESS: at 56.05% examples, 138380 words/s, in_qsize 4, out_qsize 0\n",
            "2022-11-01 16:12:34,928 : INFO : EPOCH 1: training on 354479 raw words (258945 effective words) took 1.5s, 170217 effective words/s\n",
            "2022-11-01 16:12:35,759 : INFO : EPOCH 2: training on 354479 raw words (258582 effective words) took 0.8s, 326409 effective words/s\n",
            "2022-11-01 16:12:36,477 : INFO : EPOCH 3: training on 354479 raw words (258735 effective words) took 0.7s, 363060 effective words/s\n",
            "2022-11-01 16:12:37,182 : INFO : EPOCH 4: training on 354479 raw words (258583 effective words) took 0.7s, 369130 effective words/s\n",
            "2022-11-01 16:12:38,036 : INFO : EPOCH 5: training on 354479 raw words (259116 effective words) took 0.8s, 305822 effective words/s\n",
            "2022-11-01 16:12:38,788 : INFO : EPOCH 6: training on 354479 raw words (258841 effective words) took 0.7s, 346965 effective words/s\n",
            "2022-11-01 16:12:39,524 : INFO : EPOCH 7: training on 354479 raw words (258742 effective words) took 0.7s, 353548 effective words/s\n",
            "2022-11-01 16:12:40,294 : INFO : EPOCH 8: training on 354479 raw words (259236 effective words) took 0.8s, 339118 effective words/s\n",
            "2022-11-01 16:12:41,021 : INFO : EPOCH 9: training on 354479 raw words (258709 effective words) took 0.7s, 358632 effective words/s\n",
            "2022-11-01 16:12:41,764 : INFO : EPOCH 10: training on 354479 raw words (258663 effective words) took 0.7s, 352449 effective words/s\n",
            "2022-11-01 16:12:42,668 : INFO : EPOCH 11: training on 354479 raw words (258956 effective words) took 0.9s, 287857 effective words/s\n",
            "2022-11-01 16:12:43,402 : INFO : EPOCH 12: training on 354479 raw words (259010 effective words) took 0.7s, 380046 effective words/s\n",
            "2022-11-01 16:12:44,099 : INFO : EPOCH 13: training on 354479 raw words (258614 effective words) took 0.7s, 374913 effective words/s\n",
            "2022-11-01 16:12:44,814 : INFO : EPOCH 14: training on 354479 raw words (258765 effective words) took 0.7s, 364182 effective words/s\n",
            "2022-11-01 16:12:44,817 : INFO : Word2Vec lifecycle event {'msg': 'training on 5317185 raw words (3882232 effective words) took 12.5s, 310619 effective words/s', 'datetime': '2022-11-01T16:12:44.817395', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-11-01 16:12:44,821 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4857, vector_size=300, alpha=0.025>', 'datetime': '2022-11-01T16:12:44.821522', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('parsley')"
      ],
      "metadata": {
        "id": "wkIQ0f-HBQ29",
        "outputId": "b7b9b0e6-68ae-438a-d8e6-45740300fb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('thyme', 0.9535082578659058),\n",
              " ('oregano', 0.949043333530426),\n",
              " ('basil', 0.9457336068153381),\n",
              " ('coriander', 0.9394667148590088),\n",
              " ('scallions', 0.9386905431747437),\n",
              " ('salt_pepper', 0.933724582195282),\n",
              " ('ginger', 0.9317354559898376),\n",
              " ('rosemary', 0.9297377467155457),\n",
              " ('minced', 0.9290481209754944),\n",
              " ('cumin', 0.9265708923339844)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: Training FastText\n",
        "\n",
        "training of FastText is syntax-wise the same.\n",
        "There are a few other paras that you can tune"
      ],
      "metadata": {
        "id": "_jDW5gJgt7wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fasttext = FastText(sentences = sentences_disk, \n",
        "                          vector_size=300, \n",
        "                          window=8, \n",
        "                          min_count=5, \n",
        "                          workers=4, \n",
        "                          epochs=15)"
      ],
      "metadata": {
        "id": "v4CzDHe3APOb",
        "outputId": "d69f7ba4-f68a-4a3f-fecc-2d8964254281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:14:46,645 : INFO : collecting all words and their counts\n",
            "2022-11-01 16:14:46,649 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-11-01 16:14:46,724 : INFO : PROGRESS: at sentence #10000, processed 121743 words, keeping 9863 word types\n",
            "2022-11-01 16:14:46,794 : INFO : PROGRESS: at sentence #20000, processed 241677 words, keeping 13807 word types\n",
            "2022-11-01 16:14:46,861 : INFO : collected 16762 word types from a corpus of 354479 raw words and 29445 sentences\n",
            "2022-11-01 16:14:46,866 : INFO : Creating a fresh vocabulary\n",
            "2022-11-01 16:14:46,899 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 retains 4857 unique words (28.98% of original 16762, drops 11905)', 'datetime': '2022-11-01T16:14:46.898992', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:14:46,901 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 leaves 335749 word corpus (94.72% of original 354479, drops 18730)', 'datetime': '2022-11-01T16:14:46.901105', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:14:46,941 : INFO : deleting the raw counts dictionary of 16762 items\n",
            "2022-11-01 16:14:46,943 : INFO : sample=0.001 downsamples 55 most-common words\n",
            "2022-11-01 16:14:46,950 : INFO : FastText lifecycle event {'msg': 'downsampling leaves estimated 258903.2163278526 word corpus (77.1%% of prior 335749)', 'datetime': '2022-11-01T16:14:46.950151', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-11-01 16:14:47,048 : INFO : estimated required memory for 4857 words, 2000000 buckets and 300 dimensions: 2414943496 bytes\n",
            "2022-11-01 16:14:47,050 : INFO : resetting layer weights\n",
            "2022-11-01 16:14:52,275 : INFO : FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-01T16:14:52.275187', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'build_vocab'}\n",
            "2022-11-01 16:14:52,284 : INFO : FastText lifecycle event {'msg': 'training model with 4 workers on 4857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-11-01T16:14:52.284471', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-11-01 16:14:53,344 : INFO : EPOCH 0 - PROGRESS: at 17.00% examples, 42316 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:14:55,512 : INFO : EPOCH 0 - PROGRESS: at 25.31% examples, 20487 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:14:56,530 : INFO : EPOCH 0 - PROGRESS: at 36.23% examples, 22487 words/s, in_qsize 7, out_qsize 1\n",
            "2022-11-01 16:14:57,942 : INFO : EPOCH 0 - PROGRESS: at 56.05% examples, 25960 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:14:59,002 : INFO : EPOCH 0 - PROGRESS: at 90.18% examples, 34910 words/s, in_qsize 4, out_qsize 0\n",
            "2022-11-01 16:14:59,149 : INFO : EPOCH 0: training on 354479 raw words (258905 effective words) took 6.8s, 37853 effective words/s\n",
            "2022-11-01 16:15:00,182 : INFO : EPOCH 1 - PROGRESS: at 27.93% examples, 70921 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:01,255 : INFO : EPOCH 1 - PROGRESS: at 58.70% examples, 73085 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:15:02,258 : INFO : EPOCH 1 - PROGRESS: at 94.43% examples, 78692 words/s, in_qsize 2, out_qsize 1\n",
            "2022-11-01 16:15:02,304 : INFO : EPOCH 1: training on 354479 raw words (258786 effective words) took 3.2s, 82144 effective words/s\n",
            "2022-11-01 16:15:03,318 : INFO : EPOCH 2 - PROGRESS: at 27.93% examples, 72584 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:04,463 : INFO : EPOCH 2 - PROGRESS: at 64.58% examples, 78192 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:15:05,388 : INFO : EPOCH 2: training on 354479 raw words (259098 effective words) took 3.1s, 84214 effective words/s\n",
            "2022-11-01 16:15:06,423 : INFO : EPOCH 3 - PROGRESS: at 25.31% examples, 63751 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:07,489 : INFO : EPOCH 3 - PROGRESS: at 58.70% examples, 73307 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:08,541 : INFO : EPOCH 3 - PROGRESS: at 97.16% examples, 79973 words/s, in_qsize 1, out_qsize 1\n",
            "2022-11-01 16:15:08,552 : INFO : EPOCH 3: training on 354479 raw words (258999 effective words) took 3.2s, 81997 effective words/s\n",
            "2022-11-01 16:15:09,773 : INFO : EPOCH 4 - PROGRESS: at 25.12% examples, 53977 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:10,846 : INFO : EPOCH 4 - PROGRESS: at 58.62% examples, 67021 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:11,830 : INFO : EPOCH 4: training on 354479 raw words (258879 effective words) took 3.3s, 79124 effective words/s\n",
            "2022-11-01 16:15:12,846 : INFO : EPOCH 5 - PROGRESS: at 25.31% examples, 64878 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:15:13,857 : INFO : EPOCH 5 - PROGRESS: at 55.71% examples, 72275 words/s, in_qsize 6, out_qsize 1\n",
            "2022-11-01 16:15:14,882 : INFO : EPOCH 5 - PROGRESS: at 93.09% examples, 79051 words/s, in_qsize 3, out_qsize 1\n",
            "2022-11-01 16:15:14,955 : INFO : EPOCH 5: training on 354479 raw words (258918 effective words) took 3.1s, 82979 effective words/s\n",
            "2022-11-01 16:15:15,992 : INFO : EPOCH 6 - PROGRESS: at 25.31% examples, 63591 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:17,020 : INFO : EPOCH 6 - PROGRESS: at 58.62% examples, 74477 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:15:18,033 : INFO : EPOCH 6 - PROGRESS: at 90.20% examples, 75951 words/s, in_qsize 4, out_qsize 0\n",
            "2022-11-01 16:15:18,169 : INFO : EPOCH 6: training on 354479 raw words (258573 effective words) took 3.2s, 80599 effective words/s\n",
            "2022-11-01 16:15:19,282 : INFO : EPOCH 7 - PROGRESS: at 27.93% examples, 66212 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:20,401 : INFO : EPOCH 7 - PROGRESS: at 61.61% examples, 72249 words/s, in_qsize 7, out_qsize 1\n",
            "2022-11-01 16:15:21,347 : INFO : EPOCH 7: training on 354479 raw words (258868 effective words) took 3.2s, 81636 effective words/s\n",
            "2022-11-01 16:15:22,490 : INFO : EPOCH 8 - PROGRESS: at 25.31% examples, 57634 words/s, in_qsize 8, out_qsize 0\n",
            "2022-11-01 16:15:23,498 : INFO : EPOCH 8 - PROGRESS: at 58.70% examples, 71533 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:24,506 : INFO : EPOCH 8 - PROGRESS: at 97.16% examples, 79795 words/s, in_qsize 1, out_qsize 1\n",
            "2022-11-01 16:15:24,540 : INFO : EPOCH 8: training on 354479 raw words (258991 effective words) took 3.2s, 81221 effective words/s\n",
            "2022-11-01 16:15:25,790 : INFO : EPOCH 9 - PROGRESS: at 27.93% examples, 58642 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:26,799 : INFO : EPOCH 9 - PROGRESS: at 61.66% examples, 71411 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:27,770 : INFO : EPOCH 9: training on 354479 raw words (258860 effective words) took 3.2s, 80335 effective words/s\n",
            "2022-11-01 16:15:28,942 : INFO : EPOCH 10 - PROGRESS: at 28.00% examples, 62421 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:29,978 : INFO : EPOCH 10 - PROGRESS: at 61.61% examples, 72942 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:30,931 : INFO : EPOCH 10: training on 354479 raw words (258958 effective words) took 3.2s, 82041 effective words/s\n",
            "2022-11-01 16:15:31,946 : INFO : EPOCH 11 - PROGRESS: at 25.31% examples, 64881 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:32,985 : INFO : EPOCH 11 - PROGRESS: at 53.05% examples, 67753 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:34,009 : INFO : EPOCH 11 - PROGRESS: at 84.53% examples, 71351 words/s, in_qsize 5, out_qsize 1\n",
            "2022-11-01 16:15:34,258 : INFO : EPOCH 11: training on 354479 raw words (258889 effective words) took 3.3s, 77931 effective words/s\n",
            "2022-11-01 16:15:35,289 : INFO : EPOCH 12 - PROGRESS: at 19.56% examples, 49860 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:36,409 : INFO : EPOCH 12 - PROGRESS: at 50.41% examples, 61342 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:37,440 : INFO : EPOCH 12 - PROGRESS: at 84.42% examples, 68983 words/s, in_qsize 6, out_qsize 0\n",
            "2022-11-01 16:15:37,727 : INFO : EPOCH 12: training on 354479 raw words (258634 effective words) took 3.5s, 74745 effective words/s\n",
            "2022-11-01 16:15:38,854 : INFO : EPOCH 13 - PROGRESS: at 28.14% examples, 64856 words/s, in_qsize 6, out_qsize 1\n",
            "2022-11-01 16:15:39,889 : INFO : EPOCH 13 - PROGRESS: at 64.58% examples, 78037 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:40,760 : INFO : EPOCH 13: training on 354479 raw words (258663 effective words) took 3.0s, 85406 effective words/s\n",
            "2022-11-01 16:15:41,822 : INFO : EPOCH 14 - PROGRESS: at 27.93% examples, 69012 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:42,842 : INFO : EPOCH 14 - PROGRESS: at 55.71% examples, 70337 words/s, in_qsize 7, out_qsize 0\n",
            "2022-11-01 16:15:43,847 : INFO : EPOCH 14 - PROGRESS: at 90.20% examples, 75816 words/s, in_qsize 4, out_qsize 0\n",
            "2022-11-01 16:15:43,960 : INFO : EPOCH 14: training on 354479 raw words (258911 effective words) took 3.2s, 81026 effective words/s\n",
            "2022-11-01 16:15:43,962 : INFO : FastText lifecycle event {'msg': 'training on 5317185 raw words (3882932 effective words) took 51.7s, 75149 effective words/s', 'datetime': '2022-11-01T16:15:43.962165', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-11-01 16:15:44,173 : INFO : FastText lifecycle event {'params': 'FastText<vocab=4857, vector_size=300, alpha=0.025>', 'datetime': '2022-11-01T16:15:44.173274', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fasttext.wv.most_similar('knife')"
      ],
      "metadata": {
        "id": "s8hXrlwZAoyw",
        "outputId": "aa30bf2f-bd26-4307-fa12-ae54bf4a3fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wife', 0.8343323469161987),\n",
              " ('life', 0.7492570877075195),\n",
              " ('hi', 0.710981011390686),\n",
              " ('kitchenaid', 0.7067800760269165),\n",
              " ('environment', 0.6972745060920715),\n",
              " ('sharp', 0.6842833161354065),\n",
              " ('sharpen', 0.6736289858818054),\n",
              " ('iron', 0.6505971550941467),\n",
              " ('profession', 0.6477628350257874),\n",
              " ('knives', 0.6448550820350647)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['powder']"
      ],
      "metadata": {
        "id": "IZtg7Ep3BMm4",
        "outputId": "2ed29383-d15c-4d3a-b9be-992b448c433f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.51166274e-02,  5.88585377e-01,  1.34537190e-01,  9.33914423e-01,\n",
              "        1.46900594e-01,  3.94622058e-01,  4.42739964e-01, -4.24239412e-03,\n",
              "        3.70113790e-01,  2.35815242e-01, -3.90817434e-01, -2.70081982e-02,\n",
              "        5.96169114e-01, -4.83595043e-01,  9.03829187e-02,  3.97176534e-01,\n",
              "       -1.12596326e-01,  2.07230151e-01, -6.33924380e-02,  2.67278939e-01,\n",
              "        1.22167774e-01,  5.55733144e-01, -2.37716556e-01,  3.42581809e-01,\n",
              "        2.23291785e-01, -3.79723012e-01,  3.12910825e-01, -7.85174370e-01,\n",
              "       -5.02312541e-01, -2.88786292e-01, -4.40250129e-01, -2.30905548e-01,\n",
              "       -4.76674467e-01, -3.92863482e-01,  1.81958880e-02, -1.97329924e-01,\n",
              "       -7.22720325e-02, -2.27187008e-01,  3.19248646e-01,  2.77612060e-01,\n",
              "        5.50923467e-01,  6.59968913e-01, -4.59815890e-01,  1.37116745e-01,\n",
              "       -3.07883695e-03, -4.06670384e-02, -1.37955789e-02,  4.45950627e-01,\n",
              "        3.25371712e-01,  1.26919985e-01, -1.41771212e-01, -3.95996094e-01,\n",
              "       -5.44713259e-01, -1.89342633e-01, -8.02612603e-01,  4.35424954e-01,\n",
              "        8.29452395e-01, -8.55951548e-01,  1.06069839e+00, -1.37520105e-01,\n",
              "       -1.27099681e+00,  5.75725317e-01, -6.33002222e-01,  2.79863417e-01,\n",
              "        1.02335382e+00, -5.16926408e-01,  2.71746181e-02,  3.40935081e-01,\n",
              "        3.28279496e-03, -4.39213783e-01, -2.63708562e-01,  1.93491563e-01,\n",
              "        7.92600691e-01, -9.62122560e-01, -4.21045721e-01, -3.81576605e-02,\n",
              "       -6.10671163e-01,  1.76468760e-01, -2.53652006e-01, -4.63124588e-02,\n",
              "       -4.59937841e-01, -7.24532247e-01, -6.28485620e-01, -3.89701486e-01,\n",
              "       -2.73893446e-01,  3.61770332e-01, -5.34310937e-01,  6.78069964e-02,\n",
              "        4.02117938e-01, -2.31726691e-01,  5.59243653e-03,  2.36367822e-01,\n",
              "        2.20166028e-01, -7.74435848e-02,  4.59821761e-01,  9.26134706e-01,\n",
              "        1.10681498e+00, -4.26089019e-01, -1.14117913e-01,  4.35757935e-01,\n",
              "        2.84276187e-01,  6.23436987e-01,  2.54742473e-01,  1.83659643e-01,\n",
              "        9.71764863e-01,  4.53507334e-01,  8.14848691e-02,  1.43713921e-01,\n",
              "       -2.40343168e-01,  1.93288654e-01, -5.38826525e-01, -1.65034235e-01,\n",
              "       -6.38220847e-01,  1.32880116e+00, -2.59808898e-01, -3.05979997e-01,\n",
              "       -3.07224363e-01,  6.28516823e-02,  5.09215772e-01, -2.61089832e-01,\n",
              "        2.35470861e-01, -5.26066720e-02,  4.28279608e-01,  2.70204425e-01,\n",
              "       -2.79931575e-01,  5.41328430e-01,  4.00978327e-01, -4.81793076e-01,\n",
              "       -1.29969776e-01, -2.05601871e-01,  1.86672717e-01,  2.38152146e-01,\n",
              "        3.25121582e-01, -8.34911764e-01,  3.42268974e-01,  4.34217900e-02,\n",
              "        3.93526107e-01, -1.90985605e-01, -1.02458704e+00, -6.23267472e-01,\n",
              "       -1.00545913e-01, -6.83817565e-02,  6.41150832e-01,  6.19626582e-01,\n",
              "        8.12935591e-01,  6.83205351e-02, -1.27114511e+00, -5.91632783e-01,\n",
              "        1.75960541e-01, -6.21152818e-01,  3.02927852e-01, -8.26390207e-01,\n",
              "       -6.47338629e-01,  2.50281990e-01, -2.30173096e-02, -3.43803287e-01,\n",
              "       -6.13436289e-02,  3.60270850e-02,  5.09528279e-01, -5.74368313e-02,\n",
              "        1.57170892e-01,  4.49562937e-01,  3.68327424e-02,  8.35651755e-01,\n",
              "       -3.81058902e-01, -1.48666099e-01,  4.91917610e-01, -3.69980186e-01,\n",
              "        2.08365411e-01,  7.05769956e-01,  2.84988850e-01,  2.98524886e-01,\n",
              "        4.95487392e-01,  2.09069610e-01,  7.01636553e-01,  3.68202060e-01,\n",
              "       -2.23225251e-01,  4.40551668e-01, -4.75860000e-01, -3.62007290e-01,\n",
              "        2.51398951e-01, -9.66930032e-01, -4.59049016e-01, -6.88624620e-01,\n",
              "        3.92489843e-02, -1.95778102e-01,  5.38981408e-02, -8.60513270e-01,\n",
              "        8.75395238e-02, -4.90356326e-01,  4.07379657e-01, -4.18392062e-01,\n",
              "        3.70071143e-01, -8.37782443e-01, -4.91142094e-01, -3.72926563e-01,\n",
              "       -5.44522107e-01, -1.12068847e-01,  4.47982043e-01, -3.77152562e-01,\n",
              "       -6.37015820e-01,  8.25394243e-02, -7.30399564e-02, -2.00324610e-01,\n",
              "       -1.61731720e-01, -1.26463383e-01,  1.64002687e-01, -2.77480006e-01,\n",
              "       -3.65307301e-01, -1.24864094e-02, -4.22769994e-01,  1.39318900e-02,\n",
              "       -1.07425368e+00,  6.22883558e-01,  1.71811715e-01, -1.02996182e+00,\n",
              "       -7.81635344e-02,  1.41912192e-01, -1.59140319e-01, -2.17707470e-01,\n",
              "       -2.97525078e-01, -2.03021392e-01, -7.90076256e-02,  1.33864909e-01,\n",
              "       -3.79824579e-01, -6.89189196e-01, -8.45177889e-01, -1.53723657e-01,\n",
              "        2.95948441e-04, -1.97515473e-01,  4.82402235e-01, -2.08456125e-02,\n",
              "       -2.52154768e-01, -6.07107699e-01, -2.03945220e-01, -1.34953409e-02,\n",
              "        3.96506399e-01,  2.26428926e-01, -4.81141567e-01, -5.42599797e-01,\n",
              "        2.16982156e-01, -6.37685228e-03,  1.24108240e-01, -3.27205151e-01,\n",
              "       -1.66818529e-01, -1.29272575e-02,  9.94103178e-02,  5.85018933e-01,\n",
              "       -1.50231551e-02,  2.67913371e-01,  5.02600014e-01, -6.01893663e-01,\n",
              "        1.04556024e-01, -8.06607530e-02, -3.86660427e-01, -1.62410289e-01,\n",
              "        4.88770097e-01,  6.04817271e-01, -3.33003432e-01,  4.18824196e-01,\n",
              "        2.68520176e-01,  1.75773531e-01, -4.32307005e-01, -6.34186506e-01,\n",
              "       -4.81691271e-01, -2.28394136e-01, -3.42150092e-01, -3.88268411e-01,\n",
              "        3.74068767e-02, -1.80363253e-01, -3.23839039e-01,  2.97912538e-01,\n",
              "       -9.14489925e-01, -2.32203230e-01,  1.97928399e-01,  5.07779745e-03,\n",
              "        2.60193080e-01,  4.30316895e-01,  4.87423211e-01, -1.49753958e-01,\n",
              "        9.34149995e-02,  3.79453897e-02,  7.74702311e-01,  7.03549236e-02,\n",
              "        3.58894557e-01,  5.08065403e-01,  2.21486643e-01,  4.72984552e-01,\n",
              "        1.02156512e-01,  3.18685174e-01, -7.10651755e-01, -1.35731265e-01,\n",
              "        1.05125397e-01, -2.47840330e-01,  4.98799562e-01,  2.66876996e-01,\n",
              "       -1.22855142e-01, -1.14908576e+00,  8.28410447e-01, -3.29616994e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Word-Vectors\n",
        "\n",
        "now that we have our Word-vectors we should be able to reduce their dimensionality to explore visually"
      ],
      "metadata": {
        "id": "jPPdBczQywEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn -q"
      ],
      "metadata": {
        "id": "vp5ja48Oy26Q",
        "outputId": "495d1049-3dae-4174-9342-51bcb7cd760d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 88 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.0 MB/s \n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import umap\n",
        "import altair as alt"
      ],
      "metadata": {
        "id": "QQrstZdjy4rz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# picking 2000 random vectors from the W2V model\n",
        "idx = random.sample(range(len(model.wv.vectors)), 2000)"
      ],
      "metadata": {
        "id": "vvkLXXK2MMtx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating 2D reduction\n",
        "umap_reducer = umap.UMAP(random_state=42, n_components=2)\n",
        "embeddings = umap_reducer.fit_transform(model.wv.vectors[idx])"
      ],
      "metadata": {
        "id": "8Xhd-NA7Kwrm"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df for plot\n",
        "df_plot = pd.DataFrame(embeddings, columns=['x','y'])"
      ],
      "metadata": {
        "id": "cmrRGZ3ZMsgy"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vector-labels\n",
        "labels = [model.wv.index_to_key[ix] for ix in idx]"
      ],
      "metadata": {
        "id": "QAboNRJD0_b0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot['labels'] = labels"
      ],
      "metadata": {
        "id": "bWGbN-FyMvPK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "alt.Chart(df_plot).mark_circle(size=60).encode(\n",
        "    x='x',\n",
        "    y='y',\n",
        "    tooltip=['labels']\n",
        ").properties(\n",
        "    width=800,\n",
        "    height=600\n",
        ").interactive()"
      ],
      "metadata": {
        "id": "miYjcUAhM_tk",
        "outputId": "1eb9b700-2bfd-41f6-9b02-8b8f599c6994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-a65e239a833648eca7940b5ea4eefaaa\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-a65e239a833648eca7940b5ea4eefaaa\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-a65e239a833648eca7940b5ea4eefaaa\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-062eeac72df1cba15eac0f0e81342f98\"}, \"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"tooltip\": [{\"field\": \"labels\", \"type\": \"nominal\"}], \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"height\": 600, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-062eeac72df1cba15eac0f0e81342f98\": [{\"x\": 4.684142589569092, \"y\": 5.3917951583862305, \"labels\": \"liquor\"}, {\"x\": 6.179241180419922, \"y\": 4.627119064331055, \"labels\": \"sub\"}, {\"x\": 5.888963222503662, \"y\": 6.713572978973389, \"labels\": \"opportunity\"}, {\"x\": 6.230129241943359, \"y\": 4.396541118621826, \"labels\": \"latin\"}, {\"x\": 0.5447621941566467, \"y\": 4.332406997680664, \"labels\": \"cinnamon\"}, {\"x\": 7.829653263092041, \"y\": 4.873239994049072, \"labels\": \"weekend\"}, {\"x\": 5.504402160644531, \"y\": 5.09194803237915, \"labels\": \"menus\"}, {\"x\": 4.073894023895264, \"y\": 5.835939407348633, \"labels\": \"colour\"}, {\"x\": 6.037709712982178, \"y\": 6.2547688484191895, \"labels\": \"whetstone\"}, {\"x\": 6.32983922958374, \"y\": 4.867985725402832, \"labels\": \"details\"}, {\"x\": 7.5838398933410645, \"y\": 6.291959285736084, \"labels\": \"considered\"}, {\"x\": 6.5759968757629395, \"y\": 6.862242221832275, \"labels\": \"surely\"}, {\"x\": 7.737545967102051, \"y\": 5.399362087249756, \"labels\": \"childhood\"}, {\"x\": 8.567253112792969, \"y\": 7.4065260887146, \"labels\": \"show\"}, {\"x\": 5.030755519866943, \"y\": 6.018409252166748, \"labels\": \"pale\"}, {\"x\": 8.772858619689941, \"y\": 6.066452503204346, \"labels\": \"thank_you\"}, {\"x\": 3.112837791442871, \"y\": 6.097860813140869, \"labels\": \"poured\"}, {\"x\": 6.719964027404785, \"y\": 3.6139118671417236, \"labels\": \"message\"}, {\"x\": 7.114561557769775, \"y\": 7.710246562957764, \"labels\": \"anything\"}, {\"x\": 6.553798675537109, \"y\": 5.3970561027526855, \"labels\": \"diet\"}, {\"x\": 6.078505039215088, \"y\": 3.587671995162964, \"labels\": \"horse\"}, {\"x\": 8.168377876281738, \"y\": 6.060636043548584, \"labels\": \"response\"}, {\"x\": 3.419022560119629, \"y\": 6.883437156677246, \"labels\": \"washing\"}, {\"x\": 4.177925109863281, \"y\": 7.455292701721191, \"labels\": \"weight\"}, {\"x\": 2.5312693119049072, \"y\": 7.336062431335449, \"labels\": \"turning\"}, {\"x\": 6.6312761306762695, \"y\": 6.619373798370361, \"labels\": \"pronounced\"}, {\"x\": 5.5387187004089355, \"y\": 8.208759307861328, \"labels\": \"choose\"}, {\"x\": 7.75849723815918, \"y\": 5.923277378082275, \"labels\": \"michelin\"}, {\"x\": 4.983945846557617, \"y\": 5.172558784484863, \"labels\": \"taiwan\"}, {\"x\": 8.56863021850586, \"y\": 7.2119975090026855, \"labels\": \"looks\"}, {\"x\": 3.9460227489471436, \"y\": 5.836809158325195, \"labels\": \"natural\"}, {\"x\": 5.1548895835876465, \"y\": 5.165409088134766, \"labels\": \"difference_between\"}, {\"x\": 7.0033440589904785, \"y\": 3.163548707962036, \"labels\": \"gordon\"}, {\"x\": 4.827305316925049, \"y\": 6.077247142791748, \"labels\": \"smokiness\"}, {\"x\": 4.649071216583252, \"y\": 5.914018154144287, \"labels\": \"elements\"}, {\"x\": 6.837965965270996, \"y\": 3.9500207901000977, \"labels\": \"dishes\"}, {\"x\": 6.3692626953125, \"y\": 7.223932266235352, \"labels\": \"suck\"}, {\"x\": 6.653205394744873, \"y\": 7.638766288757324, \"labels\": \"just\"}, {\"x\": 8.177422523498535, \"y\": 7.6502766609191895, \"labels\": \"think\"}, {\"x\": 6.706939697265625, \"y\": 3.9412736892700195, \"labels\": \"different\"}, {\"x\": 3.53908634185791, \"y\": 5.089297771453857, \"labels\": \"goods\"}, {\"x\": 4.259853363037109, \"y\": 5.320101261138916, \"labels\": \"strong\"}, {\"x\": 7.8097920417785645, \"y\": 6.875229835510254, \"labels\": \"almost\"}, {\"x\": 4.394637584686279, \"y\": 5.57636022567749, \"labels\": \"greasy\"}, {\"x\": 5.270569324493408, \"y\": 6.0265679359436035, \"labels\": \"habit\"}, {\"x\": 1.0373605489730835, \"y\": 4.451132297515869, \"labels\": \"leaf\"}, {\"x\": 4.897604465484619, \"y\": 8.345281600952148, \"labels\": \"turns\"}, {\"x\": 4.906152248382568, \"y\": 5.775365829467773, \"labels\": \"sanitary\"}, {\"x\": 6.718796253204346, \"y\": 5.656299114227295, \"labels\": \"photo\"}, {\"x\": 6.70764684677124, \"y\": 5.107054233551025, \"labels\": \"familiar\"}, {\"x\": 2.748091220855713, \"y\": 5.087477684020996, \"labels\": \"popcorn\"}, {\"x\": 3.015472888946533, \"y\": 6.620950698852539, \"labels\": \"placing\"}, {\"x\": 7.372270584106445, \"y\": 5.973135471343994, \"labels\": \"attention\"}, {\"x\": 5.389326095581055, \"y\": 8.559164047241211, \"labels\": \"get\"}, {\"x\": 4.235145568847656, \"y\": 5.594681739807129, \"labels\": \"watery\"}, {\"x\": 8.714764595031738, \"y\": 6.531425952911377, \"labels\": \"saw\"}, {\"x\": 1.9327746629714966, \"y\": 3.8110291957855225, \"labels\": \"burgers\"}, {\"x\": 1.920578956604004, \"y\": 5.404281139373779, \"labels\": \"package\"}, {\"x\": 3.733440399169922, \"y\": 5.081358432769775, \"labels\": \"charred\"}, {\"x\": 3.170081377029419, \"y\": 7.667201042175293, \"labels\": \"pressure\"}, {\"x\": 3.058985948562622, \"y\": 6.700647354125977, \"labels\": \"cap\"}, {\"x\": 6.9505510330200195, \"y\": 6.877613067626953, \"labels\": \"recall\"}, {\"x\": 1.9445807933807373, \"y\": 5.464463233947754, \"labels\": \"cube\"}, {\"x\": 5.625946521759033, \"y\": 4.172983169555664, \"labels\": \"alternative\"}, {\"x\": 2.1568679809570312, \"y\": 3.795407295227051, \"labels\": \"steak\"}, {\"x\": 6.56835412979126, \"y\": 6.176874160766602, \"labels\": \"discussion\"}, {\"x\": 1.7223074436187744, \"y\": 5.249452114105225, \"labels\": \"melted\"}, {\"x\": 7.276641845703125, \"y\": 4.558526515960693, \"labels\": \"areas\"}, {\"x\": 7.750115394592285, \"y\": 7.425311088562012, \"labels\": \"versatile\"}, {\"x\": 4.167489528656006, \"y\": 6.174258708953857, \"labels\": \"molecules\"}, {\"x\": 8.046298027038574, \"y\": 4.349160671234131, \"labels\": \"minimum\"}, {\"x\": 2.3887665271759033, \"y\": 3.4835145473480225, \"labels\": \"scrambled_eggs\"}, {\"x\": 7.116061210632324, \"y\": 6.435981750488281, \"labels\": \"ignorant\"}, {\"x\": 8.154672622680664, \"y\": 7.069218635559082, \"labels\": \"awesome\"}, {\"x\": 4.520477294921875, \"y\": 4.31696081161499, \"labels\": \"stocks\"}, {\"x\": 3.8101038932800293, \"y\": 7.537356853485107, \"labels\": \"reach\"}, {\"x\": 8.852494239807129, \"y\": 6.252866268157959, \"labels\": \"guy\"}, {\"x\": 2.8970787525177, \"y\": 4.645456790924072, \"labels\": \"whipping\"}, {\"x\": 7.907614231109619, \"y\": 6.683908939361572, \"labels\": \"gosh\"}, {\"x\": 6.242147445678711, \"y\": 6.18621826171875, \"labels\": \"blowing\"}, {\"x\": 1.6340720653533936, \"y\": 4.394717216491699, \"labels\": \"drained\"}, {\"x\": 3.3671329021453857, \"y\": 6.232327938079834, \"labels\": \"saran\"}, {\"x\": 6.388648509979248, \"y\": 8.014148712158203, \"labels\": \"complain\"}, {\"x\": 3.958160877227783, \"y\": 6.700681209564209, \"labels\": \"body\"}, {\"x\": 7.3299336433410645, \"y\": 4.863597393035889, \"labels\": \"label\"}, {\"x\": 5.720032691955566, \"y\": 5.684158802032471, \"labels\": \"species\"}, {\"x\": 7.319849014282227, \"y\": 4.035608768463135, \"labels\": \"victorinox\"}, {\"x\": 5.553050994873047, \"y\": 3.9912829399108887, \"labels\": \"heavenly\"}, {\"x\": 7.4393486976623535, \"y\": 5.683430194854736, \"labels\": \"trick\"}, {\"x\": 5.5659379959106445, \"y\": 5.842329978942871, \"labels\": \"asia\"}, {\"x\": 7.4667463302612305, \"y\": 6.850853443145752, \"labels\": \"entertaining\"}, {\"x\": 4.359554290771484, \"y\": 6.488809585571289, \"labels\": \"volume\"}, {\"x\": 6.961745262145996, \"y\": 4.820423603057861, \"labels\": \"specialty\"}, {\"x\": 2.859588861465454, \"y\": 3.3035545349121094, \"labels\": \"tacos\"}, {\"x\": 5.978215217590332, \"y\": 7.4911603927612305, \"labels\": \"consuming\"}, {\"x\": 5.834231853485107, \"y\": 8.386015892028809, \"labels\": \"avoid\"}, {\"x\": 5.244118690490723, \"y\": 7.897026538848877, \"labels\": \"replace\"}, {\"x\": 5.420932769775391, \"y\": 7.075211048126221, \"labels\": \"early\"}, {\"x\": 2.9873900413513184, \"y\": 3.8708231449127197, \"labels\": \"provolone\"}, {\"x\": 1.2519818544387817, \"y\": 3.82523250579834, \"labels\": \"tuna\"}, {\"x\": 3.5720865726470947, \"y\": 5.708629131317139, \"labels\": \"quarts\"}, {\"x\": 0.6897203922271729, \"y\": 4.343153953552246, \"labels\": \"apple\"}, {\"x\": 5.475603103637695, \"y\": 5.014077186584473, \"labels\": \"appliances\"}, {\"x\": 6.954858779907227, \"y\": 6.709137439727783, \"labels\": \"recognize\"}, {\"x\": 3.3315441608428955, \"y\": 5.92695951461792, \"labels\": \"gradually\"}, {\"x\": 2.4035065174102783, \"y\": 3.9229164123535156, \"labels\": \"miso\"}, {\"x\": 7.970564842224121, \"y\": 4.489092826843262, \"labels\": \"th\"}, {\"x\": 4.606291770935059, \"y\": 5.35568904876709, \"labels\": \"amino\"}, {\"x\": 2.2592475414276123, \"y\": 5.65737247467041, \"labels\": \"fold\"}, {\"x\": 5.012057304382324, \"y\": 7.28748083114624, \"labels\": \"sand\"}, {\"x\": 7.887164115905762, \"y\": 4.64073371887207, \"labels\": \"six\"}, {\"x\": 3.4187982082366943, \"y\": 6.76224422454834, \"labels\": \"bubbles\"}, {\"x\": 6.016438007354736, \"y\": 7.928627967834473, \"labels\": \"lead\"}, {\"x\": 3.49025821685791, \"y\": 3.875492811203003, \"labels\": \"liver\"}, {\"x\": 8.644878387451172, \"y\": 6.094065189361572, \"labels\": \"advice\"}, {\"x\": 1.823930263519287, \"y\": 4.5616774559021, \"labels\": \"some\"}, {\"x\": 4.892749309539795, \"y\": 4.753350257873535, \"labels\": \"combining\"}, {\"x\": 7.4502129554748535, \"y\": 5.756937503814697, \"labels\": \"doctor\"}, {\"x\": 4.8897600173950195, \"y\": 6.411187648773193, \"labels\": \"proportion\"}, {\"x\": 4.6582417488098145, \"y\": 4.86458158493042, \"labels\": \"flavouring\"}, {\"x\": 5.590937614440918, \"y\": 4.820256233215332, \"labels\": \"joes\"}, {\"x\": 6.093507289886475, \"y\": 5.2734479904174805, \"labels\": \"shitty\"}, {\"x\": 1.3766473531723022, \"y\": 3.8765156269073486, \"labels\": \"salmon\"}, {\"x\": 6.496021270751953, \"y\": 6.434613227844238, \"labels\": \"iirc\"}, {\"x\": 7.690633773803711, \"y\": 5.736904144287109, \"labels\": \"everyday\"}, {\"x\": 2.899061441421509, \"y\": 6.787807941436768, \"labels\": \"fully\"}, {\"x\": 3.8583223819732666, \"y\": 7.140450477600098, \"labels\": \"becomes\"}, {\"x\": 3.547858715057373, \"y\": 3.9211463928222656, \"labels\": \"maker\"}, {\"x\": 3.850706100463867, \"y\": 4.170925617218018, \"labels\": \"cola\"}, {\"x\": 2.9602348804473877, \"y\": 4.951426029205322, \"labels\": \"adds\"}, {\"x\": 5.05028772354126, \"y\": 5.337044715881348, \"labels\": \"ikea\"}, {\"x\": 5.207300186157227, \"y\": 6.391210079193115, \"labels\": \"reseason\"}, {\"x\": 2.789719581604004, \"y\": 5.0803327560424805, \"labels\": \"amount\"}, {\"x\": 4.33629035949707, \"y\": 4.277514457702637, \"labels\": \"fruity\"}, {\"x\": 2.3709635734558105, \"y\": 5.90645170211792, \"labels\": \"crispy\"}, {\"x\": 6.429878234863281, \"y\": 4.237122535705566, \"labels\": \"majority\"}, {\"x\": 1.120194673538208, \"y\": 3.769531726837158, \"labels\": \"taco\"}, {\"x\": 4.465708255767822, \"y\": 6.259862422943115, \"labels\": \"teeth\"}, {\"x\": 4.415308475494385, \"y\": 5.284695625305176, \"labels\": \"perfection\"}, {\"x\": 8.256134033203125, \"y\": 6.208108901977539, \"labels\": \"literally\"}, {\"x\": 5.043184757232666, \"y\": 6.447272300720215, \"labels\": \"clumps\"}, {\"x\": 3.7798714637756348, \"y\": 4.116916179656982, \"labels\": \"goose\"}, {\"x\": 8.76491928100586, \"y\": 6.58909797668457, \"labels\": \"everyone\"}, {\"x\": 6.746617794036865, \"y\": 5.339569091796875, \"labels\": \"intolerance\"}, {\"x\": 8.450486183166504, \"y\": 6.728446006774902, \"labels\": \"meant\"}, {\"x\": 5.681224346160889, \"y\": 7.873563766479492, \"labels\": \"pass\"}, {\"x\": 1.9919092655181885, \"y\": 7.131054401397705, \"labels\": \"rack\"}, {\"x\": 5.500575065612793, \"y\": 7.072210788726807, \"labels\": \"causes\"}, {\"x\": 3.96435284614563, \"y\": 6.785668849945068, \"labels\": \"flipping\"}, {\"x\": 8.081053733825684, \"y\": 4.339709281921387, \"labels\": \"price\"}, {\"x\": 2.3693594932556152, \"y\": 7.1526994705200195, \"labels\": \"cool\"}, {\"x\": 5.754411697387695, \"y\": 5.713078022003174, \"labels\": \"led\"}, {\"x\": 3.239743947982788, \"y\": 7.579883098602295, \"labels\": \"setting\"}, {\"x\": 6.202262878417969, \"y\": 8.09836196899414, \"labels\": \"afford\"}, {\"x\": 8.504448890686035, \"y\": 7.245053768157959, \"labels\": \"absolutely\"}, {\"x\": 6.829196453094482, \"y\": 4.553213596343994, \"labels\": \"southern\"}, {\"x\": 6.93026876449585, \"y\": 3.405092716217041, \"labels\": \"rank\"}, {\"x\": 6.567473411560059, \"y\": 5.6809000968933105, \"labels\": \"suspect\"}, {\"x\": 6.235317707061768, \"y\": 6.684586048126221, \"labels\": \"grit\"}, {\"x\": 5.061107158660889, \"y\": 6.440899848937988, \"labels\": \"lifespan\"}, {\"x\": 4.125552177429199, \"y\": 4.67567777633667, \"labels\": \"ripe\"}, {\"x\": 6.651575565338135, \"y\": 7.047296524047852, \"labels\": \"passionate\"}, {\"x\": 7.928786277770996, \"y\": 6.628694534301758, \"labels\": \"unhealthy\"}, {\"x\": 1.8122756481170654, \"y\": 6.56549072265625, \"labels\": \"wrap\"}, {\"x\": 5.945484638214111, \"y\": 8.054481506347656, \"labels\": \"become\"}, {\"x\": 6.860352039337158, \"y\": 4.242480754852295, \"labels\": \"selling\"}, {\"x\": 7.437692642211914, \"y\": 6.710833549499512, \"labels\": \"impressed\"}, {\"x\": 5.635977268218994, \"y\": 6.88876485824585, \"labels\": \"opener\"}, {\"x\": 6.988070964813232, \"y\": 3.2609612941741943, \"labels\": \"blog\"}, {\"x\": 7.1157708168029785, \"y\": 3.5507147312164307, \"labels\": \"product\"}, {\"x\": 7.425106525421143, \"y\": 4.774796485900879, \"labels\": \"dining\"}, {\"x\": 3.0247628688812256, \"y\": 7.390198707580566, \"labels\": \"aluminum\"}, {\"x\": 7.301308631896973, \"y\": 4.898893356323242, \"labels\": \"honing\"}, {\"x\": 3.471128225326538, \"y\": 5.9724345207214355, \"labels\": \"deeper\"}, {\"x\": 7.376113414764404, \"y\": 4.0941853523254395, \"labels\": \"aid\"}, {\"x\": 0.5207165479660034, \"y\": 4.457296371459961, \"labels\": \"soy_sauce\"}, {\"x\": 3.4968671798706055, \"y\": 4.536783695220947, \"labels\": \"thickened\"}, {\"x\": 6.294619083404541, \"y\": 7.402896881103516, \"labels\": \"involve\"}, {\"x\": 6.894471645355225, \"y\": 4.995543479919434, \"labels\": \"magazine\"}, {\"x\": 6.91797399520874, \"y\": 5.154597282409668, \"labels\": \"related\"}, {\"x\": 6.8423237800598145, \"y\": 5.725396156311035, \"labels\": \"obsessed\"}, {\"x\": 3.52276349067688, \"y\": 4.0835981369018555, \"labels\": \"processed\"}, {\"x\": 4.095673561096191, \"y\": 4.345200538635254, \"labels\": \"bullion\"}, {\"x\": 5.104040622711182, \"y\": 6.100485801696777, \"labels\": \"firmer\"}, {\"x\": 3.8079020977020264, \"y\": 4.833308219909668, \"labels\": \"stale\"}, {\"x\": 1.2714486122131348, \"y\": 4.4425578117370605, \"labels\": \"seasonings\"}, {\"x\": 6.850113391876221, \"y\": 3.1399714946746826, \"labels\": \"bot\"}, {\"x\": 5.600642204284668, \"y\": 6.273551940917969, \"labels\": \"pride\"}, {\"x\": 6.592914581298828, \"y\": 5.259647369384766, \"labels\": \"boards\"}, {\"x\": 3.0675034523010254, \"y\": 5.321998596191406, \"labels\": \"along\"}, {\"x\": 7.525519371032715, \"y\": 6.846022605895996, \"labels\": \"clue\"}, {\"x\": 2.045496940612793, \"y\": 3.642563819885254, \"labels\": \"stir_fry\"}, {\"x\": 7.3987040519714355, \"y\": 4.170858383178711, \"labels\": \"shop\"}, {\"x\": 3.726491689682007, \"y\": 3.837630271911621, \"labels\": \"mousse\"}, {\"x\": 5.024127006530762, \"y\": 6.357340335845947, \"labels\": \"shine\"}, {\"x\": 5.273875713348389, \"y\": 4.494118690490723, \"labels\": \"paneer\"}, {\"x\": 6.331076622009277, \"y\": 6.2040300369262695, \"labels\": \"suggesting\"}, {\"x\": 4.297966003417969, \"y\": 6.762292385101318, \"labels\": \"utensils\"}, {\"x\": 8.49203872680664, \"y\": 5.814888000488281, \"labels\": \"linked\"}, {\"x\": 1.1136289834976196, \"y\": 3.7357892990112305, \"labels\": \"ham\"}, {\"x\": 6.095780372619629, \"y\": 7.992039680480957, \"labels\": \"feed\"}, {\"x\": 5.0064263343811035, \"y\": 8.045814514160156, \"labels\": \"walk\"}, {\"x\": 2.8069565296173096, \"y\": 7.383340835571289, \"labels\": \"in\"}, {\"x\": 6.638588905334473, \"y\": 4.0116963386535645, \"labels\": \"many\"}, {\"x\": 5.872462749481201, \"y\": 4.8241353034973145, \"labels\": \"varies\"}, {\"x\": 5.556280136108398, \"y\": 6.834707260131836, \"labels\": \"act\"}, {\"x\": 4.530966758728027, \"y\": 5.508036136627197, \"labels\": \"whatnot\"}, {\"x\": 8.57388687133789, \"y\": 7.063575267791748, \"labels\": \"happened\"}, {\"x\": 4.249630928039551, \"y\": 4.851663112640381, \"labels\": \"packages\"}, {\"x\": 7.182967662811279, \"y\": 4.6441473960876465, \"labels\": \"nyc\"}, {\"x\": 6.56576681137085, \"y\": 2.575868844985962, \"labels\": \"ie\"}, {\"x\": 3.0642809867858887, \"y\": 4.27354097366333, \"labels\": \"wraps\"}, {\"x\": 3.9098942279815674, \"y\": 7.508017539978027, \"labels\": \"speed\"}, {\"x\": 6.195914268493652, \"y\": 5.3134684562683105, \"labels\": \"trimethylamine\"}, {\"x\": 3.282818078994751, \"y\": 6.260265350341797, \"labels\": \"mason\"}, {\"x\": 1.5274360179901123, \"y\": 3.869589328765869, \"labels\": \"pickles\"}, {\"x\": 7.137392520904541, \"y\": 3.929109811782837, \"labels\": \"mise\"}, {\"x\": 0.46832382678985596, \"y\": 4.3863325119018555, \"labels\": \"black_pepper\"}, {\"x\": 7.191292762756348, \"y\": 7.169504165649414, \"labels\": \"id\"}, {\"x\": 5.613931655883789, \"y\": 6.845996856689453, \"labels\": \"garage\"}, {\"x\": 4.580298900604248, \"y\": 5.372602939605713, \"labels\": \"exterior\"}, {\"x\": 6.14231014251709, \"y\": 4.541301727294922, \"labels\": \"uh\"}, {\"x\": 5.827550888061523, \"y\": 8.425341606140137, \"labels\": \"make\"}, {\"x\": 7.086472511291504, \"y\": 5.6588616371154785, \"labels\": \"upvote\"}, {\"x\": 7.16978645324707, \"y\": 4.363969326019287, \"labels\": \"section\"}, {\"x\": 7.261713981628418, \"y\": 6.859036922454834, \"labels\": \"effective\"}, {\"x\": 3.341646671295166, \"y\": 5.561224460601807, \"labels\": \"crawfish\"}, {\"x\": 4.996880054473877, \"y\": 7.57280969619751, \"labels\": \"pulling\"}, {\"x\": 0.44508716464042664, \"y\": 4.408384799957275, \"labels\": \"cayenne\"}, {\"x\": 2.5879695415496826, \"y\": 7.073703289031982, \"labels\": \"ready\"}, {\"x\": 8.737630844116211, \"y\": 5.746994972229004, \"labels\": \"video\"}, {\"x\": 6.442472457885742, \"y\": 4.1440534591674805, \"labels\": \"kind\"}, {\"x\": 7.3618597984313965, \"y\": 7.729930400848389, \"labels\": \"wanna\"}, {\"x\": 3.329951047897339, \"y\": 5.789236068725586, \"labels\": \"steaming\"}, {\"x\": 2.0522353649139404, \"y\": 7.269296646118164, \"labels\": \"oven\"}, {\"x\": 7.600264072418213, \"y\": 4.686851978302002, \"labels\": \"creuset\"}, {\"x\": 3.1056013107299805, \"y\": 4.128006458282471, \"labels\": \"gouda\"}, {\"x\": 6.488165378570557, \"y\": 4.448976039886475, \"labels\": \"non\"}, {\"x\": 2.296283721923828, \"y\": 7.204526424407959, \"labels\": \"cook\"}, {\"x\": 2.0647263526916504, \"y\": 6.022158622741699, \"labels\": \"seasoned\"}, {\"x\": 1.3698136806488037, \"y\": 4.428091049194336, \"labels\": \"powdered\"}, {\"x\": 6.636767864227295, \"y\": 3.368161916732788, \"labels\": \"budgetbytes\"}, {\"x\": 2.7967586517333984, \"y\": 3.604768991470337, \"labels\": \"cajun\"}, {\"x\": 4.043808937072754, \"y\": 7.519763469696045, \"labels\": \"power\"}, {\"x\": 4.030271053314209, \"y\": 3.5790860652923584, \"labels\": \"singles\"}, {\"x\": 1.1871672868728638, \"y\": 3.6355581283569336, \"labels\": \"pie\"}, {\"x\": 3.1593878269195557, \"y\": 4.204751968383789, \"labels\": \"kecap\"}, {\"x\": 4.313808917999268, \"y\": 6.857301712036133, \"labels\": \"slip\"}, {\"x\": 8.755719184875488, \"y\": 6.398199081420898, \"labels\": \"problem\"}, {\"x\": 8.51915454864502, \"y\": 5.504425048828125, \"labels\": \"chef\"}, {\"x\": 6.505795001983643, \"y\": 2.6253039836883545, \"labels\": \"french\"}, {\"x\": 0.3906632363796234, \"y\": 4.281243801116943, \"labels\": \"carrots\"}, {\"x\": 4.949974536895752, \"y\": 6.69404935836792, \"labels\": \"burned\"}, {\"x\": 5.967716693878174, \"y\": 4.299079418182373, \"labels\": \"lists\"}, {\"x\": 4.111867427825928, \"y\": 5.731525421142578, \"labels\": \"ap\"}, {\"x\": 4.024528980255127, \"y\": 5.195679187774658, \"labels\": \"quantity\"}, {\"x\": 5.0361480712890625, \"y\": 7.302720069885254, \"labels\": \"fell\"}, {\"x\": 6.516099452972412, \"y\": 4.57362699508667, \"labels\": \"bon\"}, {\"x\": 1.2398834228515625, \"y\": 3.615757942199707, \"labels\": \"baked\"}, {\"x\": 4.934260368347168, \"y\": 5.273171901702881, \"labels\": \"mmm\"}, {\"x\": 5.6548566818237305, \"y\": 7.680534362792969, \"labels\": \"due\"}, {\"x\": 7.749457359313965, \"y\": 7.325069904327393, \"labels\": \"trying\"}, {\"x\": 5.09773588180542, \"y\": 5.663313388824463, \"labels\": \"charcuterie\"}, {\"x\": 1.4638326168060303, \"y\": 4.905867576599121, \"labels\": \"veggies\"}, {\"x\": 1.3520604372024536, \"y\": 3.8047282695770264, \"labels\": \"toast\"}, {\"x\": 7.875101089477539, \"y\": 4.437483310699463, \"labels\": \"morning\"}, {\"x\": 4.40229606628418, \"y\": 4.5988450050354, \"labels\": \"swap\"}, {\"x\": 1.3173900842666626, \"y\": 3.802375555038452, \"labels\": \"pasta\"}, {\"x\": 4.173675060272217, \"y\": 5.567652225494385, \"labels\": \"vermouth\"}, {\"x\": 8.450509071350098, \"y\": 4.555284023284912, \"labels\": \"years\"}, {\"x\": 8.674886703491211, \"y\": 6.664146900177002, \"labels\": \"tried\"}, {\"x\": 2.0394327640533447, \"y\": 6.668956279754639, \"labels\": \"hot\"}, {\"x\": 7.325247287750244, \"y\": 5.534476280212402, \"labels\": \"ridiculous\"}, {\"x\": 7.256579399108887, \"y\": 6.031996726989746, \"labels\": \"moment\"}, {\"x\": 2.138350009918213, \"y\": 4.785953521728516, \"labels\": \"touch\"}, {\"x\": 8.52295970916748, \"y\": 7.092240333557129, \"labels\": \"says\"}, {\"x\": 2.2312474250793457, \"y\": 3.824538230895996, \"labels\": \"horseradish\"}, {\"x\": 6.939702987670898, \"y\": 7.3006272315979, \"labels\": \"lacking\"}, {\"x\": 5.267339706420898, \"y\": 4.325735569000244, \"labels\": \"broths\"}, {\"x\": 5.420090198516846, \"y\": 5.739543914794922, \"labels\": \"loaded\"}, {\"x\": 6.894186019897461, \"y\": 5.6918768882751465, \"labels\": \"auto\"}, {\"x\": 3.7077696323394775, \"y\": 6.228875160217285, \"labels\": \"inner\"}, {\"x\": 3.041879177093506, \"y\": 6.372753620147705, \"labels\": \"poach\"}, {\"x\": 6.67618465423584, \"y\": 6.403231143951416, \"labels\": \"desert\"}, {\"x\": 1.5074926614761353, \"y\": 4.605008602142334, \"labels\": \"dash\"}, {\"x\": 6.4177117347717285, \"y\": 7.105189323425293, \"labels\": \"michael\"}, {\"x\": 7.750589847564697, \"y\": 7.103831768035889, \"labels\": \"crazy\"}, {\"x\": 5.389472007751465, \"y\": 4.719341278076172, \"labels\": \"santoku\"}, {\"x\": 7.55254602432251, \"y\": 5.698805809020996, \"labels\": \"keto\"}, {\"x\": 6.2692179679870605, \"y\": 5.480343341827393, \"labels\": \"bakery\"}, {\"x\": 5.648004531860352, \"y\": 6.981167316436768, \"labels\": \"strictly\"}, {\"x\": 5.131095886230469, \"y\": 3.9525694847106934, \"labels\": \"nbsp\"}, {\"x\": 5.102229595184326, \"y\": 8.365423202514648, \"labels\": \"pull\"}, {\"x\": 3.949634313583374, \"y\": 5.37117338180542, \"labels\": \"rough\"}, {\"x\": 3.571380138397217, \"y\": 4.552361011505127, \"labels\": \"tabasco\"}, {\"x\": 1.0722850561141968, \"y\": 4.535562515258789, \"labels\": \"vegetable\"}, {\"x\": 2.138986587524414, \"y\": 3.928068161010742, \"labels\": \"crusty\"}, {\"x\": 7.234306335449219, \"y\": 4.5427680015563965, \"labels\": \"mart\"}, {\"x\": 0.8501073122024536, \"y\": 3.7167251110076904, \"labels\": \"salad\"}, {\"x\": 2.5261497497558594, \"y\": 4.931077480316162, \"labels\": \"dark\"}, {\"x\": 2.4528801441192627, \"y\": 4.462400436401367, \"labels\": \"unsalted\"}, {\"x\": 6.797287940979004, \"y\": 5.486517429351807, \"labels\": \"australian\"}, {\"x\": 6.949936389923096, \"y\": 6.7601494789123535, \"labels\": \"ultimate\"}, {\"x\": 5.1168293952941895, \"y\": 6.357905387878418, \"labels\": \"prone\"}, {\"x\": 5.391063690185547, \"y\": 5.745080947875977, \"labels\": \"lmao\"}, {\"x\": 2.1299972534179688, \"y\": 4.011735916137695, \"labels\": \"wings\"}, {\"x\": 5.551131248474121, \"y\": 3.9046027660369873, \"labels\": \"yummy\"}, {\"x\": 8.021797180175781, \"y\": 7.062414646148682, \"labels\": \"similar\"}, {\"x\": 6.513980388641357, \"y\": 4.600517272949219, \"labels\": \"animals\"}, {\"x\": 2.5140509605407715, \"y\": 7.355317115783691, \"labels\": \"make_sure\"}, {\"x\": 6.745067119598389, \"y\": 5.598005771636963, \"labels\": \"location\"}, {\"x\": 2.076913595199585, \"y\": 3.7144534587860107, \"labels\": \"ranch\"}, {\"x\": 6.24544620513916, \"y\": 6.23497200012207, \"labels\": \"heh\"}, {\"x\": 2.513732671737671, \"y\": 3.673579692840576, \"labels\": \"jasmine\"}, {\"x\": 3.942478895187378, \"y\": 5.568706035614014, \"labels\": \"preferred\"}, {\"x\": 2.083672046661377, \"y\": 3.519432544708252, \"labels\": \"crab\"}, {\"x\": 6.655942916870117, \"y\": 2.473482131958008, \"labels\": \"https_www\"}, {\"x\": 8.21937084197998, \"y\": 7.441534519195557, \"labels\": \"though\"}, {\"x\": 5.241279125213623, \"y\": 6.371678829193115, \"labels\": \"bakes\"}, {\"x\": 4.728302001953125, \"y\": 6.235820770263672, \"labels\": \"advance\"}, {\"x\": 6.373422622680664, \"y\": 5.0367536544799805, \"labels\": \"usual\"}, {\"x\": 2.0047049522399902, \"y\": 5.684175491333008, \"labels\": \"sized\"}, {\"x\": 2.6131505966186523, \"y\": 3.9399492740631104, \"labels\": \"mirepoix\"}, {\"x\": 2.629692792892456, \"y\": 4.069838523864746, \"labels\": \"adobo\"}, {\"x\": 4.914686679840088, \"y\": 5.864614486694336, \"labels\": \"intact\"}, {\"x\": 4.576779842376709, \"y\": 4.893529415130615, \"labels\": \"trinity\"}, {\"x\": 4.992532253265381, \"y\": 4.967737197875977, \"labels\": \"button\"}, {\"x\": 6.5435051918029785, \"y\": 3.54659366607666, \"labels\": \"index\"}, {\"x\": 6.954298973083496, \"y\": 6.080131530761719, \"labels\": \"statement\"}, {\"x\": 6.353779315948486, \"y\": 5.412015438079834, \"labels\": \"particularly\"}, {\"x\": 7.418711185455322, \"y\": 4.183480739593506, \"labels\": \"paring\"}, {\"x\": 7.49440860748291, \"y\": 3.9838907718658447, \"labels\": \"dinners\"}, {\"x\": 6.441571235656738, \"y\": 4.134814262390137, \"labels\": \"articles\"}, {\"x\": 6.352229595184326, \"y\": 4.881864547729492, \"labels\": \"myth\"}, {\"x\": 5.115684509277344, \"y\": 7.949625015258789, \"labels\": \"jump\"}, {\"x\": 3.070739269256592, \"y\": 4.043679237365723, \"labels\": \"gold\"}, {\"x\": 1.3622934818267822, \"y\": 5.245266914367676, \"labels\": \"egg\"}, {\"x\": 3.168283462524414, \"y\": 7.42540979385376, \"labels\": \"electric\"}, {\"x\": 2.0928337574005127, \"y\": 4.167769908905029, \"labels\": \"apples\"}, {\"x\": 5.431610107421875, \"y\": 4.075069427490234, \"labels\": \"big\"}, {\"x\": 6.294383525848389, \"y\": 6.930471420288086, \"labels\": \"frequently\"}, {\"x\": 4.184296607971191, \"y\": 7.5531158447265625, \"labels\": \"getting\"}, {\"x\": 3.9448773860931396, \"y\": 6.2603840827941895, \"labels\": \"dog\"}, {\"x\": 6.2871012687683105, \"y\": 5.879223823547363, \"labels\": \"superior\"}, {\"x\": 6.152218341827393, \"y\": 5.752341270446777, \"labels\": \"costs\"}, {\"x\": 7.214545726776123, \"y\": 6.977096080780029, \"labels\": \"unsafe\"}, {\"x\": 7.4826130867004395, \"y\": 4.986459732055664, \"labels\": \"safety\"}, {\"x\": 5.395228862762451, \"y\": 6.7262797355651855, \"labels\": \"moments\"}, {\"x\": 7.766333103179932, \"y\": 6.101078987121582, \"labels\": \"results\"}, {\"x\": 6.433475494384766, \"y\": 4.587663650512695, \"labels\": \"factory\"}, {\"x\": 5.09853458404541, \"y\": 7.576507568359375, \"labels\": \"adjust\"}, {\"x\": 6.607487201690674, \"y\": 6.123968124389648, \"labels\": \"significant\"}, {\"x\": 4.335358142852783, \"y\": 3.878511905670166, \"labels\": \"ragu\"}, {\"x\": 2.916188955307007, \"y\": 6.761373043060303, \"labels\": \"cooled\"}, {\"x\": 6.106342792510986, \"y\": 8.15146541595459, \"labels\": \"pay\"}, {\"x\": 3.5309019088745117, \"y\": 7.198390483856201, \"labels\": \"defrost\"}, {\"x\": 4.6806864738464355, \"y\": 5.211202144622803, \"labels\": \"tree\"}, {\"x\": 4.247010707855225, \"y\": 6.705089569091797, \"labels\": \"remains\"}, {\"x\": 6.229928016662598, \"y\": 6.13444185256958, \"labels\": \"dislike\"}, {\"x\": 5.616907119750977, \"y\": 8.252532958984375, \"labels\": \"end_up\"}, {\"x\": 2.6521079540252686, \"y\": 4.114078998565674, \"labels\": \"roux\"}, {\"x\": 2.030763626098633, \"y\": 6.433738708496094, \"labels\": \"slowly\"}, {\"x\": 4.105470180511475, \"y\": 5.237707614898682, \"labels\": \"snow\"}, {\"x\": 5.335805416107178, \"y\": 4.072152614593506, \"labels\": \"mr\"}, {\"x\": 4.861117362976074, \"y\": 6.0637969970703125, \"labels\": \"click\"}, {\"x\": 4.772322654724121, \"y\": 4.6225457191467285, \"labels\": \"ceviche\"}, {\"x\": 2.0761709213256836, \"y\": 6.374345302581787, \"labels\": \"bring\"}, {\"x\": 3.782515287399292, \"y\": 6.6161112785339355, \"labels\": \"micro\"}, {\"x\": 4.393769264221191, \"y\": 6.048690319061279, \"labels\": \"increase\"}, {\"x\": 3.4719974994659424, \"y\": 6.002771854400635, \"labels\": \"pool\"}, {\"x\": 6.730227470397949, \"y\": 4.027554035186768, \"labels\": \"those\"}, {\"x\": 1.5108164548873901, \"y\": 3.7508559226989746, \"labels\": \"dip\"}, {\"x\": 3.716942548751831, \"y\": 6.08004093170166, \"labels\": \"un\"}, {\"x\": 1.9721994400024414, \"y\": 6.693451881408691, \"labels\": \"freeze\"}, {\"x\": 3.972113847732544, \"y\": 6.669081687927246, \"labels\": \"crock_pot\"}, {\"x\": 4.394780158996582, \"y\": 4.938262462615967, \"labels\": \"starchy\"}, {\"x\": 5.746082305908203, \"y\": 6.239763259887695, \"labels\": \"handed\"}, {\"x\": 6.8772664070129395, \"y\": 5.389867782592773, \"labels\": \"team\"}, {\"x\": 7.853993892669678, \"y\": 6.614015102386475, \"labels\": \"hah\"}, {\"x\": 6.777522087097168, \"y\": 5.922560691833496, \"labels\": \"digital\"}, {\"x\": 5.706678867340088, \"y\": 5.94131326675415, \"labels\": \"advanced\"}, {\"x\": 1.3048114776611328, \"y\": 4.5364484786987305, \"labels\": \"breadcrumbs\"}, {\"x\": 6.782899379730225, \"y\": 7.896569728851318, \"labels\": \"next_time\"}, {\"x\": 7.278040409088135, \"y\": 4.410170555114746, \"labels\": \"shopping\"}, {\"x\": 8.213799476623535, \"y\": 6.905386447906494, \"labels\": \"claim\"}, {\"x\": 3.924604654312134, \"y\": 4.947006702423096, \"labels\": \"platter\"}, {\"x\": 4.3952836990356445, \"y\": 5.222604751586914, \"labels\": \"pile\"}, {\"x\": 5.494613170623779, \"y\": 3.981308698654175, \"labels\": \"strange\"}, {\"x\": 1.1192002296447754, \"y\": 3.800976514816284, \"labels\": \"tofu\"}, {\"x\": 7.739388942718506, \"y\": 5.435930252075195, \"labels\": \"aunt\"}, {\"x\": 4.082211017608643, \"y\": 4.033812522888184, \"labels\": \"berry\"}, {\"x\": 5.013564109802246, \"y\": 6.473296642303467, \"labels\": \"smokes\"}, {\"x\": 4.557891845703125, \"y\": 4.618268966674805, \"labels\": \"raisin\"}, {\"x\": 8.212397575378418, \"y\": 4.332845687866211, \"labels\": \"couple\"}, {\"x\": 5.4193339347839355, \"y\": 4.90041446685791, \"labels\": \"labels\"}, {\"x\": 5.190748691558838, \"y\": 5.2152628898620605, \"labels\": \"processing\"}, {\"x\": 6.949852466583252, \"y\": 5.881599426269531, \"labels\": \"enlightening\"}, {\"x\": 3.293513059616089, \"y\": 7.059794902801514, \"labels\": \"preheated\"}, {\"x\": 7.253846645355225, \"y\": 4.946612358093262, \"labels\": \"links\"}, {\"x\": 5.628347873687744, \"y\": 5.434850215911865, \"labels\": \"jersey\"}, {\"x\": 6.975103855133057, \"y\": 7.1821513175964355, \"labels\": \"safer\"}, {\"x\": 3.4849748611450195, \"y\": 3.4532508850097656, \"labels\": \"pho\"}, {\"x\": 5.956236362457275, \"y\": 4.923296928405762, \"labels\": \"rose\"}, {\"x\": 3.7645161151885986, \"y\": 6.1818647384643555, \"labels\": \"vs\"}, {\"x\": 4.071896553039551, \"y\": 4.795797824859619, \"labels\": \"items\"}, {\"x\": 6.301675796508789, \"y\": 6.962735652923584, \"labels\": \"preserve\"}, {\"x\": 8.576602935791016, \"y\": 5.586675643920898, \"labels\": \"kitchen\"}, {\"x\": 1.2863210439682007, \"y\": 3.6938188076019287, \"labels\": \"casserole\"}, {\"x\": 4.48328161239624, \"y\": 6.566551685333252, \"labels\": \"colder\"}, {\"x\": 5.971035957336426, \"y\": 8.288455963134766, \"labels\": \"suggest\"}, {\"x\": 4.216921329498291, \"y\": 7.280548095703125, \"labels\": \"omega\"}, {\"x\": 8.162869453430176, \"y\": 7.658179759979248, \"labels\": \"remember\"}, {\"x\": 7.103701114654541, \"y\": 5.506306171417236, \"labels\": \"international\"}, {\"x\": 7.22761869430542, \"y\": 6.7820353507995605, \"labels\": \"canadian\"}, {\"x\": 6.642050743103027, \"y\": 2.572173833847046, \"labels\": \"ref\"}, {\"x\": 2.6193552017211914, \"y\": 5.889004230499268, \"labels\": \"nicely\"}, {\"x\": 3.2338480949401855, \"y\": 6.464895725250244, \"labels\": \"sieve\"}, {\"x\": 6.71192741394043, \"y\": 7.953676700592041, \"labels\": \"right\"}, {\"x\": 3.9000027179718018, \"y\": 3.74773907661438, \"labels\": \"philly\"}, {\"x\": 7.123405456542969, \"y\": 4.3658366203308105, \"labels\": \"grocer\"}, {\"x\": 6.106725215911865, \"y\": 6.7748284339904785, \"labels\": \"opening\"}, {\"x\": 6.353999137878418, \"y\": 7.124510288238525, \"labels\": \"labor\"}, {\"x\": 7.044166088104248, \"y\": 5.1479339599609375, \"labels\": \"native\"}, {\"x\": 6.533019542694092, \"y\": 5.10321044921875, \"labels\": \"indeed\"}, {\"x\": 5.386005401611328, \"y\": 4.969435214996338, \"labels\": \"sheep\"}, {\"x\": 6.4482927322387695, \"y\": 4.65255069732666, \"labels\": \"art\"}, {\"x\": 8.646773338317871, \"y\": 5.997284889221191, \"labels\": \"reading\"}, {\"x\": 3.4161458015441895, \"y\": 6.518373489379883, \"labels\": \"pit\"}, {\"x\": 4.725008010864258, \"y\": 5.184113502502441, \"labels\": \"equivalent\"}, {\"x\": 8.513056755065918, \"y\": 6.902483940124512, \"labels\": \"realized\"}, {\"x\": 6.223649501800537, \"y\": 8.089913368225098, \"labels\": \"want\"}, {\"x\": 6.547563552856445, \"y\": 3.0897140502929688, \"labels\": \"keywords\"}, {\"x\": 2.708268404006958, \"y\": 4.270988464355469, \"labels\": \"leeks\"}, {\"x\": 2.280042886734009, \"y\": 7.15959358215332, \"labels\": \"flip\"}, {\"x\": 3.5190539360046387, \"y\": 5.133421897888184, \"labels\": \"tinfoil\"}, {\"x\": 2.1685566902160645, \"y\": 4.273406505584717, \"labels\": \"mince\"}, {\"x\": 6.263522624969482, \"y\": 6.531738758087158, \"labels\": \"dream\"}, {\"x\": 2.226011276245117, \"y\": 5.7279372215271, \"labels\": \"tin\"}, {\"x\": 4.763019561767578, \"y\": 6.180490970611572, \"labels\": \"managed\"}, {\"x\": 6.425922393798828, \"y\": 6.06718111038208, \"labels\": \"grows\"}, {\"x\": 4.89683198928833, \"y\": 7.383241653442383, \"labels\": \"energy\"}, {\"x\": 7.0374064445495605, \"y\": 3.4007136821746826, \"labels\": \"lopez\"}, {\"x\": 5.173169136047363, \"y\": 5.015748977661133, \"labels\": \"irish\"}, {\"x\": 6.7640862464904785, \"y\": 4.694917678833008, \"labels\": \"ancestors\"}, {\"x\": 8.188749313354492, \"y\": 4.958564758300781, \"labels\": \"old\"}, {\"x\": 8.293108940124512, \"y\": 6.718299388885498, \"labels\": \"assumed\"}, {\"x\": 1.7962157726287842, \"y\": 4.200165271759033, \"labels\": \"leftover\"}, {\"x\": 5.757503986358643, \"y\": 6.04460334777832, \"labels\": \"illinois\"}, {\"x\": 5.460643291473389, \"y\": 5.698574542999268, \"labels\": \"chances\"}, {\"x\": 4.8152852058410645, \"y\": 5.278837203979492, \"labels\": \"extras\"}, {\"x\": 8.027482032775879, \"y\": 4.437077522277832, \"labels\": \"total\"}, {\"x\": 7.081913948059082, \"y\": 4.750019550323486, \"labels\": \"books\"}, {\"x\": 2.178800344467163, \"y\": 5.878945350646973, \"labels\": \"thick\"}, {\"x\": 0.9832671284675598, \"y\": 4.280585289001465, \"labels\": \"vanilla\"}, {\"x\": 5.842623710632324, \"y\": 7.069251537322998, \"labels\": \"waiting\"}, {\"x\": 6.257437229156494, \"y\": 7.761200904846191, \"labels\": \"piss\"}, {\"x\": 2.2672832012176514, \"y\": 5.589744567871094, \"labels\": \"wedges\"}, {\"x\": 3.229888439178467, \"y\": 5.792063236236572, \"labels\": \"swirl\"}, {\"x\": 7.248013019561768, \"y\": 5.1074604988098145, \"labels\": \"tools\"}, {\"x\": 4.4855828285217285, \"y\": 4.7692437171936035, \"labels\": \"calamari\"}, {\"x\": 3.5219264030456543, \"y\": 4.2582197189331055, \"labels\": \"store_bought\"}, {\"x\": 3.3054416179656982, \"y\": 7.168519973754883, \"labels\": \"smoking\"}, {\"x\": 3.606708288192749, \"y\": 4.911770343780518, \"labels\": \"steaks\"}, {\"x\": 3.9653377532958984, \"y\": 7.12744665145874, \"labels\": \"desired\"}, {\"x\": 0.828940212726593, \"y\": 5.1564226150512695, \"labels\": \"mix\"}, {\"x\": 6.65102481842041, \"y\": 2.574584484100342, \"labels\": \"amp_amp\"}, {\"x\": 3.866112470626831, \"y\": 6.578953742980957, \"labels\": \"rather_than\"}, {\"x\": 8.524147987365723, \"y\": 6.573599338531494, \"labels\": \"joke\"}, {\"x\": 2.8570709228515625, \"y\": 3.594573974609375, \"labels\": \"cakes\"}, {\"x\": 4.148285388946533, \"y\": 5.898303031921387, \"labels\": \"juicy\"}, {\"x\": 6.008123874664307, \"y\": 6.190129280090332, \"labels\": \"jams\"}, {\"x\": 4.46139669418335, \"y\": 4.046761989593506, \"labels\": \"crepes\"}, {\"x\": 7.779171943664551, \"y\": 6.3449931144714355, \"labels\": \"writing\"}, {\"x\": 2.7758800983428955, \"y\": 7.154135704040527, \"labels\": \"upside\"}, {\"x\": 2.1807968616485596, \"y\": 4.019872188568115, \"labels\": \"fruits\"}, {\"x\": 3.8802907466888428, \"y\": 6.428609848022461, \"labels\": \"pocket\"}, {\"x\": 3.822172164916992, \"y\": 6.4419074058532715, \"labels\": \"fondue\"}, {\"x\": 2.4892842769622803, \"y\": 3.5528669357299805, \"labels\": \"alfredo\"}, {\"x\": 5.760032653808594, \"y\": 8.499186515808105, \"labels\": \"buy\"}, {\"x\": 6.258518695831299, \"y\": 5.90505313873291, \"labels\": \"across\"}, {\"x\": 6.383297920227051, \"y\": 5.01711893081665, \"labels\": \"confusion\"}, {\"x\": 2.3864905834198, \"y\": 7.185032844543457, \"labels\": \"over\"}, {\"x\": 7.3332719802856445, \"y\": 7.434857368469238, \"labels\": \"imo\"}, {\"x\": 2.4194536209106445, \"y\": 3.7122294902801514, \"labels\": \"teriyaki\"}, {\"x\": 3.893174409866333, \"y\": 3.4867095947265625, \"labels\": \"nachos\"}, {\"x\": 2.461540699005127, \"y\": 7.0238261222839355, \"labels\": \"microwave\"}, {\"x\": 5.8034820556640625, \"y\": 7.929158687591553, \"labels\": \"require\"}, {\"x\": 6.510385990142822, \"y\": 6.406291484832764, \"labels\": \"ooh\"}, {\"x\": 2.8713395595550537, \"y\": 7.059325218200684, \"labels\": \"kettle\"}, {\"x\": 5.9403252601623535, \"y\": 8.376440048217773, \"labels\": \"consider\"}, {\"x\": 1.4431238174438477, \"y\": 4.154358386993408, \"labels\": \"panko\"}, {\"x\": 6.8679399490356445, \"y\": 4.098611831665039, \"labels\": \"others\"}, {\"x\": 4.531532287597656, \"y\": 5.307092666625977, \"labels\": \"bush\"}, {\"x\": 2.974735975265503, \"y\": 4.416990280151367, \"labels\": \"grey\"}, {\"x\": 2.7225241661071777, \"y\": 5.314083576202393, \"labels\": \"flavour\"}, {\"x\": 5.440643310546875, \"y\": 6.214216232299805, \"labels\": \"introduce\"}, {\"x\": 1.8998955488204956, \"y\": 3.9534175395965576, \"labels\": \"creme\"}, {\"x\": 6.995318412780762, \"y\": 4.805996417999268, \"labels\": \"holidays\"}, {\"x\": 3.684436559677124, \"y\": 4.16889762878418, \"labels\": \"crabs\"}, {\"x\": 1.1868484020233154, \"y\": 3.874248504638672, \"labels\": \"fish\"}, {\"x\": 4.82222318649292, \"y\": 4.9894256591796875, \"labels\": \"boxes\"}, {\"x\": 7.631277084350586, \"y\": 6.1645121574401855, \"labels\": \"pictures\"}, {\"x\": 4.547729015350342, \"y\": 7.576955795288086, \"labels\": \"much\"}, {\"x\": 3.1491618156433105, \"y\": 4.789346218109131, \"labels\": \"tossed\"}, {\"x\": 1.409590244293213, \"y\": 5.541594505310059, \"labels\": \"mixture\"}, {\"x\": 5.569812774658203, \"y\": 3.956298351287842, \"labels\": \"inspired\"}, {\"x\": 5.716645240783691, \"y\": 8.046491622924805, \"labels\": \"lose\"}, {\"x\": 5.3752360343933105, \"y\": 6.396479606628418, \"labels\": \"liking\"}, {\"x\": 4.729808330535889, \"y\": 7.390403747558594, \"labels\": \"tastier\"}, {\"x\": 7.697683334350586, \"y\": 5.1262969970703125, \"labels\": \"cleaning\"}, {\"x\": 3.3447940349578857, \"y\": 5.439942836761475, \"labels\": \"liberally\"}, {\"x\": 2.3830981254577637, \"y\": 5.43577241897583, \"labels\": \"bit\"}, {\"x\": 6.561629295349121, \"y\": 6.349054336547852, \"labels\": \"caution\"}, {\"x\": 5.083040237426758, \"y\": 8.146976470947266, \"labels\": \"pick\"}, {\"x\": 2.570795774459839, \"y\": 4.185664653778076, \"labels\": \"peppercorns\"}, {\"x\": 6.827374458312988, \"y\": 4.7650465965271, \"labels\": \"wal\"}, {\"x\": 2.141932964324951, \"y\": 4.866353511810303, \"labels\": \"uncooked\"}, {\"x\": 6.335364818572998, \"y\": 6.4374871253967285, \"labels\": \"opened\"}, {\"x\": 3.387610673904419, \"y\": 3.9531097412109375, \"labels\": \"blending\"}, {\"x\": 1.9618178606033325, \"y\": 7.04925537109375, \"labels\": \"foil\"}, {\"x\": 6.64381217956543, \"y\": 5.589756965637207, \"labels\": \"spores\"}, {\"x\": 6.0653228759765625, \"y\": 7.19630765914917, \"labels\": \"requires\"}, {\"x\": 7.704381942749023, \"y\": 7.272172927856445, \"labels\": \"pricey\"}, {\"x\": 1.9466192722320557, \"y\": 6.3616790771484375, \"labels\": \"saut\\u00e9\"}, {\"x\": 5.879261493682861, \"y\": 6.233813285827637, \"labels\": \"koreans\"}, {\"x\": 5.4066667556762695, \"y\": 6.034666061401367, \"labels\": \"bias\"}, {\"x\": 1.1287083625793457, \"y\": 4.576071262359619, \"labels\": \"cider\"}, {\"x\": 7.935216903686523, \"y\": 4.444967746734619, \"labels\": \"another\"}, {\"x\": 3.309680700302124, \"y\": 3.5927767753601074, \"labels\": \"whitefish\"}, {\"x\": 2.5158803462982178, \"y\": 5.919179439544678, \"labels\": \"skins\"}, {\"x\": 7.231363773345947, \"y\": 4.951797008514404, \"labels\": \"web\"}, {\"x\": 0.9039968252182007, \"y\": 4.437498092651367, \"labels\": \"optional\"}, {\"x\": 3.4313647747039795, \"y\": 5.9252119064331055, \"labels\": \"resulting\"}, {\"x\": 3.053720474243164, \"y\": 4.1949262619018555, \"labels\": \"loin\"}, {\"x\": 2.0543150901794434, \"y\": 5.337370872497559, \"labels\": \"batch\"}, {\"x\": 5.9448699951171875, \"y\": 5.876832962036133, \"labels\": \"whilst\"}, {\"x\": 3.6146187782287598, \"y\": 7.453245639801025, \"labels\": \"air\"}, {\"x\": 8.472352981567383, \"y\": 7.282951354980469, \"labels\": \"else\"}, {\"x\": 2.382211923599243, \"y\": 6.453176975250244, \"labels\": \"roasting\"}, {\"x\": 2.5723273754119873, \"y\": 4.151760101318359, \"labels\": \"ounces\"}, {\"x\": 7.506260395050049, \"y\": 5.851031303405762, \"labels\": \"worries\"}, {\"x\": 3.3828821182250977, \"y\": 5.741763114929199, \"labels\": \"stream\"}, {\"x\": 7.72074031829834, \"y\": 7.258991718292236, \"labels\": \"worth\"}, {\"x\": 6.60655403137207, \"y\": 5.925839900970459, \"labels\": \"chang\"}, {\"x\": 5.262466907501221, \"y\": 5.358806133270264, \"labels\": \"convenience\"}, {\"x\": 5.380990982055664, \"y\": 5.158900260925293, \"labels\": \"laundry\"}, {\"x\": 8.065893173217773, \"y\": 5.539557933807373, \"labels\": \"born\"}, {\"x\": 4.116870403289795, \"y\": 3.8390605449676514, \"labels\": \"bechamel\"}, {\"x\": 1.5590691566467285, \"y\": 4.190917015075684, \"labels\": \"jalapenos\"}, {\"x\": 7.185606956481934, \"y\": 3.8660008907318115, \"labels\": \"essentials\"}, {\"x\": 3.0756936073303223, \"y\": 4.082320213317871, \"labels\": \"halved\"}, {\"x\": 8.746301651000977, \"y\": 5.9206085205078125, \"labels\": \"comment\"}, {\"x\": 6.554640293121338, \"y\": 6.724968433380127, \"labels\": \"basically\"}, {\"x\": 1.0180916786193848, \"y\": 3.8836944103240967, \"labels\": \"cucumber\"}, {\"x\": 2.317335844039917, \"y\": 4.0918869972229, \"labels\": \"cardamom\"}, {\"x\": 2.8879547119140625, \"y\": 7.6955366134643555, \"labels\": \"degrees\"}, {\"x\": 5.790859699249268, \"y\": 5.133172512054443, \"labels\": \"commercially\"}, {\"x\": 5.20808744430542, \"y\": 5.714111328125, \"labels\": \"noticeable\"}, {\"x\": 3.6554856300354004, \"y\": 5.762941837310791, \"labels\": \"thicker\"}, {\"x\": 6.710677146911621, \"y\": 5.7371602058410645, \"labels\": \"note\"}, {\"x\": 3.6028008460998535, \"y\": 5.542582988739014, \"labels\": \"semi\"}, {\"x\": 7.1803202629089355, \"y\": 6.317998886108398, \"labels\": \"prepared\"}, {\"x\": 7.5610671043396, \"y\": 5.517582893371582, \"labels\": \"planning\"}, {\"x\": 3.461674928665161, \"y\": 4.502345085144043, \"labels\": \"avocados\"}, {\"x\": 8.68390941619873, \"y\": 5.626601696014404, \"labels\": \"book\"}, {\"x\": 3.8123350143432617, \"y\": 6.967007637023926, \"labels\": \"beforehand\"}, {\"x\": 2.5214297771453857, \"y\": 4.750192642211914, \"labels\": \"plus\"}, {\"x\": 4.183811664581299, \"y\": 6.015056610107422, \"labels\": \"prepped\"}, {\"x\": 1.4080415964126587, \"y\": 3.672351598739624, \"labels\": \"sandwich\"}, {\"x\": 4.693763732910156, \"y\": 5.945913314819336, \"labels\": \"profiles\"}, {\"x\": 2.9424569606781006, \"y\": 3.9405839443206787, \"labels\": \"casseroles\"}, {\"x\": 4.95084285736084, \"y\": 4.611486434936523, \"labels\": \"drumsticks\"}, {\"x\": 6.685805797576904, \"y\": 7.905885696411133, \"labels\": \"needs\"}, {\"x\": 8.59532356262207, \"y\": 6.612070560455322, \"labels\": \"used\"}, {\"x\": 6.828075408935547, \"y\": 6.73823881149292, \"labels\": \"special\"}, {\"x\": 7.9919047355651855, \"y\": 7.275230407714844, \"labels\": \"good\"}, {\"x\": 6.198084831237793, \"y\": 8.173959732055664, \"labels\": \"ruin\"}, {\"x\": 3.249312400817871, \"y\": 3.356600522994995, \"labels\": \"english\"}, {\"x\": 1.4727449417114258, \"y\": 4.291561603546143, \"labels\": \"tomato_sauce\"}, {\"x\": 8.728348731994629, \"y\": 5.744415283203125, \"labels\": \"thread\"}, {\"x\": 3.9015772342681885, \"y\": 6.601110458374023, \"labels\": \"normal\"}, {\"x\": 5.723307132720947, \"y\": 5.0998854637146, \"labels\": \"monthly\"}, {\"x\": 4.376890182495117, \"y\": 3.409449815750122, \"labels\": \"bolognese\"}, {\"x\": 7.403103828430176, \"y\": 6.797637462615967, \"labels\": \"crap\"}, {\"x\": 1.8319145441055298, \"y\": 5.494317054748535, \"labels\": \"bottle\"}, {\"x\": 2.706092357635498, \"y\": 3.6279685497283936, \"labels\": \"hamburger\"}, {\"x\": 6.2412428855896, \"y\": 6.366954803466797, \"labels\": \"solution\"}, {\"x\": 3.419402599334717, \"y\": 6.101076126098633, \"labels\": \"polymerized\"}, {\"x\": 7.133936405181885, \"y\": 3.8273444175720215, \"labels\": \"attachment\"}, {\"x\": 3.7860608100891113, \"y\": 4.635584354400635, \"labels\": \"slurry\"}, {\"x\": 6.429561138153076, \"y\": 6.981810569763184, \"labels\": \"bro\"}, {\"x\": 5.393431663513184, \"y\": 6.74755859375, \"labels\": \"estimate\"}, {\"x\": 4.8807597160339355, \"y\": 6.0535101890563965, \"labels\": \"subjective\"}, {\"x\": 3.75938081741333, \"y\": 4.8514323234558105, \"labels\": \"alternatively\"}, {\"x\": 6.222567081451416, \"y\": 6.561038970947266, \"labels\": \"deglazing\"}, {\"x\": 6.292164325714111, \"y\": 2.7343368530273438, \"labels\": \"korean\"}, {\"x\": 3.272819757461548, \"y\": 5.942743301391602, \"labels\": \"kernel\"}, {\"x\": 6.575107574462891, \"y\": 6.026974201202393, \"labels\": \"sensitive\"}, {\"x\": 8.52210521697998, \"y\": 6.19937801361084, \"labels\": \"issue\"}, {\"x\": 8.294562339782715, \"y\": 6.395785808563232, \"labels\": \"older\"}, {\"x\": 3.2537951469421387, \"y\": 7.327358245849609, \"labels\": \"convection\"}, {\"x\": 5.989785671234131, \"y\": 7.641509056091309, \"labels\": \"allows\"}, {\"x\": 6.348269939422607, \"y\": 6.0591630935668945, \"labels\": \"addicted\"}, {\"x\": 2.2877373695373535, \"y\": 6.410050392150879, \"labels\": \"strain\"}, {\"x\": 8.22477912902832, \"y\": 7.400304317474365, \"labels\": \"certainly\"}, {\"x\": 3.9529571533203125, \"y\": 6.640763759613037, \"labels\": \"anodized\"}, {\"x\": 4.685587406158447, \"y\": 5.45205545425415, \"labels\": \"skillets\"}, {\"x\": 8.240657806396484, \"y\": 4.712470531463623, \"labels\": \"school\"}, {\"x\": 5.246291160583496, \"y\": 5.3214111328125, \"labels\": \"tenderizer\"}, {\"x\": 2.1300852298736572, \"y\": 4.841281414031982, \"labels\": \"extra\"}, {\"x\": 7.753957271575928, \"y\": 7.038265705108643, \"labels\": \"hell\"}, {\"x\": 3.3349251747131348, \"y\": 7.240293025970459, \"labels\": \"apart\"}, {\"x\": 4.420259475708008, \"y\": 4.587673664093018, \"labels\": \"loaves\"}, {\"x\": 8.129193305969238, \"y\": 4.398797512054443, \"labels\": \"party\"}, {\"x\": 8.417912483215332, \"y\": 7.059948921203613, \"labels\": \"hope\"}, {\"x\": 5.280200481414795, \"y\": 5.913142204284668, \"labels\": \"surgery\"}, {\"x\": 4.785184860229492, \"y\": 6.5951642990112305, \"labels\": \"wrapping\"}, {\"x\": 7.097504615783691, \"y\": 7.2023773193359375, \"labels\": \"rarely\"}, {\"x\": 3.4114584922790527, \"y\": 7.365776538848877, \"labels\": \"non_stick\"}, {\"x\": 6.15165901184082, \"y\": 4.9557294845581055, \"labels\": \"lunches\"}, {\"x\": 3.7100625038146973, \"y\": 7.438581943511963, \"labels\": \"wood\"}, {\"x\": 4.2229533195495605, \"y\": 4.844625473022461, \"labels\": \"dipped\"}, {\"x\": 6.016844272613525, \"y\": 6.298848628997803, \"labels\": \"spin\"}, {\"x\": 3.2666051387786865, \"y\": 4.772430896759033, \"labels\": \"dollop\"}, {\"x\": 2.159191846847534, \"y\": 7.013992786407471, \"labels\": \"glass\"}, {\"x\": 8.780058860778809, \"y\": 6.5144195556640625, \"labels\": \"op\"}, {\"x\": 6.997585296630859, \"y\": 4.947788715362549, \"labels\": \"major\"}, {\"x\": 1.0705769062042236, \"y\": 4.577822685241699, \"labels\": \"lime_juice\"}, {\"x\": 6.304195880889893, \"y\": 7.091040134429932, \"labels\": \"admit\"}, {\"x\": 6.896246433258057, \"y\": 4.004177093505859, \"labels\": \"recipes\"}, {\"x\": 7.185827255249023, \"y\": 5.462707996368408, \"labels\": \"expert\"}, {\"x\": 4.675240516662598, \"y\": 7.5339579582214355, \"labels\": \"bacteria\"}, {\"x\": 7.099040508270264, \"y\": 4.8791656494140625, \"labels\": \"london\"}, {\"x\": 3.4589924812316895, \"y\": 5.858811378479004, \"labels\": \"sugars\"}, {\"x\": 2.563983678817749, \"y\": 7.384469509124756, \"labels\": \"once\"}, {\"x\": 7.367187023162842, \"y\": 7.982396602630615, \"labels\": \"could\"}, {\"x\": 3.9037275314331055, \"y\": 3.889481544494629, \"labels\": \"grater\"}, {\"x\": 3.139828681945801, \"y\": 4.193332195281982, \"labels\": \"watermelon\"}, {\"x\": 4.58164119720459, \"y\": 6.993673801422119, \"labels\": \"provide\"}, {\"x\": 6.327380657196045, \"y\": 5.740823268890381, \"labels\": \"anova\"}, {\"x\": 4.3281450271606445, \"y\": 4.081915855407715, \"labels\": \"naan\"}, {\"x\": 1.3327410221099854, \"y\": 4.33504581451416, \"labels\": \"seed\"}, {\"x\": 3.2889251708984375, \"y\": 4.099996089935303, \"labels\": \"hashbrowns\"}, {\"x\": 3.566667318344116, \"y\": 7.017125606536865, \"labels\": \"bare\"}, {\"x\": 5.955346584320068, \"y\": 6.4735517501831055, \"labels\": \"jealous\"}, {\"x\": 5.902552127838135, \"y\": 6.263111591339111, \"labels\": \"hardest\"}, {\"x\": 2.9335055351257324, \"y\": 4.274888515472412, \"labels\": \"combination\"}, {\"x\": 3.686976194381714, \"y\": 6.0884857177734375, \"labels\": \"soaks\"}, {\"x\": 4.57366943359375, \"y\": 6.1357574462890625, \"labels\": \"mineral\"}, {\"x\": 8.135473251342773, \"y\": 7.111685752868652, \"labels\": \"awful\"}, {\"x\": 3.1013898849487305, \"y\": 4.225813388824463, \"labels\": \"rolled\"}, {\"x\": 7.064075469970703, \"y\": 7.675891399383545, \"labels\": \"hurt\"}, {\"x\": 6.096523761749268, \"y\": 7.209637641906738, \"labels\": \"guarantee\"}, {\"x\": 6.862135887145996, \"y\": 6.585751056671143, \"labels\": \"preferences\"}, {\"x\": 0.3366544544696808, \"y\": 4.340406894683838, \"labels\": \"garlic\"}, {\"x\": 3.198134660720825, \"y\": 6.627974987030029, \"labels\": \"scraping\"}, {\"x\": 0.4581235945224762, \"y\": 4.372932434082031, \"labels\": \"flakes\"}, {\"x\": 4.875346660614014, \"y\": 6.562464237213135, \"labels\": \"dropped\"}, {\"x\": 2.7628567218780518, \"y\": 6.902503490447998, \"labels\": \"refrigerator\"}, {\"x\": 5.221956729888916, \"y\": 4.104278564453125, \"labels\": \"bourguignon\"}, {\"x\": 2.495030403137207, \"y\": 6.389620780944824, \"labels\": \"pat\"}, {\"x\": 1.9349751472473145, \"y\": 5.123226165771484, \"labels\": \"blend\"}, {\"x\": 5.523674964904785, \"y\": 4.7227864265441895, \"labels\": \"example\"}, {\"x\": 6.9716081619262695, \"y\": 5.2394514083862305, \"labels\": \"immersion\"}, {\"x\": 3.5710694789886475, \"y\": 6.737052917480469, \"labels\": \"soggy\"}, {\"x\": 2.412323236465454, \"y\": 5.3474345207214355, \"labels\": \"little\"}, {\"x\": 5.254723072052002, \"y\": 4.619605541229248, \"labels\": \"avoiding\"}, {\"x\": 6.289576530456543, \"y\": 5.167298316955566, \"labels\": \"vitamin\"}, {\"x\": 2.760399580001831, \"y\": 6.7624664306640625, \"labels\": \"leftovers\"}, {\"x\": 3.368699073791504, \"y\": 4.950362682342529, \"labels\": \"brick\"}, {\"x\": 8.175561904907227, \"y\": 5.170919895172119, \"labels\": \"own\"}, {\"x\": 2.6371171474456787, \"y\": 3.6935067176818848, \"labels\": \"spanish\"}, {\"x\": 8.413772583007812, \"y\": 7.203000068664551, \"labels\": \"but\"}, {\"x\": 4.211153507232666, \"y\": 5.553972244262695, \"labels\": \"durable\"}, {\"x\": 2.550788640975952, \"y\": 4.3299360275268555, \"labels\": \"tblsp\"}, {\"x\": 3.3326332569122314, \"y\": 3.5494940280914307, \"labels\": \"caesar\"}, {\"x\": 6.713850498199463, \"y\": 4.752382755279541, \"labels\": \"project\"}, {\"x\": 6.842604637145996, \"y\": 7.538328647613525, \"labels\": \"effort\"}, {\"x\": 1.0044262409210205, \"y\": 3.940497875213623, \"labels\": \"lettuce\"}, {\"x\": 6.233128070831299, \"y\": 6.413764953613281, \"labels\": \"timing\"}, {\"x\": 7.764307975769043, \"y\": 5.185159206390381, \"labels\": \"women\"}, {\"x\": 5.382668495178223, \"y\": 6.211976051330566, \"labels\": \"thermometers\"}, {\"x\": 2.650662422180176, \"y\": 5.889962196350098, \"labels\": \"mush\"}, {\"x\": 6.981441020965576, \"y\": 5.179263591766357, \"labels\": \"philadelphia\"}, {\"x\": 1.8601378202438354, \"y\": 5.394155025482178, \"labels\": \"preferably\"}, {\"x\": 6.992091178894043, \"y\": 6.88568639755249, \"labels\": \"proven\"}, {\"x\": 5.44251823425293, \"y\": 6.386603832244873, \"labels\": \"attitude\"}, {\"x\": 1.5666630268096924, \"y\": 4.950318813323975, \"labels\": \"meat\"}, {\"x\": 6.834918975830078, \"y\": 7.172399044036865, \"labels\": \"refrigerated\"}, {\"x\": 3.461808919906616, \"y\": 5.311732769012451, \"labels\": \"ziploc\"}, {\"x\": 8.591670989990234, \"y\": 7.185120582580566, \"labels\": \"hear\"}, {\"x\": 0.941145658493042, \"y\": 3.9237427711486816, \"labels\": \"dressing\"}, {\"x\": 2.9704413414001465, \"y\": 5.302371501922607, \"labels\": \"cob\"}, {\"x\": 8.290494918823242, \"y\": 5.194296360015869, \"labels\": \"at\"}, {\"x\": 4.785400390625, \"y\": 4.366437911987305, \"labels\": \"brisket\"}, {\"x\": 7.7581787109375, \"y\": 6.972681045532227, \"labels\": \"surprised\"}, {\"x\": 3.7128853797912598, \"y\": 5.864988803863525, \"labels\": \"fitting\"}, {\"x\": 3.2066338062286377, \"y\": 7.448668956756592, \"labels\": \"degree\"}, {\"x\": 0.982438862323761, \"y\": 4.449770450592041, \"labels\": \"zest\"}, {\"x\": 5.954375743865967, \"y\": 6.352840900421143, \"labels\": \"wasteful\"}, {\"x\": 5.312666416168213, \"y\": 7.847149848937988, \"labels\": \"skip\"}, {\"x\": 8.40242862701416, \"y\": 5.484471321105957, \"labels\": \"culinary\"}, {\"x\": 1.8797434568405151, \"y\": 5.066901683807373, \"labels\": \"handful\"}, {\"x\": 3.875375986099243, \"y\": 4.098412990570068, \"labels\": \"guinness\"}, {\"x\": 2.609262228012085, \"y\": 7.410881996154785, \"labels\": \"counter\"}, {\"x\": 2.3357813358306885, \"y\": 4.528011322021484, \"labels\": \"sometimes\"}, {\"x\": 0.524124026298523, \"y\": 4.203183174133301, \"labels\": \"rosemary\"}, {\"x\": 4.125842094421387, \"y\": 7.048189163208008, \"labels\": \"stuck\"}, {\"x\": 1.491642951965332, \"y\": 4.919857025146484, \"labels\": \"chunks\"}, {\"x\": 1.390337347984314, \"y\": 4.296347618103027, \"labels\": \"shallots\"}, {\"x\": 7.701205253601074, \"y\": 7.27604341506958, \"labels\": \"able\"}, {\"x\": 8.357598304748535, \"y\": 6.237729072570801, \"labels\": \"already\"}, {\"x\": 7.311058044433594, \"y\": 7.970911026000977, \"labels\": \"won\"}, {\"x\": 6.900885581970215, \"y\": 6.914181232452393, \"labels\": \"terribly\"}, {\"x\": 3.1780641078948975, \"y\": 6.323152542114258, \"labels\": \"mallet\"}, {\"x\": 5.1158037185668945, \"y\": 5.2927937507629395, \"labels\": \"tail\"}, {\"x\": 5.838342189788818, \"y\": 5.895371913909912, \"labels\": \"diets\"}, {\"x\": 5.430953025817871, \"y\": 6.703962326049805, \"labels\": \"office\"}, {\"x\": 8.591312408447266, \"y\": 5.4893364906311035, \"labels\": \"science\"}, {\"x\": 7.897096157073975, \"y\": 7.479536533355713, \"labels\": \"well\"}, {\"x\": 4.139397144317627, \"y\": 7.433806419372559, \"labels\": \"content\"}, {\"x\": 3.101956844329834, \"y\": 3.536364793777466, \"labels\": \"buffalo\"}, {\"x\": 1.8976587057113647, \"y\": 3.907175064086914, \"labels\": \"kidney\"}, {\"x\": 6.1872878074646, \"y\": 4.145143508911133, \"labels\": \"variations\"}, {\"x\": 4.61906099319458, \"y\": 7.120963096618652, \"labels\": \"runs\"}, {\"x\": 3.7059762477874756, \"y\": 3.7868030071258545, \"labels\": \"frosting\"}, {\"x\": 5.8150153160095215, \"y\": 5.481629371643066, \"labels\": \"woks\"}, {\"x\": 6.694180488586426, \"y\": 6.275988578796387, \"labels\": \"vegetarians\"}, {\"x\": 2.77489972114563, \"y\": 3.529270648956299, \"labels\": \"kraft\"}, {\"x\": 2.3346996307373047, \"y\": 4.143099784851074, \"labels\": \"almond\"}, {\"x\": 6.305451393127441, \"y\": 6.103545665740967, \"labels\": \"simplest\"}, {\"x\": 2.9841549396514893, \"y\": 6.826249122619629, \"labels\": \"broken\"}, {\"x\": 0.3864445984363556, \"y\": 4.354501247406006, \"labels\": \"salt_pepper\"}, {\"x\": 6.70053768157959, \"y\": 2.4605321884155273, \"labels\": \"http\"}, {\"x\": 3.8317012786865234, \"y\": 6.060530185699463, \"labels\": \"diameter\"}, {\"x\": 7.075904369354248, \"y\": 5.746633052825928, \"labels\": \"future\"}, {\"x\": 3.1909852027893066, \"y\": 5.875235080718994, \"labels\": \"removing\"}, {\"x\": 1.1816214323043823, \"y\": 3.8332643508911133, \"labels\": \"ketchup\"}, {\"x\": 3.8723292350769043, \"y\": 6.810458660125732, \"labels\": \"below\"}, {\"x\": 1.9870069026947021, \"y\": 5.286513805389404, \"labels\": \"mixing\"}, {\"x\": 2.5001208782196045, \"y\": 7.1279144287109375, \"labels\": \"sink\"}, {\"x\": 6.148331642150879, \"y\": 7.356876850128174, \"labels\": \"convert\"}, {\"x\": 3.7688467502593994, \"y\": 5.82248067855835, \"labels\": \"portions\"}, {\"x\": 5.5606536865234375, \"y\": 6.647028923034668, \"labels\": \"defrosting\"}, {\"x\": 4.745569705963135, \"y\": 5.756882190704346, \"labels\": \"variable\"}, {\"x\": 6.729985237121582, \"y\": 5.710753440856934, \"labels\": \"locally\"}, {\"x\": 4.378477573394775, \"y\": 5.473605632781982, \"labels\": \"blood\"}, {\"x\": 6.405646800994873, \"y\": 4.068741321563721, \"labels\": \"methods\"}, {\"x\": 3.824894666671753, \"y\": 3.6284496784210205, \"labels\": \"gnocchi\"}, {\"x\": 5.715482234954834, \"y\": 6.3134331703186035, \"labels\": \"chosen\"}, {\"x\": 5.191618919372559, \"y\": 8.284102439880371, \"labels\": \"figure\"}, {\"x\": 6.480052471160889, \"y\": 4.031190395355225, \"labels\": \"brands\"}, {\"x\": 5.7491044998168945, \"y\": 6.864356517791748, \"labels\": \"thumbs\"}, {\"x\": 5.256226539611816, \"y\": 6.254998683929443, \"labels\": \"poop\"}, {\"x\": 2.4771053791046143, \"y\": 4.517739295959473, \"labels\": \"palm\"}, {\"x\": 3.812753915786743, \"y\": 4.607177257537842, \"labels\": \"heads\"}, {\"x\": 2.2177813053131104, \"y\": 5.623287200927734, \"labels\": \"dice\"}, {\"x\": 8.106983184814453, \"y\": 4.414850234985352, \"labels\": \"average\"}, {\"x\": 3.15756893157959, \"y\": 4.323493003845215, \"labels\": \"manis\"}, {\"x\": 6.919815540313721, \"y\": 5.7191338539123535, \"labels\": \"reasons\"}, {\"x\": 3.4565823078155518, \"y\": 5.428255081176758, \"labels\": \"packed\"}, {\"x\": 7.0020856857299805, \"y\": 6.177357196807861, \"labels\": \"production\"}, {\"x\": 2.5316197872161865, \"y\": 5.032722473144531, \"labels\": \"light\"}, {\"x\": 0.47270652651786804, \"y\": 4.115659713745117, \"labels\": \"beans\"}, {\"x\": 4.511697769165039, \"y\": 7.47025203704834, \"labels\": \"hotter\"}, {\"x\": 7.050563812255859, \"y\": 3.4610087871551514, \"labels\": \"alt\"}, {\"x\": 6.673083782196045, \"y\": 2.5241599082946777, \"labels\": \"https\"}, {\"x\": 5.467958450317383, \"y\": 4.402101039886475, \"labels\": \"commonly\"}, {\"x\": 8.623298645019531, \"y\": 7.134613513946533, \"labels\": \"sounds\"}, {\"x\": 3.4256432056427, \"y\": 7.608479022979736, \"labels\": \"during\"}, {\"x\": 7.587210655212402, \"y\": 4.765668869018555, \"labels\": \"grew_up\"}, {\"x\": 0.7755094766616821, \"y\": 3.929520845413208, \"labels\": \"spinach\"}, {\"x\": 5.014932155609131, \"y\": 5.185582637786865, \"labels\": \"contrast\"}, {\"x\": 5.354212284088135, \"y\": 5.340746879577637, \"labels\": \"foundation\"}, {\"x\": 2.639955520629883, \"y\": 4.754162311553955, \"labels\": \"mild\"}, {\"x\": 8.225510597229004, \"y\": 6.181537628173828, \"labels\": \"beyond\"}, {\"x\": 8.578706741333008, \"y\": 5.478161811828613, \"labels\": \"kenji\"}, {\"x\": 6.408742904663086, \"y\": 4.066605567932129, \"labels\": \"plenty\"}, {\"x\": 6.68016242980957, \"y\": 2.5942816734313965, \"labels\": \"imgur_com\"}, {\"x\": 3.1705920696258545, \"y\": 4.60530948638916, \"labels\": \"barley\"}, {\"x\": 2.55877423286438, \"y\": 4.577615261077881, \"labels\": \"tbl\"}, {\"x\": 4.74421501159668, \"y\": 4.825328350067139, \"labels\": \"brats\"}, {\"x\": 7.401181697845459, \"y\": 3.960472583770752, \"labels\": \"instant_pot\"}, {\"x\": 1.778949499130249, \"y\": 6.640719413757324, \"labels\": \"put\"}, {\"x\": 3.6149706840515137, \"y\": 6.390058517456055, \"labels\": \"brining\"}, {\"x\": 7.451278209686279, \"y\": 4.523980617523193, \"labels\": \"nights\"}, {\"x\": 0.3997362554073334, \"y\": 4.161019325256348, \"labels\": \"red\"}, {\"x\": 6.454120635986328, \"y\": 5.999042510986328, \"labels\": \"poster\"}, {\"x\": 6.832451820373535, \"y\": 5.040869235992432, \"labels\": \"pla\"}, {\"x\": 6.9413652420043945, \"y\": 4.677430629730225, \"labels\": \"catering\"}, {\"x\": 7.259560585021973, \"y\": 5.495737075805664, \"labels\": \"idiot\"}, {\"x\": 8.532737731933594, \"y\": 6.946774959564209, \"labels\": \"tasted\"}, {\"x\": 7.1606035232543945, \"y\": 6.506982803344727, \"labels\": \"community\"}, {\"x\": 6.82793664932251, \"y\": 2.899935007095337, \"labels\": \"alton_brown\"}, {\"x\": 2.631922960281372, \"y\": 7.056548595428467, \"labels\": \"wait\"}, {\"x\": 8.64238452911377, \"y\": 6.584139823913574, \"labels\": \"stupid\"}, {\"x\": 7.70026969909668, \"y\": 6.453874111175537, \"labels\": \"positive\"}, {\"x\": 7.222700119018555, \"y\": 6.052799224853516, \"labels\": \"mood\"}, {\"x\": 1.2277625799179077, \"y\": 4.621222972869873, \"labels\": \"adding\"}, {\"x\": 7.120314598083496, \"y\": 4.692252159118652, \"labels\": \"shipping\"}, {\"x\": 4.226949691772461, \"y\": 5.111618518829346, \"labels\": \"pounds\"}, {\"x\": 6.462159633636475, \"y\": 3.47878098487854, \"labels\": \"courtesy\"}, {\"x\": 2.544936418533325, \"y\": 3.495486259460449, \"labels\": \"pudding\"}, {\"x\": 4.12792444229126, \"y\": 4.57636833190918, \"labels\": \"dates\"}, {\"x\": 4.943243026733398, \"y\": 6.17772102355957, \"labels\": \"warped\"}, {\"x\": 4.446556091308594, \"y\": 7.358794689178467, \"labels\": \"which\"}, {\"x\": 3.5387837886810303, \"y\": 3.8418033123016357, \"labels\": \"bruschetta\"}, {\"x\": 4.47472620010376, \"y\": 6.23942756652832, \"labels\": \"loose\"}, {\"x\": 6.390052318572998, \"y\": 5.081912040710449, \"labels\": \"resistance\"}, {\"x\": 7.178903102874756, \"y\": 5.272430419921875, \"labels\": \"utility\"}, {\"x\": 4.618842124938965, \"y\": 4.3013224601745605, \"labels\": \"veal\"}, {\"x\": 1.3916735649108887, \"y\": 4.264619827270508, \"labels\": \"cans\"}, {\"x\": 4.812194347381592, \"y\": 6.429046154022217, \"labels\": \"rinsing\"}, {\"x\": 5.847732067108154, \"y\": 7.2987236976623535, \"labels\": \"individually\"}, {\"x\": 7.372546672821045, \"y\": 4.518754959106445, \"labels\": \"north\"}, {\"x\": 3.2689313888549805, \"y\": 6.699785232543945, \"labels\": \"warming\"}, {\"x\": 4.352768421173096, \"y\": 4.309945583343506, \"labels\": \"regularly\"}, {\"x\": 8.046469688415527, \"y\": 4.344201564788818, \"labels\": \"history\"}, {\"x\": 2.844316244125366, \"y\": 6.552569389343262, \"labels\": \"ends\"}, {\"x\": 8.024696350097656, \"y\": 7.253697872161865, \"labels\": \"bad\"}, {\"x\": 6.3712687492370605, \"y\": 6.069422245025635, \"labels\": \"toxins\"}, {\"x\": 4.342657566070557, \"y\": 3.7676584720611572, \"labels\": \"shepherd\"}, {\"x\": 6.750241279602051, \"y\": 2.967729330062866, \"labels\": \"uk\"}, {\"x\": 7.775229454040527, \"y\": 6.539255142211914, \"labels\": \"considering\"}, {\"x\": 3.3264904022216797, \"y\": 6.12336540222168, \"labels\": \"sweat\"}, {\"x\": 1.8584023714065552, \"y\": 6.101465225219727, \"labels\": \"spoon\"}, {\"x\": 2.0712502002716064, \"y\": 3.94461727142334, \"labels\": \"cornmeal\"}, {\"x\": 0.6417363286018372, \"y\": 4.404513359069824, \"labels\": \"ground\"}, {\"x\": 5.845791816711426, \"y\": 5.986310005187988, \"labels\": \"manner\"}, {\"x\": 3.432786703109741, \"y\": 6.119687080383301, \"labels\": \"cooler\"}, {\"x\": 6.614199161529541, \"y\": 4.11314058303833, \"labels\": \"options\"}, {\"x\": 3.379065752029419, \"y\": 7.27888298034668, \"labels\": \"nonstick\"}, {\"x\": 5.277058124542236, \"y\": 5.082754611968994, \"labels\": \"weekly\"}, {\"x\": 5.027270793914795, \"y\": 5.248687267303467, \"labels\": \"carolina\"}, {\"x\": 6.704348087310791, \"y\": 3.7623658180236816, \"labels\": \"image\"}, {\"x\": 3.81626558303833, \"y\": 4.77567720413208, \"labels\": \"triple\"}, {\"x\": 2.9357292652130127, \"y\": 7.231143474578857, \"labels\": \"size\"}, {\"x\": 2.7742748260498047, \"y\": 6.935245513916016, \"labels\": \"center\"}, {\"x\": 6.098110675811768, \"y\": 4.963778018951416, \"labels\": \"experimenting\"}, {\"x\": 3.581620454788208, \"y\": 3.5144503116607666, \"labels\": \"minestrone\"}, {\"x\": 6.245776653289795, \"y\": 5.744897365570068, \"labels\": \"whiskey\"}, {\"x\": 5.84395170211792, \"y\": 6.520950794219971, \"labels\": \"angle\"}, {\"x\": 5.455301284790039, \"y\": 6.217064380645752, \"labels\": \"rotating\"}, {\"x\": 0.3546977937221527, \"y\": 4.30925178527832, \"labels\": \"onions\"}, {\"x\": 7.205132961273193, \"y\": 7.275423049926758, \"labels\": \"ocean\"}, {\"x\": 8.139973640441895, \"y\": 5.200984001159668, \"labels\": \"boyfriend\"}, {\"x\": 2.446627378463745, \"y\": 4.619355201721191, \"labels\": \"divided\"}, {\"x\": 4.929092884063721, \"y\": 5.0593390464782715, \"labels\": \"shoe\"}, {\"x\": 3.5149283409118652, \"y\": 5.763485431671143, \"labels\": \"bars\"}, {\"x\": 3.568321704864502, \"y\": 5.157988548278809, \"labels\": \"reduced\"}, {\"x\": 8.254534721374512, \"y\": 6.983211994171143, \"labels\": \"myself\"}, {\"x\": 6.8712382316589355, \"y\": 6.310452461242676, \"labels\": \"hates\"}, {\"x\": 5.794161319732666, \"y\": 6.596095561981201, \"labels\": \"whats\"}, {\"x\": 4.524167060852051, \"y\": 4.168462753295898, \"labels\": \"sliders\"}, {\"x\": 7.774439334869385, \"y\": 6.230638027191162, \"labels\": \"sadly\"}, {\"x\": 4.2946038246154785, \"y\": 5.075880527496338, \"labels\": \"flower\"}, {\"x\": 1.331557273864746, \"y\": 4.37733268737793, \"labels\": \"white_wine\"}, {\"x\": 5.889868259429932, \"y\": 6.752867698669434, \"labels\": \"confirm\"}, {\"x\": 5.219125747680664, \"y\": 6.697801113128662, \"labels\": \"ripen\"}, {\"x\": 5.525230884552002, \"y\": 6.568934440612793, \"labels\": \"insight\"}, {\"x\": 3.605201482772827, \"y\": 6.19291877746582, \"labels\": \"outer\"}, {\"x\": 7.614373683929443, \"y\": 6.517305850982666, \"labels\": \"useless\"}, {\"x\": 8.334672927856445, \"y\": 4.958801746368408, \"labels\": \"family\"}, {\"x\": 3.3866870403289795, \"y\": 4.001138687133789, \"labels\": \"aka\"}, {\"x\": 5.700744152069092, \"y\": 4.317875862121582, \"labels\": \"diy\"}, {\"x\": 4.064493656158447, \"y\": 7.019629955291748, \"labels\": \"falling\"}, {\"x\": 7.802148818969727, \"y\": 5.034032821655273, \"labels\": \"step\"}, {\"x\": 3.997673749923706, \"y\": 7.061891078948975, \"labels\": \"oxygen\"}, {\"x\": 1.8668736219406128, \"y\": 6.440124034881592, \"labels\": \"melt\"}, {\"x\": 1.9749282598495483, \"y\": 3.8389482498168945, \"labels\": \"whipped\"}, {\"x\": 2.207674980163574, \"y\": 3.8128750324249268, \"labels\": \"relish\"}, {\"x\": 6.74644660949707, \"y\": 4.514833450317383, \"labels\": \"west\"}, {\"x\": 4.700438499450684, \"y\": 5.710817813873291, \"labels\": \"rubbery\"}, {\"x\": 1.718133568763733, \"y\": 4.0980448722839355, \"labels\": \"beef\"}, {\"x\": 1.8965989351272583, \"y\": 3.9589290618896484, \"labels\": \"crackers\"}, {\"x\": 6.324333667755127, \"y\": 2.730475664138794, \"labels\": \"mexican\"}, {\"x\": 2.5819008350372314, \"y\": 4.016534328460693, \"labels\": \"tamarind\"}, {\"x\": 8.212667465209961, \"y\": 5.749204635620117, \"labels\": \"professional\"}, {\"x\": 4.431253910064697, \"y\": 4.408759117126465, \"labels\": \"coloring\"}, {\"x\": 5.242129325866699, \"y\": 7.712050437927246, \"labels\": \"otherwise\"}, {\"x\": 2.0801289081573486, \"y\": 5.6419758796691895, \"labels\": \"container\"}, {\"x\": 4.683508396148682, \"y\": 4.75396728515625, \"labels\": \"peeling\"}, {\"x\": 7.889804840087891, \"y\": 7.8139142990112305, \"labels\": \"care\"}, {\"x\": 1.7566032409667969, \"y\": 4.1545023918151855, \"labels\": \"turkey\"}, {\"x\": 6.833352565765381, \"y\": 3.4991660118103027, \"labels\": \"php\"}, {\"x\": 3.9761316776275635, \"y\": 4.648174285888672, \"labels\": \"pear\"}, {\"x\": 3.5490200519561768, \"y\": 5.876730918884277, \"labels\": \"levels\"}, {\"x\": 5.141011714935303, \"y\": 4.943113327026367, \"labels\": \"zojirushi\"}, {\"x\": 3.552791118621826, \"y\": 4.988452911376953, \"labels\": \"sofrito\"}, {\"x\": 3.236790895462036, \"y\": 3.7050538063049316, \"labels\": \"boxed\"}, {\"x\": 7.339156150817871, \"y\": 6.380410194396973, \"labels\": \"disease\"}, {\"x\": 3.686218023300171, \"y\": 7.646398067474365, \"labels\": \"temps\"}, {\"x\": 5.5235209465026855, \"y\": 5.610764980316162, \"labels\": \"garnishes\"}, {\"x\": 7.735681056976318, \"y\": 6.987685680389404, \"labels\": \"im\"}, {\"x\": 3.7152345180511475, \"y\": 4.915131092071533, \"labels\": \"gin\"}, {\"x\": 4.757078170776367, \"y\": 6.870208740234375, \"labels\": \"plane\"}, {\"x\": 7.944411277770996, \"y\": 7.033970832824707, \"labels\": \"interested\"}, {\"x\": 4.371096134185791, \"y\": 6.937551021575928, \"labels\": \"stain\"}, {\"x\": 2.8106329441070557, \"y\": 3.9542243480682373, \"labels\": \"hearts\"}, {\"x\": 7.16472053527832, \"y\": 4.476659774780273, \"labels\": \"chicago\"}, {\"x\": 8.501045227050781, \"y\": 7.2420148849487305, \"labels\": \"trust\"}, {\"x\": 3.2149689197540283, \"y\": 6.1548686027526855, \"labels\": \"bubbling\"}, {\"x\": 5.11498498916626, \"y\": 6.823093414306641, \"labels\": \"afterward\"}, {\"x\": 6.291991233825684, \"y\": 6.751541614532471, \"labels\": \"themselves\"}, {\"x\": 8.216072082519531, \"y\": 5.904671669006348, \"labels\": \"shows\"}, {\"x\": 8.471932411193848, \"y\": 5.555779457092285, \"labels\": \"youtube\"}, {\"x\": 6.595358371734619, \"y\": 5.81730842590332, \"labels\": \"adapted\"}, {\"x\": 4.539555549621582, \"y\": 6.956942081451416, \"labels\": \"thawing\"}, {\"x\": 6.146265983581543, \"y\": 8.12971305847168, \"labels\": \"need\"}, {\"x\": 7.467350006103516, \"y\": 7.629629611968994, \"labels\": \"isn\"}, {\"x\": 3.3898792266845703, \"y\": 5.210727214813232, \"labels\": \"rich\"}, {\"x\": 3.3096601963043213, \"y\": 6.440384387969971, \"labels\": \"interior\"}, {\"x\": 5.331601619720459, \"y\": 4.586664199829102, \"labels\": \"omg\"}, {\"x\": 2.6724624633789062, \"y\": 3.5532941818237305, \"labels\": \"masala\"}, {\"x\": 2.690666675567627, \"y\": 6.882293701171875, \"labels\": \"everything\"}, {\"x\": 7.134219646453857, \"y\": 6.188842296600342, \"labels\": \"alright\"}, {\"x\": 4.998263359069824, \"y\": 5.953760147094727, \"labels\": \"shelves\"}, {\"x\": 7.903326988220215, \"y\": 5.178884506225586, \"labels\": \"favourite\"}, {\"x\": 3.463905096054077, \"y\": 6.710360050201416, \"labels\": \"evaporates\"}, {\"x\": 5.856169700622559, \"y\": 7.624382019042969, \"labels\": \"maintain\"}, {\"x\": 2.646953821182251, \"y\": 6.632842540740967, \"labels\": \"pouring\"}, {\"x\": 3.701352119445801, \"y\": 4.277644634246826, \"labels\": \"cherries\"}, {\"x\": 5.101835250854492, \"y\": 4.0073652267456055, \"labels\": \"essentially\"}, {\"x\": 6.9576945304870605, \"y\": 6.620416164398193, \"labels\": \"strict\"}, {\"x\": 5.369065761566162, \"y\": 6.773499965667725, \"labels\": \"cleanup\"}, {\"x\": 3.2042059898376465, \"y\": 6.9796142578125, \"labels\": \"wooden\"}, {\"x\": 7.754852294921875, \"y\": 6.243798732757568, \"labels\": \"hers\"}, {\"x\": 6.517597675323486, \"y\": 5.153730392456055, \"labels\": \"gif\"}, {\"x\": 5.605128288269043, \"y\": 5.174427509307861, \"labels\": \"department\"}, {\"x\": 1.084439754486084, \"y\": 4.149028301239014, \"labels\": \"bacon\"}, {\"x\": 1.4412920475006104, \"y\": 4.4233222007751465, \"labels\": \"maybe\"}, {\"x\": 2.951958417892456, \"y\": 4.427707195281982, \"labels\": \"puff\"}, {\"x\": 6.567994594573975, \"y\": 5.673149108886719, \"labels\": \"street\"}, {\"x\": 2.3879549503326416, \"y\": 4.599241256713867, \"labels\": \"sea\"}, {\"x\": 2.5841007232666016, \"y\": 7.271227836608887, \"labels\": \"under\"}, {\"x\": 3.5429012775421143, \"y\": 4.423245429992676, \"labels\": \"gizzards\"}, {\"x\": 7.502926349639893, \"y\": 4.715746879577637, \"labels\": \"kitchens\"}, {\"x\": 8.542566299438477, \"y\": 5.740859508514404, \"labels\": \"link\"}, {\"x\": 6.946504592895508, \"y\": 6.20239782333374, \"labels\": \"bill\"}, {\"x\": 5.575119495391846, \"y\": 5.509794235229492, \"labels\": \"freezes\"}, {\"x\": 1.57733952999115, \"y\": 3.8597774505615234, \"labels\": \"tortilla\"}, {\"x\": 5.071837425231934, \"y\": 5.4236650466918945, \"labels\": \"silicone\"}, {\"x\": 3.9543111324310303, \"y\": 6.153151512145996, \"labels\": \"wide\"}, {\"x\": 6.97678279876709, \"y\": 4.125519275665283, \"labels\": \"places\"}, {\"x\": 5.991847038269043, \"y\": 7.789251804351807, \"labels\": \"survive\"}, {\"x\": 3.5840861797332764, \"y\": 3.5934202671051025, \"labels\": \"cottage\"}, {\"x\": 6.000112533569336, \"y\": 5.918627738952637, \"labels\": \"management\"}, {\"x\": 0.5806573033332825, \"y\": 4.037657260894775, \"labels\": \"canned\"}, {\"x\": 3.627833604812622, \"y\": 6.604161739349365, \"labels\": \"score\"}, {\"x\": 7.774322986602783, \"y\": 5.248653888702393, \"labels\": \"age\"}, {\"x\": 0.7523730397224426, \"y\": 4.289272308349609, \"labels\": \"herbs\"}, {\"x\": 7.992501735687256, \"y\": 7.70198917388916, \"labels\": \"matter\"}, {\"x\": 3.713613510131836, \"y\": 3.7879037857055664, \"labels\": \"tongue\"}, {\"x\": 6.9378485679626465, \"y\": 3.5730860233306885, \"labels\": \"basic\"}, {\"x\": 3.13554310798645, \"y\": 4.011971473693848, \"labels\": \"deviled\"}, {\"x\": 2.6708149909973145, \"y\": 4.443697452545166, \"labels\": \"serrano\"}, {\"x\": 7.852180480957031, \"y\": 5.532130718231201, \"labels\": \"memory\"}, {\"x\": 5.7082366943359375, \"y\": 8.446873664855957, \"labels\": \"help\"}, {\"x\": 7.289266586303711, \"y\": 4.12884521484375, \"labels\": \"local\"}, {\"x\": 7.984513759613037, \"y\": 5.221602916717529, \"labels\": \"brother\"}, {\"x\": 6.683803558349609, \"y\": 3.0433082580566406, \"labels\": \"views\"}, {\"x\": 3.9366350173950195, \"y\": 4.197068214416504, \"labels\": \"pb\"}, {\"x\": 7.977307319641113, \"y\": 7.070072174072266, \"labels\": \"yea\"}, {\"x\": 3.371108055114746, \"y\": 5.277141571044922, \"labels\": \"wedge\"}, {\"x\": 5.847555160522461, \"y\": 6.664875030517578, \"labels\": \"audience\"}, {\"x\": 2.0659470558166504, \"y\": 5.339677333831787, \"labels\": \"loaf\"}, {\"x\": 6.986275672912598, \"y\": 5.201096057891846, \"labels\": \"allergies\"}, {\"x\": 0.8037055134773254, \"y\": 4.791374206542969, \"labels\": \"sugar\"}, {\"x\": 4.442068099975586, \"y\": 6.881374835968018, \"labels\": \"create\"}, {\"x\": 0.8840709328651428, \"y\": 4.069164752960205, \"labels\": \"avocado\"}, {\"x\": 7.5984296798706055, \"y\": 6.839865684509277, \"labels\": \"guests\"}, {\"x\": 7.830981254577637, \"y\": 7.641260147094727, \"labels\": \"super\"}, {\"x\": 2.3960602283477783, \"y\": 6.927770614624023, \"labels\": \"up\"}, {\"x\": 5.969452381134033, \"y\": 5.794559478759766, \"labels\": \"incorrect\"}, {\"x\": 2.5897743701934814, \"y\": 7.382362365722656, \"labels\": \"hand\"}, {\"x\": 6.271230697631836, \"y\": 3.965367555618286, \"labels\": \"bunch\"}, {\"x\": 8.226866722106934, \"y\": 5.1419572830200195, \"labels\": \"husband\"}, {\"x\": 7.103291988372803, \"y\": 4.197279930114746, \"labels\": \"ethnic\"}, {\"x\": 5.687714099884033, \"y\": 4.462714195251465, \"labels\": \"regional\"}, {\"x\": 8.180066108703613, \"y\": 4.658642768859863, \"labels\": \"christmas\"}, {\"x\": 6.999248027801514, \"y\": 6.65447473526001, \"labels\": \"elsewhere\"}, {\"x\": 5.210882186889648, \"y\": 7.632514953613281, \"labels\": \"wear\"}, {\"x\": 7.674816608428955, \"y\": 6.371407508850098, \"labels\": \"assuming\"}, {\"x\": 1.11138916015625, \"y\": 4.2906036376953125, \"labels\": \"worcestershire\"}, {\"x\": 1.1492817401885986, \"y\": 3.6727426052093506, \"labels\": \"grilled\"}, {\"x\": 7.206957817077637, \"y\": 6.487314224243164, \"labels\": \"mods\"}, {\"x\": 7.166741847991943, \"y\": 5.959636211395264, \"labels\": \"depends\"}, {\"x\": 5.49459981918335, \"y\": 7.623874664306641, \"labels\": \"reheat\"}, {\"x\": 8.342597961425781, \"y\": 4.454366207122803, \"labels\": \"three\"}, {\"x\": 3.9402356147766113, \"y\": 4.0534281730651855, \"labels\": \"voila\"}, {\"x\": 6.246786117553711, \"y\": 7.567970275878906, \"labels\": \"harder\"}, {\"x\": 6.826022148132324, \"y\": 3.0761163234710693, \"labels\": \"lab\"}, {\"x\": 2.592686414718628, \"y\": 3.772125482559204, \"labels\": \"yoghurt\"}, {\"x\": 5.052669525146484, \"y\": 5.431904315948486, \"labels\": \"endless\"}, {\"x\": 5.388371467590332, \"y\": 8.517298698425293, \"labels\": \"stick\"}, {\"x\": 7.81463623046875, \"y\": 6.169827461242676, \"labels\": \"perfect\"}, {\"x\": 2.293694496154785, \"y\": 6.978682518005371, \"labels\": \"warm\"}, {\"x\": 5.586957931518555, \"y\": 6.518589496612549, \"labels\": \"material\"}, {\"x\": 2.4817252159118652, \"y\": 3.878066301345825, \"labels\": \"chilis\"}, {\"x\": 6.511001110076904, \"y\": 7.523723602294922, \"labels\": \"goes\"}, {\"x\": 6.914601802825928, \"y\": 6.137326717376709, \"labels\": \"serves\"}, {\"x\": 2.8157079219818115, \"y\": 3.8026392459869385, \"labels\": \"breads\"}, {\"x\": 3.566757917404175, \"y\": 5.077054500579834, \"labels\": \"grains\"}, {\"x\": 2.766993761062622, \"y\": 4.088571548461914, \"labels\": \"sticks\"}, {\"x\": 8.42999267578125, \"y\": 7.169424057006836, \"labels\": \"realize\"}, {\"x\": 6.754336357116699, \"y\": 3.1898696422576904, \"labels\": \"net\"}, {\"x\": 4.288018226623535, \"y\": 4.691662311553955, \"labels\": \"porridge\"}, {\"x\": 3.1556220054626465, \"y\": 3.953193426132202, \"labels\": \"asiago\"}, {\"x\": 3.9956085681915283, \"y\": 3.826019763946533, \"labels\": \"poutine\"}, {\"x\": 2.532846212387085, \"y\": 6.436302661895752, \"labels\": \"excess\"}, {\"x\": 3.5598037242889404, \"y\": 7.063232421875, \"labels\": \"enameled\"}, {\"x\": 8.04189395904541, \"y\": 7.141758918762207, \"labels\": \"great\"}, {\"x\": 7.644738674163818, \"y\": 6.206289768218994, \"labels\": \"talking\"}, {\"x\": 5.9383015632629395, \"y\": 4.837442874908447, \"labels\": \"okra\"}, {\"x\": 3.021456241607666, \"y\": 6.685159206390381, \"labels\": \"bite\"}, {\"x\": 6.216198444366455, \"y\": 6.4367780685424805, \"labels\": \"googling\"}, {\"x\": 8.400847434997559, \"y\": 6.320879936218262, \"labels\": \"master\"}, {\"x\": 7.224620342254639, \"y\": 6.031856060028076, \"labels\": \"relevant\"}, {\"x\": 0.6595963835716248, \"y\": 4.335636615753174, \"labels\": \"grated\"}, {\"x\": 2.584568738937378, \"y\": 6.005905628204346, \"labels\": \"crust\"}, {\"x\": 3.134206771850586, \"y\": 3.7347910404205322, \"labels\": \"enchilada\"}, {\"x\": 7.082167625427246, \"y\": 6.053431034088135, \"labels\": \"listen\"}, {\"x\": 5.6034746170043945, \"y\": 6.77815055847168, \"labels\": \"slight\"}, {\"x\": 5.504221439361572, \"y\": 5.3993916511535645, \"labels\": \"kicks\"}, {\"x\": 3.991746187210083, \"y\": 7.136843204498291, \"labels\": \"stays\"}, {\"x\": 4.532861709594727, \"y\": 4.573799133300781, \"labels\": \"marshmallow\"}, {\"x\": 5.5314788818359375, \"y\": 5.303810119628906, \"labels\": \"torch\"}, {\"x\": 2.849853277206421, \"y\": 7.233160972595215, \"labels\": \"later\"}, {\"x\": 8.572576522827148, \"y\": 6.630697250366211, \"labels\": \"ive\"}, {\"x\": 7.088293075561523, \"y\": 5.783781051635742, \"labels\": \"explained\"}, {\"x\": 0.6810193061828613, \"y\": 4.209331035614014, \"labels\": \"orange\"}, {\"x\": 4.792644023895264, \"y\": 4.012946605682373, \"labels\": \"alla\"}, {\"x\": 7.579687118530273, \"y\": 4.8302083015441895, \"labels\": \"their\"}, {\"x\": 2.62270188331604, \"y\": 4.441011905670166, \"labels\": \"sunflower\"}, {\"x\": 3.305556297302246, \"y\": 5.8445000648498535, \"labels\": \"punch\"}, {\"x\": 5.7601399421691895, \"y\": 6.047818183898926, \"labels\": \"becoming\"}, {\"x\": 2.571661949157715, \"y\": 6.946372985839844, \"labels\": \"it\"}, {\"x\": 7.558362007141113, \"y\": 6.985001087188721, \"labels\": \"wondered\"}, {\"x\": 7.1258625984191895, \"y\": 6.422816753387451, \"labels\": \"nervous\"}, {\"x\": 1.0380645990371704, \"y\": 4.057088851928711, \"labels\": \"peanut_butter\"}, {\"x\": 6.582225322723389, \"y\": 5.985978126525879, \"labels\": \"commenter\"}, {\"x\": 6.349850654602051, \"y\": 4.11475944519043, \"labels\": \"sorts\"}, {\"x\": 3.6136882305145264, \"y\": 4.881536960601807, \"labels\": \"coke\"}, {\"x\": 8.246466636657715, \"y\": 5.966862201690674, \"labels\": \"near\"}, {\"x\": 7.339977741241455, \"y\": 7.397660255432129, \"labels\": \"hate\"}, {\"x\": 6.531297206878662, \"y\": 5.660543441772461, \"labels\": \"language\"}, {\"x\": 2.4308831691741943, \"y\": 4.821178913116455, \"labels\": \"ml\"}, {\"x\": 4.487218856811523, \"y\": 3.9653875827789307, \"labels\": \"meatball\"}, {\"x\": 5.740053176879883, \"y\": 5.557837009429932, \"labels\": \"ratios\"}, {\"x\": 6.212020397186279, \"y\": 4.896401882171631, \"labels\": \"retailers\"}, {\"x\": 2.880667209625244, \"y\": 4.103610038757324, \"labels\": \"tarragon\"}, {\"x\": 5.912330627441406, \"y\": 6.796320915222168, \"labels\": \"beautifully\"}, {\"x\": 0.8245802521705627, \"y\": 4.433887481689453, \"labels\": \"oz\"}, {\"x\": 5.979602813720703, \"y\": 6.299829959869385, \"labels\": \"advantage\"}, {\"x\": 3.127998113632202, \"y\": 7.51243257522583, \"labels\": \"cast_iron\"}, {\"x\": 6.690619945526123, \"y\": 2.585196018218994, \"labels\": \"youtube_com\"}, {\"x\": 6.026767730712891, \"y\": 7.873101711273193, \"labels\": \"spend\"}, {\"x\": 5.396109580993652, \"y\": 6.057713985443115, \"labels\": \"rain\"}, {\"x\": 4.628107070922852, \"y\": 6.008411884307861, \"labels\": \"complexity\"}, {\"x\": 7.018554210662842, \"y\": 5.499425411224365, \"labels\": \"tool\"}, {\"x\": 6.017714023590088, \"y\": 5.7398152351379395, \"labels\": \"vegas\"}, {\"x\": 2.1754772663116455, \"y\": 7.242162227630615, \"labels\": \"stove\"}, {\"x\": 5.408318042755127, \"y\": 6.064922332763672, \"labels\": \"demand\"}, {\"x\": 6.214356899261475, \"y\": 5.208880424499512, \"labels\": \"trich\"}, {\"x\": 3.566514492034912, \"y\": 5.618463039398193, \"labels\": \"elbow\"}, {\"x\": 6.305370807647705, \"y\": 5.812980651855469, \"labels\": \"worried\"}, {\"x\": 3.330720901489258, \"y\": 4.223029136657715, \"labels\": \"campbell\"}, {\"x\": 4.362678527832031, \"y\": 5.048546314239502, \"labels\": \"runny\"}, {\"x\": 3.3653147220611572, \"y\": 6.3130574226379395, \"labels\": \"crepe\"}, {\"x\": 6.608022212982178, \"y\": 2.5737593173980713, \"labels\": \"style\"}, {\"x\": 4.315965175628662, \"y\": 5.436560153961182, \"labels\": \"grainy\"}, {\"x\": 7.611731052398682, \"y\": 7.123800277709961, \"labels\": \"disappointed\"}, {\"x\": 5.222583770751953, \"y\": 6.927957534790039, \"labels\": \"lick\"}, {\"x\": 6.185327529907227, \"y\": 6.891838073730469, \"labels\": \"isnt\"}, {\"x\": 7.418067455291748, \"y\": 5.075168132781982, \"labels\": \"sale\"}, {\"x\": 8.357925415039062, \"y\": 6.771433353424072, \"labels\": \"hadn\"}, {\"x\": 0.5610551238059998, \"y\": 4.311991214752197, \"labels\": \"balsamic\"}, {\"x\": 7.362478733062744, \"y\": 7.990809440612793, \"labels\": \"might\"}, {\"x\": 2.8634865283966064, \"y\": 6.4468302726745605, \"labels\": \"colander\"}, {\"x\": 5.3841681480407715, \"y\": 8.518260955810547, \"labels\": \"burn\"}, {\"x\": 6.782533168792725, \"y\": 6.367081642150879, \"labels\": \"deleted\"}, {\"x\": 2.9020259380340576, \"y\": 7.315549850463867, \"labels\": \"frying\"}, {\"x\": 1.4200801849365234, \"y\": 4.623449325561523, \"labels\": \"ground_beef\"}, {\"x\": 6.765690803527832, \"y\": 6.299336910247803, \"labels\": \"grand\"}, {\"x\": 3.626081705093384, \"y\": 5.621257781982422, \"labels\": \"scraper\"}, {\"x\": 8.621330261230469, \"y\": 5.52473783493042, \"labels\": \"article\"}, {\"x\": 2.412648916244507, \"y\": 4.4974284172058105, \"labels\": \"sherry\"}, {\"x\": 3.231072187423706, \"y\": 4.254310607910156, \"labels\": \"blueberries\"}, {\"x\": 2.989084005355835, \"y\": 3.5187599658966064, \"labels\": \"lentil\"}, {\"x\": 6.273441791534424, \"y\": 5.379430770874023, \"labels\": \"kiwi\"}, {\"x\": 5.080235481262207, \"y\": 3.5714497566223145, \"labels\": \"vegetarian\"}, {\"x\": 2.1430177688598633, \"y\": 3.7110178470611572, \"labels\": \"pancakes\"}, {\"x\": 3.0207316875457764, \"y\": 4.7522430419921875, \"labels\": \"mushy\"}, {\"x\": 4.33328914642334, \"y\": 6.8468241691589355, \"labels\": \"ph\"}, {\"x\": 3.7028918266296387, \"y\": 4.543966293334961, \"labels\": \"rotisserie\"}, {\"x\": 6.9775710105896, \"y\": 6.378275394439697, \"labels\": \"grateful\"}, {\"x\": 5.964676380157471, \"y\": 5.581533432006836, \"labels\": \"um\"}, {\"x\": 3.082331657409668, \"y\": 3.5062665939331055, \"labels\": \"dressings\"}, {\"x\": 4.731013774871826, \"y\": 5.376656532287598, \"labels\": \"bargain\"}, {\"x\": 1.7332403659820557, \"y\": 4.158234596252441, \"labels\": \"brussel\"}, {\"x\": 6.746783256530762, \"y\": 6.5265889167785645, \"labels\": \"attack\"}, {\"x\": 5.820985794067383, \"y\": 6.057641506195068, \"labels\": \"projects\"}, {\"x\": 2.8954973220825195, \"y\": 6.25445556640625, \"labels\": \"soften\"}, {\"x\": 5.305903434753418, \"y\": 6.961918354034424, \"labels\": \"scratches\"}, {\"x\": 6.604188919067383, \"y\": 6.491336345672607, \"labels\": \"realised\"}, {\"x\": 7.969656467437744, \"y\": 7.64376974105835, \"labels\": \"agree\"}, {\"x\": 7.076029300689697, \"y\": 6.105005264282227, \"labels\": \"title\"}, {\"x\": 3.5237996578216553, \"y\": 4.657929420471191, \"labels\": \"safflower\"}, {\"x\": 5.41539192199707, \"y\": 8.033058166503906, \"labels\": \"play\"}, {\"x\": 2.928295612335205, \"y\": 7.229061126708984, \"labels\": \"letting\"}, {\"x\": 6.448564529418945, \"y\": 4.479473114013672, \"labels\": \"problems\"}, {\"x\": 4.309711456298828, \"y\": 5.889935493469238, \"labels\": \"sweeter\"}, {\"x\": 6.318645477294922, \"y\": 5.913280963897705, \"labels\": \"approximate\"}, {\"x\": 6.710862636566162, \"y\": 5.220696926116943, \"labels\": \"thoughts\"}, {\"x\": 6.320001125335693, \"y\": 4.2150397300720215, \"labels\": \"sizes\"}, {\"x\": 7.53045654296875, \"y\": 5.976225852966309, \"labels\": \"late\"}, {\"x\": 2.466085433959961, \"y\": 7.384653568267822, \"labels\": \"until\"}, {\"x\": 3.9522409439086914, \"y\": 5.56152868270874, \"labels\": \"either\"}, {\"x\": 8.33426570892334, \"y\": 6.862043380737305, \"labels\": \"kid\"}, {\"x\": 2.4770171642303467, \"y\": 7.212693691253662, \"labels\": \"on\"}, {\"x\": 6.793121814727783, \"y\": 4.135697841644287, \"labels\": \"ideas\"}, {\"x\": 7.302369594573975, \"y\": 7.238073348999023, \"labels\": \"smell\"}, {\"x\": 7.809536457061768, \"y\": 7.787541389465332, \"labels\": \"too\"}, {\"x\": 3.5858352184295654, \"y\": 4.455844879150391, \"labels\": \"emulsifier\"}, {\"x\": 4.46362829208374, \"y\": 7.815502643585205, \"labels\": \"aside\"}, {\"x\": 7.614939212799072, \"y\": 5.321625709533691, \"labels\": \"machine\"}, {\"x\": 5.692379951477051, \"y\": 5.950806140899658, \"labels\": \"substitutions\"}, {\"x\": 7.770902633666992, \"y\": 7.634581565856934, \"labels\": \"fairly\"}, {\"x\": 6.788163661956787, \"y\": 3.414130926132202, \"labels\": \"blogs\"}, {\"x\": 4.77229642868042, \"y\": 5.256381511688232, \"labels\": \"pads\"}, {\"x\": 3.996591806411743, \"y\": 6.4495673179626465, \"labels\": \"hair\"}, {\"x\": 6.161503314971924, \"y\": 8.116774559020996, \"labels\": \"cause\"}, {\"x\": 5.430133819580078, \"y\": 6.264133930206299, \"labels\": \"sumac\"}, {\"x\": 6.664398670196533, \"y\": 3.4119231700897217, \"labels\": \"nytimes\"}, {\"x\": 5.28869104385376, \"y\": 7.472705841064453, \"labels\": \"ended_up\"}, {\"x\": 4.918881416320801, \"y\": 8.20695686340332, \"labels\": \"coming\"}, {\"x\": 4.587245464324951, \"y\": 4.998424530029297, \"labels\": \"stronger\"}, {\"x\": 3.4105868339538574, \"y\": 3.554460287094116, \"labels\": \"custard\"}, {\"x\": 3.213489532470703, \"y\": 7.521877765655518, \"labels\": \"gas\"}, {\"x\": 4.108169078826904, \"y\": 7.517597198486328, \"labels\": \"keeping\"}, {\"x\": 5.670831203460693, \"y\": 5.627157211303711, \"labels\": \"cats\"}, {\"x\": 3.095658302307129, \"y\": 3.3147614002227783, \"labels\": \"breakfast\"}, {\"x\": 3.7488772869110107, \"y\": 5.231939315795898, \"labels\": \"sharp\"}, {\"x\": 2.6491851806640625, \"y\": 3.485201597213745, \"labels\": \"veggie\"}, {\"x\": 7.9335551261901855, \"y\": 4.393527030944824, \"labels\": \"single\"}, {\"x\": 7.088091850280762, \"y\": 7.483561038970947, \"labels\": \"refuse\"}, {\"x\": 5.808167934417725, \"y\": 7.714393138885498, \"labels\": \"money\"}, {\"x\": 3.8956027030944824, \"y\": 5.266147136688232, \"labels\": \"flesh\"}, {\"x\": 4.597123622894287, \"y\": 6.824495315551758, \"labels\": \"mid\"}, {\"x\": 4.817281723022461, \"y\": 4.505287170410156, \"labels\": \"chick\"}, {\"x\": 5.434845924377441, \"y\": 8.432750701904297, \"labels\": \"check\"}, {\"x\": 0.7263608574867249, \"y\": 4.225512981414795, \"labels\": \"cream\"}, {\"x\": 2.9294753074645996, \"y\": 7.63388204574585, \"labels\": \"internal\"}, {\"x\": 3.8064322471618652, \"y\": 7.732020378112793, \"labels\": \"end\"}, {\"x\": 6.6241912841796875, \"y\": 5.888636112213135, \"labels\": \"enjoying\"}, {\"x\": 5.8710527420043945, \"y\": 7.289185047149658, \"labels\": \"ultimately\"}, {\"x\": 4.661288261413574, \"y\": 5.583265781402588, \"labels\": \"moderate\"}, {\"x\": 1.2784700393676758, \"y\": 3.7584431171417236, \"labels\": \"mac\"}, {\"x\": 8.341293334960938, \"y\": 4.589117050170898, \"labels\": \"years_ago\"}, {\"x\": 4.535083770751953, \"y\": 6.034660339355469, \"labels\": \"richer\"}, {\"x\": 6.5025434494018555, \"y\": 2.6954691410064697, \"labels\": \"japanese\"}, {\"x\": 2.5231854915618896, \"y\": 6.58600378036499, \"labels\": \"saucepan\"}, {\"x\": 3.0399467945098877, \"y\": 3.8367421627044678, \"labels\": \"iced\"}, {\"x\": 0.933525025844574, \"y\": 3.977841854095459, \"labels\": \"olives\"}, {\"x\": 3.4641480445861816, \"y\": 6.683368682861328, \"labels\": \"soapy\"}, {\"x\": 4.208880424499512, \"y\": 5.645934104919434, \"labels\": \"latter\"}, {\"x\": 4.153944969177246, \"y\": 7.296949863433838, \"labels\": \"saturated\"}, {\"x\": 1.1692332029342651, \"y\": 4.479166030883789, \"labels\": \"leaves\"}, {\"x\": 7.185162544250488, \"y\": 4.674189567565918, \"labels\": \"bachelor\"}, {\"x\": 3.9978480339050293, \"y\": 5.345423221588135, \"labels\": \"carbs\"}, {\"x\": 3.540299415588379, \"y\": 6.293457508087158, \"labels\": \"trays\"}, {\"x\": 4.695712566375732, \"y\": 7.243065357208252, \"labels\": \"healthier\"}, {\"x\": 7.533570766448975, \"y\": 5.33256196975708, \"labels\": \"broke\"}, {\"x\": 5.60509729385376, \"y\": 5.857422351837158, \"labels\": \"peoples\"}, {\"x\": 6.285454273223877, \"y\": 6.443477153778076, \"labels\": \"agrees\"}, {\"x\": 5.347316741943359, \"y\": 6.597577095031738, \"labels\": \"covers\"}, {\"x\": 5.064806938171387, \"y\": 8.459071159362793, \"labels\": \"move\"}, {\"x\": 3.814835786819458, \"y\": 3.9888343811035156, \"labels\": \"sunday\"}, {\"x\": 8.381412506103516, \"y\": 7.420095443725586, \"labels\": \"sound\"}, {\"x\": 4.723762512207031, \"y\": 5.7800703048706055, \"labels\": \"pyrex\"}, {\"x\": 5.230709552764893, \"y\": 4.061219692230225, \"labels\": \"mountain\"}, {\"x\": 7.742568016052246, \"y\": 7.677282810211182, \"labels\": \"argue\"}, {\"x\": 4.956235408782959, \"y\": 5.88238000869751, \"labels\": \"discoloration\"}, {\"x\": 3.1756439208984375, \"y\": 3.4024882316589355, \"labels\": \"stews\"}, {\"x\": 1.6421124935150146, \"y\": 5.514636039733887, \"labels\": \"beer\"}, {\"x\": 6.197482109069824, \"y\": 7.037850379943848, \"labels\": \"correctly\"}, {\"x\": 6.686461925506592, \"y\": 7.3271965980529785, \"labels\": \"compare\"}, {\"x\": 7.560758113861084, \"y\": 5.026706695556641, \"labels\": \"raised\"}, {\"x\": 2.552597999572754, \"y\": 3.6620981693267822, \"labels\": \"cod\"}, {\"x\": 7.927950859069824, \"y\": 4.47924280166626, \"labels\": \"shelf\"}, {\"x\": 6.1920695304870605, \"y\": 4.278629779815674, \"labels\": \"styles\"}, {\"x\": 2.205207586288452, \"y\": 3.956150770187378, \"labels\": \"wheat\"}, {\"x\": 6.761074542999268, \"y\": 4.022629737854004, \"labels\": \"these\"}, {\"x\": 6.904585838317871, \"y\": 4.844403266906738, \"labels\": \"max\"}, {\"x\": 2.042141914367676, \"y\": 6.866178512573242, \"labels\": \"pop\"}, {\"x\": 7.512740135192871, \"y\": 6.436596393585205, \"labels\": \"hearing\"}, {\"x\": 8.055948257446289, \"y\": 7.198118209838867, \"labels\": \"extremely\"}, {\"x\": 2.622575283050537, \"y\": 3.6434056758880615, \"labels\": \"garam\"}, {\"x\": 6.723891735076904, \"y\": 4.012964248657227, \"labels\": \"foods\"}, {\"x\": 4.983325958251953, \"y\": 5.589344024658203, \"labels\": \"reasonably\"}, {\"x\": 3.757093906402588, \"y\": 7.577480316162109, \"labels\": \"process\"}, {\"x\": 2.186594247817993, \"y\": 6.111782550811768, \"labels\": \"drippings\"}, {\"x\": 5.439358234405518, \"y\": 6.829198837280273, \"labels\": \"instantly\"}, {\"x\": 6.066628456115723, \"y\": 4.4081292152404785, \"labels\": \"listed\"}, {\"x\": 6.417805194854736, \"y\": 6.7317023277282715, \"labels\": \"blame\"}, {\"x\": 5.0191779136657715, \"y\": 7.729894161224365, \"labels\": \"incorporate\"}, {\"x\": 5.59143590927124, \"y\": 7.159237384796143, \"labels\": \"reduces\"}, {\"x\": 6.0384345054626465, \"y\": 4.324528217315674, \"labels\": \"textures\"}, {\"x\": 6.251473426818848, \"y\": 4.982193946838379, \"labels\": \"importantly\"}, {\"x\": 4.393830299377441, \"y\": 6.783834934234619, \"labels\": \"stretch\"}, {\"x\": 5.942080974578857, \"y\": 4.9108099937438965, \"labels\": \"paella\"}, {\"x\": 5.984796524047852, \"y\": 6.672669410705566, \"labels\": \"placed\"}, {\"x\": 4.395073890686035, \"y\": 4.507803916931152, \"labels\": \"marshmallows\"}, {\"x\": 5.06640100479126, \"y\": 5.746424198150635, \"labels\": \"worn\"}, {\"x\": 3.715747833251953, \"y\": 5.65542459487915, \"labels\": \"curd\"}, {\"x\": 5.575181484222412, \"y\": 5.553505897521973, \"labels\": \"somehow\"}, {\"x\": 4.018946647644043, \"y\": 7.113272666931152, \"labels\": \"level\"}, {\"x\": 5.876755714416504, \"y\": 6.3690385818481445, \"labels\": \"additives\"}, {\"x\": 6.885269641876221, \"y\": 7.076755046844482, \"labels\": \"suppose\"}, {\"x\": 7.845832824707031, \"y\": 7.476592540740967, \"labels\": \"healthy\"}, {\"x\": 2.4616317749023438, \"y\": 4.856411457061768, \"labels\": \"measuring\"}, {\"x\": 6.209309101104736, \"y\": 6.305690765380859, \"labels\": \"fuzzy\"}, {\"x\": 7.987103462219238, \"y\": 7.653286457061768, \"labels\": \"assume\"}, {\"x\": 3.9369139671325684, \"y\": 3.9467153549194336, \"labels\": \"chai\"}, {\"x\": 6.425121784210205, \"y\": 3.456604480743408, \"labels\": \"cacio\"}, {\"x\": 4.152443885803223, \"y\": 3.9431169033050537, \"labels\": \"unique\"}, {\"x\": 4.315195560455322, \"y\": 6.281918525695801, \"labels\": \"burns\"}, {\"x\": 4.519801616668701, \"y\": 7.568078517913818, \"labels\": \"less\"}, {\"x\": 5.85648250579834, \"y\": 6.5774664878845215, \"labels\": \"decade\"}, {\"x\": 7.9383864402771, \"y\": 5.255441665649414, \"labels\": \"children\"}, {\"x\": 3.5248987674713135, \"y\": 6.323676109313965, \"labels\": \"braising\"}, {\"x\": 5.709672451019287, \"y\": 5.9692463874816895, \"labels\": \"import\"}, {\"x\": 6.6371169090271, \"y\": 6.036161422729492, \"labels\": \"confusing\"}, {\"x\": 1.7262794971466064, \"y\": 5.194676399230957, \"labels\": \"quart\"}, {\"x\": 1.9086073637008667, \"y\": 4.320675373077393, \"labels\": \"peanuts\"}, {\"x\": 7.403501987457275, \"y\": 5.559572696685791, \"labels\": \"luck\"}, {\"x\": 5.113405704498291, \"y\": 5.390871047973633, \"labels\": \"substance\"}, {\"x\": 5.8677754402160645, \"y\": 6.052950859069824, \"labels\": \"washington\"}, {\"x\": 6.13632869720459, \"y\": 5.1537933349609375, \"labels\": \"proof\"}, {\"x\": 6.881747722625732, \"y\": 7.104465484619141, \"labels\": \"parasites\"}, {\"x\": 7.214288234710693, \"y\": 5.440863132476807, \"labels\": \"network\"}, {\"x\": 6.166748523712158, \"y\": 6.270870685577393, \"labels\": \"retail\"}, {\"x\": 8.201484680175781, \"y\": 6.728081226348877, \"labels\": \"apparently\"}, {\"x\": 1.7875986099243164, \"y\": 5.213666915893555, \"labels\": \"whites\"}, {\"x\": 1.835642695426941, \"y\": 4.190094947814941, \"labels\": \"jalapeno\"}, {\"x\": 7.130472183227539, \"y\": 6.332091808319092, \"labels\": \"profession\"}, {\"x\": 4.81745719909668, \"y\": 5.163578033447266, \"labels\": \"loosely\"}, {\"x\": 6.210057258605957, \"y\": 6.2177958488464355, \"labels\": \"razor\"}, {\"x\": 5.333737850189209, \"y\": 4.48085880279541, \"labels\": \"kebabs\"}, {\"x\": 5.642764091491699, \"y\": 6.666931629180908, \"labels\": \"russets\"}, {\"x\": 8.677786827087402, \"y\": 6.574957370758057, \"labels\": \"god\"}, {\"x\": 3.7642383575439453, \"y\": 5.839970588684082, \"labels\": \"virgin\"}, {\"x\": 5.495795249938965, \"y\": 6.035841941833496, \"labels\": \"previously\"}, {\"x\": 7.772781848907471, \"y\": 5.371403694152832, \"labels\": \"ex\"}, {\"x\": 1.9376134872436523, \"y\": 4.940594673156738, \"labels\": \"stuffing\"}, {\"x\": 7.173612594604492, \"y\": 7.684389114379883, \"labels\": \"cant\"}, {\"x\": 7.772707462310791, \"y\": 7.376784801483154, \"labels\": \"difficult\"}, {\"x\": 4.556678771972656, \"y\": 7.535761833190918, \"labels\": \"more\"}, {\"x\": 4.560616970062256, \"y\": 5.184606075286865, \"labels\": \"shaped\"}, {\"x\": 7.234555721282959, \"y\": 7.747838020324707, \"labels\": \"tend\"}, {\"x\": 5.8051838874816895, \"y\": 4.817047595977783, \"labels\": \"global\"}, {\"x\": 6.829502105712891, \"y\": 6.171019554138184, \"labels\": \"ain\"}, {\"x\": 5.817714691162109, \"y\": 4.523355960845947, \"labels\": \"images\"}, {\"x\": 4.590630531311035, \"y\": 6.055644989013672, \"labels\": \"somewhat\"}, {\"x\": 5.901382923126221, \"y\": 5.679178237915039, \"labels\": \"ours\"}, {\"x\": 2.7511842250823975, \"y\": 4.15686559677124, \"labels\": \"boneless\"}, {\"x\": 6.134925842285156, \"y\": 8.080504417419434, \"labels\": \"stand\"}, {\"x\": 6.035611152648926, \"y\": 6.824477195739746, \"labels\": \"comparable\"}, {\"x\": 5.7958664894104, \"y\": 8.472559928894043, \"labels\": \"find\"}, {\"x\": 3.771801233291626, \"y\": 3.504739761352539, \"labels\": \"vin\"}, {\"x\": 8.386366844177246, \"y\": 7.38429594039917, \"labels\": \"appreciate\"}, {\"x\": 6.812191963195801, \"y\": 6.845198154449463, \"labels\": \"boy\"}, {\"x\": 1.7430744171142578, \"y\": 6.215643405914307, \"labels\": \"fill\"}, {\"x\": 4.444208145141602, \"y\": 5.064957141876221, \"labels\": \"salami\"}, {\"x\": 7.059799671173096, \"y\": 5.847238540649414, \"labels\": \"garbage\"}, {\"x\": 6.70380973815918, \"y\": 5.245759963989258, \"labels\": \"manual\"}, {\"x\": 3.0057735443115234, \"y\": 6.485551834106445, \"labels\": \"scoop\"}, {\"x\": 5.495530128479004, \"y\": 5.5905585289001465, \"labels\": \"boys\"}, {\"x\": 5.511380195617676, \"y\": 6.338483810424805, \"labels\": \"failure\"}, {\"x\": 8.257234573364258, \"y\": 4.5777764320373535, \"labels\": \"night\"}, {\"x\": 2.953864812850952, \"y\": 4.440667629241943, \"labels\": \"jello\"}, {\"x\": 6.07140588760376, \"y\": 6.682490348815918, \"labels\": \"belt\"}, {\"x\": 1.252194881439209, \"y\": 4.03854513168335, \"labels\": \"chilli\"}, {\"x\": 3.576683759689331, \"y\": 6.8706560134887695, \"labels\": \"fryer\"}, {\"x\": 6.453675270080566, \"y\": 6.8091959953308105, \"labels\": \"spoiled\"}, {\"x\": 7.161331653594971, \"y\": 4.958916664123535, \"labels\": \"sf\"}, {\"x\": 2.8386261463165283, \"y\": 4.9355692863464355, \"labels\": \"sour\"}, {\"x\": 2.207934856414795, \"y\": 4.149356842041016, \"labels\": \"tenderloin\"}, {\"x\": 3.3130478858947754, \"y\": 7.313751697540283, \"labels\": \"highest\"}, {\"x\": 6.419227123260498, \"y\": 5.600491046905518, \"labels\": \"shops\"}, {\"x\": 6.4481096267700195, \"y\": 6.2305097579956055, \"labels\": \"birds\"}, {\"x\": 4.136092662811279, \"y\": 4.887706756591797, \"labels\": \"congee\"}, {\"x\": 7.356913089752197, \"y\": 7.991621971130371, \"labels\": \"should\"}, {\"x\": 6.20296573638916, \"y\": 6.66491174697876, \"labels\": \"shot\"}, {\"x\": 6.029531955718994, \"y\": 5.346930027008057, \"labels\": \"users\"}, {\"x\": 7.565193176269531, \"y\": 7.594661712646484, \"labels\": \"wanted\"}, {\"x\": 3.9665515422821045, \"y\": 5.892611026763916, \"labels\": \"cuts\"}, {\"x\": 3.7568256855010986, \"y\": 7.426058769226074, \"labels\": \"fat\"}, {\"x\": 7.462806224822998, \"y\": 4.90731954574585, \"labels\": \"library\"}, {\"x\": 3.6697380542755127, \"y\": 5.0390167236328125, \"labels\": \"quarters\"}, {\"x\": 1.1440092325210571, \"y\": 3.861893653869629, \"labels\": \"chorizo\"}, {\"x\": 1.4534107446670532, \"y\": 4.285427093505859, \"labels\": \"sesame\"}, {\"x\": 5.402168273925781, \"y\": 5.805248737335205, \"labels\": \"boat\"}, {\"x\": 6.246139049530029, \"y\": 6.591975212097168, \"labels\": \"cheating\"}, {\"x\": 2.343733310699463, \"y\": 4.978973388671875, \"labels\": \"quarter\"}, {\"x\": 3.6650004386901855, \"y\": 7.346320629119873, \"labels\": \"gets\"}, {\"x\": 1.5158075094223022, \"y\": 4.785857677459717, \"labels\": \"packet\"}, {\"x\": 2.764564275741577, \"y\": 3.7884161472320557, \"labels\": \"habanero\"}, {\"x\": 4.0340471267700195, \"y\": 6.697920799255371, \"labels\": \"scrubbing\"}, {\"x\": 1.6708279848098755, \"y\": 3.813274621963501, \"labels\": \"mashed\"}, {\"x\": 5.442615985870361, \"y\": 6.403294086456299, \"labels\": \"dye\"}, {\"x\": 7.1313090324401855, \"y\": 7.683547019958496, \"labels\": \"gotta\"}, {\"x\": 5.533236026763916, \"y\": 5.765387535095215, \"labels\": \"scrambling\"}, {\"x\": 5.0842132568359375, \"y\": 5.821218967437744, \"labels\": \"hog\"}, {\"x\": 3.3819754123687744, \"y\": 5.788293361663818, \"labels\": \"quantities\"}, {\"x\": 1.986146092414856, \"y\": 4.598465919494629, \"labels\": \"usually\"}, {\"x\": 3.1819024085998535, \"y\": 4.084300518035889, \"labels\": \"vodka\"}, {\"x\": 7.5792694091796875, \"y\": 5.747595310211182, \"labels\": \"according\"}, {\"x\": 6.668162822723389, \"y\": 5.410833835601807, \"labels\": \"downvote\"}, {\"x\": 8.06748104095459, \"y\": 6.760227680206299, \"labels\": \"truly\"}, {\"x\": 1.634061574935913, \"y\": 5.3060221672058105, \"labels\": \"pound\"}, {\"x\": 4.194612503051758, \"y\": 5.021383285522461, \"labels\": \"thawed\"}, {\"x\": 6.933708667755127, \"y\": 5.484502792358398, \"labels\": \"allergy\"}, {\"x\": 2.771260976791382, \"y\": 7.618445873260498, \"labels\": \"seconds\"}, {\"x\": 5.272305011749268, \"y\": 8.466399192810059, \"labels\": \"take\"}, {\"x\": 7.936054706573486, \"y\": 7.456686019897461, \"labels\": \"works\"}, {\"x\": 6.382158279418945, \"y\": 5.747592926025391, \"labels\": \"risks\"}, {\"x\": 2.4747581481933594, \"y\": 3.9450042247772217, \"labels\": \"sausages\"}, {\"x\": 4.327534198760986, \"y\": 6.569820404052734, \"labels\": \"conventional\"}, {\"x\": 6.007219314575195, \"y\": 5.910418510437012, \"labels\": \"versus\"}, {\"x\": 6.9815592765808105, \"y\": 6.5809550285339355, \"labels\": \"nor\"}, {\"x\": 6.635788917541504, \"y\": 4.180177211761475, \"labels\": \"none\"}, {\"x\": 3.3421425819396973, \"y\": 5.923155307769775, \"labels\": \"til\"}, {\"x\": 3.8809008598327637, \"y\": 4.758923530578613, \"labels\": \"grapeseed\"}, {\"x\": 5.182046413421631, \"y\": 6.377519130706787, \"labels\": \"freshness\"}, {\"x\": 3.2740516662597656, \"y\": 5.700841426849365, \"labels\": \"braise\"}, {\"x\": 6.841021537780762, \"y\": 4.170224666595459, \"labels\": \"americans\"}, {\"x\": 6.454494953155518, \"y\": 5.818879127502441, \"labels\": \"changer\"}, {\"x\": 4.16666841506958, \"y\": 5.766976833343506, \"labels\": \"darker\"}, {\"x\": 6.5502824783325195, \"y\": 2.5835442543029785, \"labels\": \"utf\"}, {\"x\": 7.0594611167907715, \"y\": 4.239251136779785, \"labels\": \"available\"}, {\"x\": 5.338899612426758, \"y\": 6.202413558959961, \"labels\": \"fermentation\"}, {\"x\": 6.411223888397217, \"y\": 7.2471113204956055, \"labels\": \"ship\"}, {\"x\": 7.45607328414917, \"y\": 6.123835563659668, \"labels\": \"listening\"}, {\"x\": 5.556360244750977, \"y\": 7.793198108673096, \"labels\": \"drink\"}, {\"x\": 3.5237107276916504, \"y\": 6.311546325683594, \"labels\": \"trim\"}, {\"x\": 4.561497211456299, \"y\": 5.341687202453613, \"labels\": \"dose\"}, {\"x\": 4.909756183624268, \"y\": 6.4689741134643555, \"labels\": \"par\"}, {\"x\": 5.385156631469727, \"y\": 8.469449043273926, \"labels\": \"go\"}, {\"x\": 5.1179046630859375, \"y\": 7.181440353393555, \"labels\": \"contribute\"}, {\"x\": 8.603443145751953, \"y\": 6.845968246459961, \"labels\": \"felt\"}, {\"x\": 7.578300952911377, \"y\": 5.496833801269531, \"labels\": \"lady\"}, {\"x\": 3.7617955207824707, \"y\": 4.393121719360352, \"labels\": \"waffles\"}, {\"x\": 2.871941089630127, \"y\": 5.4671406745910645, \"labels\": \"taste\"}, {\"x\": 5.075522422790527, \"y\": 7.123787879943848, \"labels\": \"print\"}, {\"x\": 1.5367889404296875, \"y\": 4.0558037757873535, \"labels\": \"crumbs\"}, {\"x\": 5.304039478302002, \"y\": 6.822144508361816, \"labels\": \"factor\"}, {\"x\": 7.289708137512207, \"y\": 7.130704402923584, \"labels\": \"rude\"}, {\"x\": 4.585232257843018, \"y\": 4.15878438949585, \"labels\": \"venison\"}, {\"x\": 4.324878215789795, \"y\": 7.491699695587158, \"labels\": \"higher\"}, {\"x\": 8.824424743652344, \"y\": 6.7729997634887695, \"labels\": \"made\"}, {\"x\": 6.743853569030762, \"y\": 7.010553359985352, \"labels\": \"efficient\"}, {\"x\": 4.836534023284912, \"y\": 6.877614498138428, \"labels\": \"rising\"}, {\"x\": 0.8497626781463623, \"y\": 4.624912738800049, \"labels\": \"cups\"}, {\"x\": 5.248978614807129, \"y\": 4.616258144378662, \"labels\": \"neither\"}, {\"x\": 3.1979429721832275, \"y\": 5.799008369445801, \"labels\": \"warmed\"}, {\"x\": 3.828415870666504, \"y\": 4.168093681335449, \"labels\": \"tartar\"}, {\"x\": 4.079468250274658, \"y\": 7.238770008087158, \"labels\": \"sodium\"}, {\"x\": 5.643547058105469, \"y\": 7.038999080657959, \"labels\": \"entirely\"}, {\"x\": 5.150246620178223, \"y\": 6.001193523406982, \"labels\": \"zone\"}, {\"x\": 2.873983383178711, \"y\": 7.7021026611328125, \"labels\": \"low\"}, {\"x\": 6.661989212036133, \"y\": 2.486926317214966, \"labels\": \"com\"}, {\"x\": 4.65833044052124, \"y\": 6.455414295196533, \"labels\": \"blanching\"}, {\"x\": 1.3685709238052368, \"y\": 4.5173540115356445, \"labels\": \"lentils\"}, {\"x\": 7.9729132652282715, \"y\": 5.967591762542725, \"labels\": \"follow\"}, {\"x\": 7.560191631317139, \"y\": 7.625071048736572, \"labels\": \"notice\"}, {\"x\": 0.9382047653198242, \"y\": 4.654775619506836, \"labels\": \"milk\"}, {\"x\": 5.211598873138428, \"y\": 6.9578728675842285, \"labels\": \"pin\"}, {\"x\": 3.6313295364379883, \"y\": 3.5670292377471924, \"labels\": \"rib\"}, {\"x\": 3.6582963466644287, \"y\": 5.877174377441406, \"labels\": \"rendered\"}, {\"x\": 3.330232858657837, \"y\": 4.187234401702881, \"labels\": \"bouillon\"}, {\"x\": 4.171854019165039, \"y\": 3.9469809532165527, \"labels\": \"chowder\"}, {\"x\": 2.4456682205200195, \"y\": 6.3995232582092285, \"labels\": \"spray\"}, {\"x\": 6.6950836181640625, \"y\": 7.413784503936768, \"labels\": \"access\"}, {\"x\": 5.193973541259766, \"y\": 4.729013442993164, \"labels\": \"theres\"}, {\"x\": 6.997133731842041, \"y\": 5.425610542297363, \"labels\": \"owned\"}, {\"x\": 0.9067707061767578, \"y\": 4.305058479309082, \"labels\": \"bay\"}, {\"x\": 7.7126264572143555, \"y\": 7.325023651123047, \"labels\": \"hard\"}, {\"x\": 6.92223596572876, \"y\": 7.80760383605957, \"labels\": \"to\"}, {\"x\": 2.3800342082977295, \"y\": 7.272042751312256, \"labels\": \"sit\"}, {\"x\": 6.516651153564453, \"y\": 5.325294494628906, \"labels\": \"fellow\"}, {\"x\": 8.275036811828613, \"y\": 4.786664962768555, \"labels\": \"meal\"}, {\"x\": 3.2946105003356934, \"y\": 7.11617374420166, \"labels\": \"coating\"}, {\"x\": 6.196467399597168, \"y\": 6.070204257965088, \"labels\": \"gym\"}, {\"x\": 3.657841920852661, \"y\": 7.547783851623535, \"labels\": \"heats\"}, {\"x\": 5.460907459259033, \"y\": 4.974133014678955, \"labels\": \"pastas\"}, {\"x\": 2.9301674365997314, \"y\": 6.278965473175049, \"labels\": \"coated\"}, {\"x\": 6.932010650634766, \"y\": 6.441726207733154, \"labels\": \"meh\"}, {\"x\": 2.5029916763305664, \"y\": 4.653113842010498, \"labels\": \"coarse\"}, {\"x\": 3.2667794227600098, \"y\": 4.577235698699951, \"labels\": \"spreads\"}, {\"x\": 8.30238151550293, \"y\": 6.635517120361328, \"labels\": \"since\"}, {\"x\": 5.323072910308838, \"y\": 6.635564804077148, \"labels\": \"brittle\"}, {\"x\": 5.48452091217041, \"y\": 7.39907693862915, \"labels\": \"burst\"}, {\"x\": 6.709787845611572, \"y\": 5.815737247467041, \"labels\": \"explanation\"}, {\"x\": 2.775789737701416, \"y\": 7.48121976852417, \"labels\": \"enough\"}, {\"x\": 2.181828022003174, \"y\": 6.312363624572754, \"labels\": \"brine\"}, {\"x\": 2.783686876296997, \"y\": 4.6846113204956055, \"labels\": \"chunky\"}, {\"x\": 6.788540840148926, \"y\": 7.048914432525635, \"labels\": \"decent\"}, {\"x\": 1.704487919807434, \"y\": 6.3076863288879395, \"labels\": \"cut\"}, {\"x\": 6.061432838439941, \"y\": 5.811381816864014, \"labels\": \"direction\"}, {\"x\": 5.363349914550781, \"y\": 5.404726982116699, \"labels\": \"practically\"}, {\"x\": 8.008296966552734, \"y\": 5.431859970092773, \"labels\": \"website\"}, {\"x\": 1.6696451902389526, \"y\": 3.728830575942993, \"labels\": \"pesto\"}, {\"x\": 8.091675758361816, \"y\": 7.235791206359863, \"labels\": \"necessarily\"}, {\"x\": 7.6902642250061035, \"y\": 6.233906269073486, \"labels\": \"brain\"}, {\"x\": 5.267284870147705, \"y\": 5.518749713897705, \"labels\": \"preparations\"}, {\"x\": 6.194363117218018, \"y\": 5.315126419067383, \"labels\": \"europe\"}, {\"x\": 7.80057430267334, \"y\": 6.405972003936768, \"labels\": \"term\"}, {\"x\": 4.231675624847412, \"y\": 6.256884574890137, \"labels\": \"perfectly\"}, {\"x\": 4.247685432434082, \"y\": 5.467984676361084, \"labels\": \"sugary\"}, {\"x\": 3.2647926807403564, \"y\": 7.574700832366943, \"labels\": \"its\"}, {\"x\": 6.020727157592773, \"y\": 5.924172878265381, \"labels\": \"sight\"}, {\"x\": 3.7631425857543945, \"y\": 4.182428359985352, \"labels\": \"creole\"}, {\"x\": 4.374483585357666, \"y\": 5.863463401794434, \"labels\": \"earthy\"}, {\"x\": 1.0054984092712402, \"y\": 4.400958061218262, \"labels\": \"nutmeg\"}, {\"x\": 7.992684364318848, \"y\": 5.22055196762085, \"labels\": \"roommate\"}, {\"x\": 5.7131266593933105, \"y\": 4.438166618347168, \"labels\": \"gourmet\"}, {\"x\": 7.8643317222595215, \"y\": 7.611922264099121, \"labels\": \"wonder\"}, {\"x\": 3.0792815685272217, \"y\": 4.353555679321289, \"labels\": \"ounce\"}, {\"x\": 4.288529396057129, \"y\": 5.790406703948975, \"labels\": \"acidic\"}, {\"x\": 3.126406669616699, \"y\": 5.166027545928955, \"labels\": \"depth\"}, {\"x\": 4.914317607879639, \"y\": 8.342985153198242, \"labels\": \"comes\"}, {\"x\": 8.559910774230957, \"y\": 7.18113374710083, \"labels\": \"happens\"}, {\"x\": 5.725525856018066, \"y\": 8.484142303466797, \"labels\": \"try\"}, {\"x\": 4.1577019691467285, \"y\": 6.715737342834473, \"labels\": \"applying\"}, {\"x\": 8.371306419372559, \"y\": 4.545748233795166, \"labels\": \"days\"}, {\"x\": 7.513772964477539, \"y\": 6.487549304962158, \"labels\": \"meaning\"}, {\"x\": 2.7049899101257324, \"y\": 7.058678150177002, \"labels\": \"finished\"}, {\"x\": 5.140722751617432, \"y\": 7.706853866577148, \"labels\": \"weigh\"}, {\"x\": 8.268550872802734, \"y\": 5.934321880340576, \"labels\": \"behind\"}, {\"x\": 6.104822635650635, \"y\": 4.422086715698242, \"labels\": \"examples\"}, {\"x\": 7.930049419403076, \"y\": 4.7186737060546875, \"labels\": \"episode\"}, {\"x\": 8.391154289245605, \"y\": 6.1632399559021, \"labels\": \"particular\"}, {\"x\": 6.298874855041504, \"y\": 4.592106342315674, \"labels\": \"consumer\"}, {\"x\": 7.493997573852539, \"y\": 4.889239311218262, \"labels\": \"instructions\"}, {\"x\": 8.109593391418457, \"y\": 4.396788597106934, \"labels\": \"five\"}, {\"x\": 3.2997918128967285, \"y\": 5.827967166900635, \"labels\": \"meanwhile\"}, {\"x\": 4.244096279144287, \"y\": 7.631499767303467, \"labels\": \"board\"}, {\"x\": 7.48282527923584, \"y\": 7.47987699508667, \"labels\": \"miss\"}, {\"x\": 2.0500264167785645, \"y\": 7.207852840423584, \"labels\": \"pan\"}, {\"x\": 2.0678954124450684, \"y\": 4.49552059173584, \"labels\": \"chicken_breasts\"}, {\"x\": 2.379924774169922, \"y\": 7.306365966796875, \"labels\": \"back\"}, {\"x\": 7.461669921875, \"y\": 6.528614044189453, \"labels\": \"actively\"}, {\"x\": 2.1216115951538086, \"y\": 5.46396017074585, \"labels\": \"jars\"}, {\"x\": 5.976072311401367, \"y\": 4.438180923461914, \"labels\": \"joint\"}, {\"x\": 6.3546977043151855, \"y\": 5.343902111053467, \"labels\": \"resource\"}, {\"x\": 8.584012031555176, \"y\": 6.918623447418213, \"labels\": \"her\"}, {\"x\": 5.682192802429199, \"y\": 5.304533004760742, \"labels\": \"capsaicin\"}, {\"x\": 6.749179363250732, \"y\": 6.608870983123779, \"labels\": \"included\"}, {\"x\": 8.524795532226562, \"y\": 5.98629903793335, \"labels\": \"way\"}, {\"x\": 6.37959623336792, \"y\": 6.5261311531066895, \"labels\": \"parties\"}, {\"x\": 1.9635286331176758, \"y\": 4.5674147605896, \"labels\": \"citrus\"}, {\"x\": 3.713463306427002, \"y\": 5.86844539642334, \"labels\": \"containers\"}, {\"x\": 5.455082893371582, \"y\": 7.121946811676025, \"labels\": \"tolerate\"}, {\"x\": 3.9288175106048584, \"y\": 5.702293395996094, \"labels\": \"balance\"}, {\"x\": 7.977311611175537, \"y\": 5.3215155601501465, \"labels\": \"suggestion\"}, {\"x\": 8.577228546142578, \"y\": 6.085666656494141, \"labels\": \"answer\"}, {\"x\": 6.28043794631958, \"y\": 4.7313737869262695, \"labels\": \"answers\"}, {\"x\": 6.897311687469482, \"y\": 6.238110542297363, \"labels\": \"emergency\"}, {\"x\": 5.126643180847168, \"y\": 6.798896789550781, \"labels\": \"brew\"}, {\"x\": 1.9802080392837524, \"y\": 3.9895427227020264, \"labels\": \"crumbled\"}, {\"x\": 8.38586139678955, \"y\": 7.504628658294678, \"labels\": \"look\"}, {\"x\": 6.646541118621826, \"y\": 6.012528896331787, \"labels\": \"university\"}, {\"x\": 4.4924092292785645, \"y\": 6.359767913818359, \"labels\": \"nd\"}, {\"x\": 5.29130220413208, \"y\": 3.9421045780181885, \"labels\": \"swedish\"}, {\"x\": 6.313174247741699, \"y\": 6.011252403259277, \"labels\": \"subject\"}, {\"x\": 6.191855430603027, \"y\": 6.095109462738037, \"labels\": \"turkeys\"}, {\"x\": 1.9427226781845093, \"y\": 7.026504039764404, \"labels\": \"bottom\"}, {\"x\": 6.481212139129639, \"y\": 4.019218921661377, \"labels\": \"types\"}, {\"x\": 1.7613831758499146, \"y\": 5.488236427307129, \"labels\": \"half\"}, {\"x\": 5.842431545257568, \"y\": 5.552107334136963, \"labels\": \"treatment\"}, {\"x\": 6.351550102233887, \"y\": 4.772826671600342, \"labels\": \"human\"}, {\"x\": 4.26732873916626, \"y\": 7.8244309425354, \"labels\": \"your\"}, {\"x\": 0.9512262344360352, \"y\": 3.8868751525878906, \"labels\": \"curry\"}, {\"x\": 2.9185826778411865, \"y\": 7.707102298736572, \"labels\": \"temp\"}, {\"x\": 2.426170587539673, \"y\": 5.7777509689331055, \"labels\": \"smooth\"}, {\"x\": 6.645508766174316, \"y\": 5.154437065124512, \"labels\": \"greatly\"}, {\"x\": 7.026299476623535, \"y\": 6.828367710113525, \"labels\": \"conversation\"}, {\"x\": 4.3221116065979, \"y\": 4.164628028869629, \"labels\": \"legs\"}, {\"x\": 4.062009811401367, \"y\": 4.361420154571533, \"labels\": \"alongside\"}, {\"x\": 5.4861602783203125, \"y\": 5.229010581970215, \"labels\": \"blumenthal\"}, {\"x\": 6.755276679992676, \"y\": 7.099841594696045, \"labels\": \"potentially\"}, {\"x\": 6.819710731506348, \"y\": 3.326751708984375, \"labels\": \"pdf\"}, {\"x\": 5.252677917480469, \"y\": 4.8554534912109375, \"labels\": \"sake\"}, {\"x\": 8.471236228942871, \"y\": 6.8380656242370605, \"labels\": \"learned\"}, {\"x\": 1.7035894393920898, \"y\": 5.7448248863220215, \"labels\": \"batter\"}, {\"x\": 6.806562900543213, \"y\": 6.204005241394043, \"labels\": \"sucks\"}, {\"x\": 6.729640007019043, \"y\": 3.971278667449951, \"labels\": \"other\"}, {\"x\": 7.334568977355957, \"y\": 6.955644130706787, \"labels\": \"criticism\"}, {\"x\": 6.793044567108154, \"y\": 7.230405807495117, \"labels\": \"sir\"}, {\"x\": 6.252090930938721, \"y\": 5.448980331420898, \"labels\": \"caused\"}, {\"x\": 2.923128843307495, \"y\": 3.6599464416503906, \"labels\": \"creamed\"}, {\"x\": 7.004925727844238, \"y\": 6.663165092468262, \"labels\": \"smelled\"}, {\"x\": 5.802517414093018, \"y\": 6.226377964019775, \"labels\": \"accept\"}, {\"x\": 5.265486240386963, \"y\": 6.611453056335449, \"labels\": \"eyes\"}, {\"x\": 4.529222011566162, \"y\": 4.73625373840332, \"labels\": \"mcdonald\"}, {\"x\": 7.524223327636719, \"y\": 5.721619606018066, \"labels\": \"value\"}, {\"x\": 5.32346773147583, \"y\": 8.437873840332031, \"labels\": \"stay\"}, {\"x\": 6.208291053771973, \"y\": 7.323732376098633, \"labels\": \"appeal\"}, {\"x\": 2.1799356937408447, \"y\": 6.549542427062988, \"labels\": \"thoroughly\"}, {\"x\": 6.566464900970459, \"y\": 6.9674072265625, \"labels\": \"waste\"}, {\"x\": 6.142298221588135, \"y\": 4.944226264953613, \"labels\": \"japan\"}, {\"x\": 7.033721923828125, \"y\": 5.660886764526367, \"labels\": \"poisoning\"}, {\"x\": 5.663559436798096, \"y\": 5.806307792663574, \"labels\": \"subbed\"}, {\"x\": 6.1601362228393555, \"y\": 3.789365530014038, \"labels\": \"snack\"}, {\"x\": 6.744649410247803, \"y\": 6.497812747955322, \"labels\": \"buys\"}, {\"x\": 5.234675407409668, \"y\": 7.648073196411133, \"labels\": \"return\"}, {\"x\": 6.429643154144287, \"y\": 6.41865348815918, \"labels\": \"collected\"}, {\"x\": 6.625112533569336, \"y\": 7.196448802947998, \"labels\": \"differently\"}, {\"x\": 5.59979772567749, \"y\": 6.046407222747803, \"labels\": \"assholes\"}, {\"x\": 8.109354972839355, \"y\": 6.873653411865234, \"labels\": \"fun\"}, {\"x\": 7.4421820640563965, \"y\": 6.203149318695068, \"labels\": \"stated\"}, {\"x\": 5.004133701324463, \"y\": 7.274603843688965, \"labels\": \"gain\"}, {\"x\": 5.203066825866699, \"y\": 6.570570945739746, \"labels\": \"yard\"}, {\"x\": 4.301205158233643, \"y\": 6.076940536499023, \"labels\": \"liquids\"}, {\"x\": 4.35860013961792, \"y\": 5.628987789154053, \"labels\": \"pots\"}, {\"x\": 6.477739334106445, \"y\": 5.108019828796387, \"labels\": \"self\"}, {\"x\": 1.3872889280319214, \"y\": 3.8084261417388916, \"labels\": \"spaghetti\"}, {\"x\": 6.935455322265625, \"y\": 4.075169086456299, \"labels\": \"cuisine\"}, {\"x\": 6.734660625457764, \"y\": 3.205049753189087, \"labels\": \"tasteofhome\"}, {\"x\": 8.299407005310059, \"y\": 6.291675567626953, \"labels\": \"given\"}, {\"x\": 5.398129940032959, \"y\": 6.282140254974365, \"labels\": \"creativity\"}, {\"x\": 6.600856304168701, \"y\": 5.121169090270996, \"labels\": \"hardly\"}, {\"x\": 5.652982234954834, \"y\": 6.439216613769531, \"labels\": \"fault\"}, {\"x\": 2.7341785430908203, \"y\": 3.655259847640991, \"labels\": \"wild\"}, {\"x\": 3.729123115539551, \"y\": 4.01078462600708, \"labels\": \"radish\"}, {\"x\": 0.8728674650192261, \"y\": 4.753123760223389, \"labels\": \"salt\"}, {\"x\": 4.337917327880859, \"y\": 4.372622489929199, \"labels\": \"cous\"}, {\"x\": 5.09893274307251, \"y\": 4.377497673034668, \"labels\": \"whereas\"}, {\"x\": 6.551560401916504, \"y\": 2.627811908721924, \"labels\": \"sr\"}, {\"x\": 6.133726119995117, \"y\": 6.691854476928711, \"labels\": \"concerned\"}, {\"x\": 4.482174873352051, \"y\": 6.950740337371826, \"labels\": \"absorb\"}, {\"x\": 2.525845527648926, \"y\": 7.298882007598877, \"labels\": \"fire\"}, {\"x\": 0.7362411022186279, \"y\": 4.103697776794434, \"labels\": \"mixed\"}, {\"x\": 5.465007781982422, \"y\": 5.092862129211426, \"labels\": \"shellfish\"}, {\"x\": 6.39888858795166, \"y\": 3.764094829559326, \"labels\": \"pairing\"}, {\"x\": 6.933572292327881, \"y\": 6.10614013671875, \"labels\": \"topic\"}, {\"x\": 5.53571891784668, \"y\": 7.5251312255859375, \"labels\": \"sat\"}, {\"x\": 4.571281433105469, \"y\": 5.091714859008789, \"labels\": \"fryers\"}, {\"x\": 5.388230800628662, \"y\": 6.601449012756348, \"labels\": \"sauteeing\"}, {\"x\": 5.724050521850586, \"y\": 7.176244258880615, \"labels\": \"window\"}, {\"x\": 3.1093156337738037, \"y\": 3.4462740421295166, \"labels\": \"dumplings\"}, {\"x\": 4.372506141662598, \"y\": 3.7300283908843994, \"labels\": \"sushi\"}, {\"x\": 5.881520748138428, \"y\": 4.4565653800964355, \"labels\": \"flavours\"}, {\"x\": 1.8023790121078491, \"y\": 5.819270610809326, \"labels\": \"remaining\"}, {\"x\": 7.575029373168945, \"y\": 7.235127925872803, \"labels\": \"fast\"}, {\"x\": 6.4634270668029785, \"y\": 6.790889739990234, \"labels\": \"googled\"}, {\"x\": 5.455533981323242, \"y\": 7.329689979553223, \"labels\": \"deliver\"}, {\"x\": 8.542032241821289, \"y\": 6.721165180206299, \"labels\": \"discovered\"}, {\"x\": 4.218519687652588, \"y\": 7.327762603759766, \"labels\": \"range\"}, {\"x\": 6.119757652282715, \"y\": 6.3189167976379395, \"labels\": \"worthwhile\"}, {\"x\": 8.456175804138184, \"y\": 6.730107307434082, \"labels\": \"actually\"}, {\"x\": 6.110055446624756, \"y\": 8.306838989257812, \"labels\": \"call\"}, {\"x\": 7.624629974365234, \"y\": 5.6694560050964355, \"labels\": \"guide\"}, {\"x\": 7.90778112411499, \"y\": 7.013907432556152, \"labels\": \"eh\"}, {\"x\": 6.659388065338135, \"y\": 6.717519283294678, \"labels\": \"saving\"}, {\"x\": 5.429615497589111, \"y\": 7.460994243621826, \"labels\": \"seek\"}, {\"x\": 5.648044109344482, \"y\": 8.476407051086426, \"labels\": \"use\"}, {\"x\": 5.409945011138916, \"y\": 6.0950398445129395, \"labels\": \"reheating\"}, {\"x\": 1.8913191556930542, \"y\": 6.442071437835693, \"labels\": \"drain\"}, {\"x\": 3.9946236610412598, \"y\": 4.6253581047058105, \"labels\": \"ricer\"}, {\"x\": 6.887983798980713, \"y\": 4.895367622375488, \"labels\": \"strip\"}, {\"x\": 5.46353006362915, \"y\": 6.185211181640625, \"labels\": \"augh\"}, {\"x\": 2.9995837211608887, \"y\": 7.091752052307129, \"labels\": \"sitting\"}, {\"x\": 8.009011268615723, \"y\": 6.0396647453308105, \"labels\": \"reply\"}, {\"x\": 3.0728414058685303, \"y\": 7.2693047523498535, \"labels\": \"toaster\"}, {\"x\": 5.67289924621582, \"y\": 4.780762195587158, \"labels\": \"appetizers\"}, {\"x\": 6.358837604522705, \"y\": 4.87214994430542, \"labels\": \"selection\"}, {\"x\": 3.674799680709839, \"y\": 5.522271156311035, \"labels\": \"ladle\"}, {\"x\": 5.239034175872803, \"y\": 6.541750431060791, \"labels\": \"ad\"}, {\"x\": 6.544515609741211, \"y\": 5.566258907318115, \"labels\": \"suggested\"}, {\"x\": 6.920878887176514, \"y\": 6.940057754516602, \"labels\": \"loss\"}, {\"x\": 7.271875381469727, \"y\": 5.169411659240723, \"labels\": \"stars\"}, {\"x\": 4.022134780883789, \"y\": 6.145345687866211, \"labels\": \"components\"}, {\"x\": 5.496896266937256, \"y\": 4.859445095062256, \"labels\": \"instance\"}, {\"x\": 6.624697685241699, \"y\": 6.215302467346191, \"labels\": \"sexy\"}, {\"x\": 7.253018379211426, \"y\": 5.6163740158081055, \"labels\": \"limited\"}, {\"x\": 4.996974468231201, \"y\": 5.662869930267334, \"labels\": \"artisan\"}, {\"x\": 2.5755629539489746, \"y\": 3.6444296836853027, \"labels\": \"barbecue\"}, {\"x\": 6.438568115234375, \"y\": 4.079794406890869, \"labels\": \"type\"}, {\"x\": 5.8596296310424805, \"y\": 6.482016086578369, \"labels\": \"cheers\"}, {\"x\": 7.426113128662109, \"y\": 5.0113115310668945, \"labels\": \"anywhere\"}, {\"x\": 3.9130446910858154, \"y\": 4.001887798309326, \"labels\": \"fritos\"}, {\"x\": 5.4110517501831055, \"y\": 4.155843257904053, \"labels\": \"equally\"}, {\"x\": 0.45369666814804077, \"y\": 4.370968341827393, \"labels\": \"lemon\"}, {\"x\": 5.282474994659424, \"y\": 5.393893718719482, \"labels\": \"stones\"}, {\"x\": 5.693089962005615, \"y\": 7.129288673400879, \"labels\": \"wire\"}, {\"x\": 4.70296049118042, \"y\": 4.29421329498291, \"labels\": \"quesadillas\"}, {\"x\": 2.308411121368408, \"y\": 7.201327800750732, \"labels\": \"plate\"}, {\"x\": 7.468526840209961, \"y\": 7.813183307647705, \"labels\": \"didn\"}, {\"x\": 2.556457042694092, \"y\": 3.6664891242980957, \"labels\": \"hollandaise\"}, {\"x\": 2.7707273960113525, \"y\": 7.639313220977783, \"labels\": \"min\"}, {\"x\": 7.6334147453308105, \"y\": 6.718135833740234, \"labels\": \"excited\"}, {\"x\": 6.388792991638184, \"y\": 6.0471954345703125, \"labels\": \"recent\"}, {\"x\": 3.014127492904663, \"y\": 7.4498066902160645, \"labels\": \"around\"}, {\"x\": 6.743893146514893, \"y\": 2.8558716773986816, \"labels\": \"wiki\"}, {\"x\": 7.587263584136963, \"y\": 7.085090637207031, \"labels\": \"drunk\"}, {\"x\": 5.501452922821045, \"y\": 6.35107946395874, \"labels\": \"rubber\"}, {\"x\": 6.5367889404296875, \"y\": 7.005773544311523, \"labels\": \"accurately\"}, {\"x\": 1.5696732997894287, \"y\": 5.073638439178467, \"labels\": \"boiled\"}, {\"x\": 6.882744312286377, \"y\": 6.3605122566223145, \"labels\": \"suddenly\"}, {\"x\": 2.851130485534668, \"y\": 7.148934364318848, \"labels\": \"med\"}, {\"x\": 6.382445812225342, \"y\": 6.320942401885986, \"labels\": \"stayed\"}, {\"x\": 6.64541482925415, \"y\": 6.819140911102295, \"labels\": \"practical\"}, {\"x\": 3.494023084640503, \"y\": 5.968471527099609, \"labels\": \"pickling\"}, {\"x\": 4.608199596405029, \"y\": 5.183471202850342, \"labels\": \"dehydrated\"}, {\"x\": 8.304513931274414, \"y\": 4.7537407875061035, \"labels\": \"past\"}, {\"x\": 7.14952278137207, \"y\": 4.971993923187256, \"labels\": \"babish\"}, {\"x\": 5.10610294342041, \"y\": 5.829007625579834, \"labels\": \"woods\"}, {\"x\": 7.924312591552734, \"y\": 5.865566253662109, \"labels\": \"please\"}, {\"x\": 7.9430012702941895, \"y\": 6.981678485870361, \"labels\": \"dick\"}, {\"x\": 6.909709930419922, \"y\": 5.913870334625244, \"labels\": \"developed\"}, {\"x\": 5.650837421417236, \"y\": 6.288848400115967, \"labels\": \"delish\"}, {\"x\": 5.9110870361328125, \"y\": 8.3880615234375, \"labels\": \"recommend\"}, {\"x\": 4.137659549713135, \"y\": 6.458585739135742, \"labels\": \"dissolves\"}, {\"x\": 6.587097644805908, \"y\": 5.969860076904297, \"labels\": \"via\"}, {\"x\": 3.275413990020752, \"y\": 4.2386250495910645, \"labels\": \"bun\"}, {\"x\": 2.1599345207214355, \"y\": 4.363036632537842, \"labels\": \"ribs\"}, {\"x\": 7.365362644195557, \"y\": 4.382264614105225, \"labels\": \"supply\"}, {\"x\": 7.853586196899414, \"y\": 7.72426700592041, \"labels\": \"very\"}, {\"x\": 7.459790229797363, \"y\": 6.615256309509277, \"labels\": \"kidding\"}, {\"x\": 5.277355194091797, \"y\": 6.929204940795898, \"labels\": \"toxin\"}, {\"x\": 8.474637985229492, \"y\": 6.955476760864258, \"labels\": \"bet\"}, {\"x\": 7.076582908630371, \"y\": 5.280990123748779, \"labels\": \"actual\"}, {\"x\": 1.949696660041809, \"y\": 6.975475788116455, \"labels\": \"top\"}, {\"x\": 7.193742752075195, \"y\": 6.95660400390625, \"labels\": \"massive\"}, {\"x\": 6.487186431884766, \"y\": 6.428430080413818, \"labels\": \"planned\"}, {\"x\": 0.46225541830062866, \"y\": 4.240403175354004, \"labels\": \"basil\"}, {\"x\": 4.498508930206299, \"y\": 4.811994552612305, \"labels\": \"pair\"}, {\"x\": 8.268595695495605, \"y\": 6.463460445404053, \"labels\": \"where\"}, {\"x\": 5.90778923034668, \"y\": 6.555393218994141, \"labels\": \"tendency\"}, {\"x\": 4.876640319824219, \"y\": 7.771576404571533, \"labels\": \"picking\"}, {\"x\": 1.4883192777633667, \"y\": 4.99591588973999, \"labels\": \"strips\"}, {\"x\": 6.116321563720703, \"y\": 7.80087947845459, \"labels\": \"send\"}, {\"x\": 5.382137298583984, \"y\": 5.853363513946533, \"labels\": \"possibility\"}, {\"x\": 7.742042064666748, \"y\": 4.887150764465332, \"labels\": \"cookware\"}, {\"x\": 7.508460998535156, \"y\": 5.020954132080078, \"labels\": \"ninja\"}, {\"x\": 5.092066764831543, \"y\": 6.044532299041748, \"labels\": \"tasks\"}, {\"x\": 4.45224142074585, \"y\": 5.639608383178711, \"labels\": \"pleasant\"}, {\"x\": 5.6447529792785645, \"y\": 6.253174781799316, \"labels\": \"mum\"}, {\"x\": 8.355841636657715, \"y\": 4.746040344238281, \"labels\": \"time\"}, {\"x\": 5.928738117218018, \"y\": 5.548519134521484, \"labels\": \"thailand\"}, {\"x\": 4.009190082550049, \"y\": 6.152877330780029, \"labels\": \"bottoms\"}, {\"x\": 7.027759552001953, \"y\": 5.537430286407471, \"labels\": \"medical\"}, {\"x\": 6.947655200958252, \"y\": 7.616879940032959, \"labels\": \"ya\"}, {\"x\": 6.825413227081299, \"y\": 5.101128101348877, \"labels\": \"delivery\"}, {\"x\": 0.5492026209831238, \"y\": 4.163771152496338, \"labels\": \"carrot\"}, {\"x\": 6.84516716003418, \"y\": 6.595137596130371, \"labels\": \"customers\"}, {\"x\": 3.310567855834961, \"y\": 6.478890419006348, \"labels\": \"flatten\"}, {\"x\": 4.694450378417969, \"y\": 4.59758186340332, \"labels\": \"tinned\"}, {\"x\": 2.9899563789367676, \"y\": 4.999541282653809, \"labels\": \"salty\"}, {\"x\": 8.328995704650879, \"y\": 4.582034587860107, \"labels\": \"month\"}, {\"x\": 3.5443406105041504, \"y\": 3.9398412704467773, \"labels\": \"chutney\"}, {\"x\": 6.059535026550293, \"y\": 5.656567573547363, \"labels\": \"nine\"}, {\"x\": 0.45458364486694336, \"y\": 4.207086086273193, \"labels\": \"dried\"}, {\"x\": 4.94880485534668, \"y\": 5.3731560707092285, \"labels\": \"cow\"}, {\"x\": 1.685185432434082, \"y\": 6.276432991027832, \"labels\": \"pour\"}, {\"x\": 4.99368953704834, \"y\": 7.803762435913086, \"labels\": \"growing\"}, {\"x\": 6.8911237716674805, \"y\": 5.198293685913086, \"labels\": \"industrial\"}, {\"x\": 6.5720534324646, \"y\": 6.924265384674072, \"labels\": \"painful\"}, {\"x\": 8.564043998718262, \"y\": 6.662607669830322, \"labels\": \"haha\"}, {\"x\": 6.419719696044922, \"y\": 6.175780773162842, \"labels\": \"fil\"}, {\"x\": 3.6325950622558594, \"y\": 7.4160990715026855, \"labels\": \"moisture\"}, {\"x\": 5.990870475769043, \"y\": 8.223121643066406, \"labels\": \"imagine\"}, {\"x\": 2.2071354389190674, \"y\": 3.3221287727355957, \"labels\": \"pizza\"}, {\"x\": 5.809944152832031, \"y\": 5.777860641479492, \"labels\": \"misinformation\"}, {\"x\": 2.6291582584381104, \"y\": 6.198241710662842, \"labels\": \"flat\"}, {\"x\": 7.637117385864258, \"y\": 7.596604824066162, \"labels\": \"personally\"}, {\"x\": 6.592132091522217, \"y\": 7.551461219787598, \"labels\": \"normally\"}, {\"x\": 8.485325813293457, \"y\": 6.358007431030273, \"labels\": \"difference\"}, {\"x\": 2.3328981399536133, \"y\": 4.359714031219482, \"labels\": \"lemons\"}, {\"x\": 4.972105979919434, \"y\": 5.733591556549072, \"labels\": \"donuts\"}, {\"x\": 6.703176021575928, \"y\": 3.370887041091919, \"labels\": \"rouxbe\"}, {\"x\": 2.2293927669525146, \"y\": 4.076731204986572, \"labels\": \"filled\"}, {\"x\": 5.889227867126465, \"y\": 6.302700042724609, \"labels\": \"harm\"}, {\"x\": 5.554429531097412, \"y\": 6.412522792816162, \"labels\": \"cooktop\"}, {\"x\": 2.647022247314453, \"y\": 6.680906772613525, \"labels\": \"em\"}, {\"x\": 5.845998287200928, \"y\": 5.026378631591797, \"labels\": \"vegeta\"}, {\"x\": 6.839451313018799, \"y\": 4.003976345062256, \"labels\": \"people\"}, {\"x\": 6.465930938720703, \"y\": 7.458250999450684, \"labels\": \"barely\"}, {\"x\": 6.567764759063721, \"y\": 5.140188694000244, \"labels\": \"group\"}, {\"x\": 4.550116062164307, \"y\": 4.670812606811523, \"labels\": \"condiments\"}, {\"x\": 4.443673610687256, \"y\": 7.3803558349609375, \"labels\": \"result\"}, {\"x\": 6.767423152923584, \"y\": 5.5363640785217285, \"labels\": \"car\"}, {\"x\": 3.561725616455078, \"y\": 4.657497882843018, \"labels\": \"carcass\"}, {\"x\": 8.382615089416504, \"y\": 4.607979774475098, \"labels\": \"times\"}, {\"x\": 4.441436290740967, \"y\": 6.022032737731934, \"labels\": \"mandolin\"}, {\"x\": 2.2418699264526367, \"y\": 4.031702518463135, \"labels\": \"sprinkled\"}, {\"x\": 5.329527854919434, \"y\": 6.35282564163208, \"labels\": \"sleep\"}, {\"x\": 5.890229225158691, \"y\": 5.230586051940918, \"labels\": \"exercise\"}, {\"x\": 6.771641254425049, \"y\": 6.19260311126709, \"labels\": \"decision\"}, {\"x\": 5.707159519195557, \"y\": 5.433071613311768, \"labels\": \"citric\"}, {\"x\": 4.717647552490234, \"y\": 4.935867786407471, \"labels\": \"polish\"}, {\"x\": 7.458329677581787, \"y\": 4.0402116775512695, \"labels\": \"york\"}, {\"x\": 2.5616345405578613, \"y\": 7.392284393310547, \"labels\": \"while\"}, {\"x\": 6.236380100250244, \"y\": 5.632690906524658, \"labels\": \"aspects\"}, {\"x\": 7.660739421844482, \"y\": 4.466691017150879, \"labels\": \"summer\"}, {\"x\": 4.944337368011475, \"y\": 5.210567474365234, \"labels\": \"dirt\"}, {\"x\": 3.0556509494781494, \"y\": 3.8163506984710693, \"labels\": \"aioli\"}, {\"x\": 7.005121231079102, \"y\": 5.705268383026123, \"labels\": \"purposes\"}, {\"x\": 6.133118629455566, \"y\": 6.313625335693359, \"labels\": \"treated\"}, {\"x\": 4.704869747161865, \"y\": 5.355130672454834, \"labels\": \"diamond\"}, {\"x\": 6.452898979187012, \"y\": 6.214779376983643, \"labels\": \"hitting\"}, {\"x\": 7.3381028175354, \"y\": 4.482253551483154, \"labels\": \"multiple\"}, {\"x\": 0.4173862040042877, \"y\": 4.245893955230713, \"labels\": \"diced\"}, {\"x\": 7.445895195007324, \"y\": 4.3826117515563965, \"labels\": \"costco\"}, {\"x\": 5.739725589752197, \"y\": 6.085969924926758, \"labels\": \"ohio\"}, {\"x\": 4.788121700286865, \"y\": 5.873076438903809, \"labels\": \"overpowering\"}, {\"x\": 2.185858964920044, \"y\": 6.2818121910095215, \"labels\": \"dump\"}, {\"x\": 1.7704933881759644, \"y\": 4.2720136642456055, \"labels\": \"maple\"}, {\"x\": 6.730918884277344, \"y\": 5.3708720207214355, \"labels\": \"male\"}, {\"x\": 7.2823166847229, \"y\": 5.641366958618164, \"labels\": \"situation\"}, {\"x\": 5.624074935913086, \"y\": 6.734031677246094, \"labels\": \"crappy\"}, {\"x\": 6.187174320220947, \"y\": 6.890050411224365, \"labels\": \"inedible\"}, {\"x\": 3.359771490097046, \"y\": 7.545907974243164, \"labels\": \"ten\"}, {\"x\": 6.878818988800049, \"y\": 5.653932571411133, \"labels\": \"successful\"}, {\"x\": 2.723228693008423, \"y\": 7.694355487823486, \"labels\": \"hours\"}, {\"x\": 7.847959518432617, \"y\": 6.685572624206543, \"labels\": \"whether\"}, {\"x\": 5.9629998207092285, \"y\": 6.517089366912842, \"labels\": \"camping\"}, {\"x\": 0.6892673373222351, \"y\": 4.019242286682129, \"labels\": \"black\"}, {\"x\": 5.007216453552246, \"y\": 4.3541717529296875, \"labels\": \"signature\"}, {\"x\": 4.518558502197266, \"y\": 6.105005264282227, \"labels\": \"durability\"}, {\"x\": 2.690664768218994, \"y\": 6.299676895141602, \"labels\": \"seared\"}, {\"x\": 6.666623115539551, \"y\": 2.521533966064453, \"labels\": \"com_recipes\"}, {\"x\": 7.870112419128418, \"y\": 4.360500335693359, \"labels\": \"piece\"}, {\"x\": 7.83316707611084, \"y\": 5.509897708892822, \"labels\": \"lost\"}, {\"x\": 6.50179386138916, \"y\": 5.7337727546691895, \"labels\": \"foot\"}, {\"x\": 3.2549126148223877, \"y\": 7.156866073608398, \"labels\": \"drying\"}, {\"x\": 7.289175510406494, \"y\": 4.690367698669434, \"labels\": \"china\"}, {\"x\": 5.788998126983643, \"y\": 5.224886417388916, \"labels\": \"gluten\"}, {\"x\": 6.586124897003174, \"y\": 6.414276123046875, \"labels\": \"sounded\"}, {\"x\": 5.8735833168029785, \"y\": 4.340170860290527, \"labels\": \"vary\"}, {\"x\": 4.66195011138916, \"y\": 5.20498514175415, \"labels\": \"miracle\"}, {\"x\": 6.284368515014648, \"y\": 7.626001834869385, \"labels\": \"decide\"}, {\"x\": 5.228693008422852, \"y\": 6.655735969543457, \"labels\": \"churn\"}, {\"x\": 6.759027481079102, \"y\": 3.4826443195343018, \"labels\": \"crocker\"}, {\"x\": 6.704382419586182, \"y\": 2.650273084640503, \"labels\": \"foodnetwork\"}, {\"x\": 5.826128005981445, \"y\": 7.095405101776123, \"labels\": \"prepping\"}, {\"x\": 8.058036804199219, \"y\": 4.446770668029785, \"labels\": \"amazon\"}, {\"x\": 1.4854015111923218, \"y\": 3.9896764755249023, \"labels\": \"eggplant\"}, {\"x\": 1.876574158668518, \"y\": 5.093388080596924, \"labels\": \"lb\"}, {\"x\": 8.308781623840332, \"y\": 5.639889717102051, \"labels\": \"only\"}, {\"x\": 8.62757682800293, \"y\": 6.949436187744141, \"labels\": \"knew\"}, {\"x\": 0.8589374423027039, \"y\": 4.850818157196045, \"labels\": \"butter\"}, {\"x\": 7.213703632354736, \"y\": 7.334251880645752, \"labels\": \"weed\"}, {\"x\": 6.155520439147949, \"y\": 7.446307182312012, \"labels\": \"ability\"}, {\"x\": 3.1257481575012207, \"y\": 7.333329677581787, \"labels\": \"door\"}, {\"x\": 2.523202657699585, \"y\": 6.095425605773926, \"labels\": \"and\"}, {\"x\": 5.716434478759766, \"y\": 6.501105308532715, \"labels\": \"measured\"}, {\"x\": 1.5007591247558594, \"y\": 4.37099027633667, \"labels\": \"clove\"}, {\"x\": 6.374300003051758, \"y\": 4.649941921234131, \"labels\": \"heavily\"}, {\"x\": 3.7133307456970215, \"y\": 5.563913822174072, \"labels\": \"ish\"}, {\"x\": 1.7621090412139893, \"y\": 4.116006851196289, \"labels\": \"capers\"}, {\"x\": 5.350705623626709, \"y\": 3.9583580493927, \"labels\": \"winner\"}, {\"x\": 6.485315799713135, \"y\": 4.377477169036865, \"labels\": \"names\"}, {\"x\": 4.752810478210449, \"y\": 7.252391338348389, \"labels\": \"allowing\"}, {\"x\": 4.494178771972656, \"y\": 4.8445305824279785, \"labels\": \"undercooked\"}, {\"x\": 2.9075183868408203, \"y\": 7.5993170738220215, \"labels\": \"rare\"}, {\"x\": 7.526896953582764, \"y\": 7.367690563201904, \"labels\": \"guys\"}, {\"x\": 4.2188801765441895, \"y\": 5.063375949859619, \"labels\": \"neck\"}, {\"x\": 4.32046365737915, \"y\": 6.944477081298828, \"labels\": \"length\"}, {\"x\": 7.727718830108643, \"y\": 7.072261333465576, \"labels\": \"lazy\"}, {\"x\": 6.237922668457031, \"y\": 7.026007652282715, \"labels\": \"acquired\"}, {\"x\": 6.541562080383301, \"y\": 4.594483852386475, \"labels\": \"vote\"}, {\"x\": 6.800631999969482, \"y\": 7.043024063110352, \"labels\": \"nasty\"}, {\"x\": 4.4188408851623535, \"y\": 5.175551414489746, \"labels\": \"lobsters\"}, {\"x\": 8.328181266784668, \"y\": 7.082057952880859, \"labels\": \"funny\"}, {\"x\": 1.0956087112426758, \"y\": 4.3537187576293945, \"labels\": \"tea\"}, {\"x\": 4.390808582305908, \"y\": 5.844353675842285, \"labels\": \"intense\"}, {\"x\": 6.123988151550293, \"y\": 5.121546745300293, \"labels\": \"enamel\"}, {\"x\": 2.997853994369507, \"y\": 7.1790361404418945, \"labels\": \"left\"}, {\"x\": 2.0279150009155273, \"y\": 3.631801128387451, \"labels\": \"ice_cream\"}, {\"x\": 2.8784306049346924, \"y\": 4.8183112144470215, \"labels\": \"patties\"}, {\"x\": 7.958462238311768, \"y\": 7.11175537109375, \"labels\": \"helpful\"}, {\"x\": 5.5096211433410645, \"y\": 6.13264274597168, \"labels\": \"jesus\"}, {\"x\": 7.7533135414123535, \"y\": 5.892489910125732, \"labels\": \"daily\"}, {\"x\": 7.375018119812012, \"y\": 7.934748649597168, \"labels\": \"wouldn\"}, {\"x\": 5.412262916564941, \"y\": 7.506061553955078, \"labels\": \"checking\"}, {\"x\": 5.805132865905762, \"y\": 6.570614337921143, \"labels\": \"oxtail\"}, {\"x\": 4.239814758300781, \"y\": 5.535086154937744, \"labels\": \"lean\"}, {\"x\": 2.373894214630127, \"y\": 6.609827041625977, \"labels\": \"together\"}, {\"x\": 8.473012924194336, \"y\": 7.194793224334717, \"labels\": \"sure\"}, {\"x\": 5.022631645202637, \"y\": 6.459378719329834, \"labels\": \"granite\"}, {\"x\": 1.4213021993637085, \"y\": 4.815284252166748, \"labels\": \"noodles\"}, {\"x\": 3.4651691913604736, \"y\": 6.03634786605835, \"labels\": \"sunny\"}, {\"x\": 4.656325340270996, \"y\": 5.914186000823975, \"labels\": \"provides\"}, {\"x\": 1.9219306707382202, \"y\": 6.329462051391602, \"labels\": \"whisk\"}, {\"x\": 0.8140580654144287, \"y\": 3.885808229446411, \"labels\": \"squash\"}, {\"x\": 8.242121696472168, \"y\": 7.420385360717773, \"labels\": \"totally\"}, {\"x\": 4.170339107513428, \"y\": 4.416300296783447, \"labels\": \"plant\"}, {\"x\": 5.91118860244751, \"y\": 5.584873676300049, \"labels\": \"durian\"}, {\"x\": 6.071923732757568, \"y\": 6.765429973602295, \"labels\": \"aggressive\"}, {\"x\": 4.47476863861084, \"y\": 4.034237861633301, \"labels\": \"idaho\"}, {\"x\": 6.5521559715271, \"y\": 2.59074068069458, \"labels\": \"qid\"}, {\"x\": 6.097253322601318, \"y\": 5.006122589111328, \"labels\": \"glutamate\"}, {\"x\": 5.343245983123779, \"y\": 8.522541999816895, \"labels\": \"keep\"}, {\"x\": 6.200064659118652, \"y\": 5.508645057678223, \"labels\": \"germany\"}, {\"x\": 4.336687088012695, \"y\": 3.4419732093811035, \"labels\": \"vegan\"}, {\"x\": 8.401418685913086, \"y\": 6.542623996734619, \"labels\": \"written\"}, {\"x\": 3.063066244125366, \"y\": 7.359266757965088, \"labels\": \"the\"}, {\"x\": 5.044914245605469, \"y\": 8.227725982666016, \"labels\": \"went\"}, {\"x\": 6.8825602531433105, \"y\": 5.3506293296813965, \"labels\": \"excuse\"}, {\"x\": 2.575934410095215, \"y\": 4.048445701599121, \"labels\": \"sun\"}, {\"x\": 6.718021869659424, \"y\": 4.07179069519043, \"labels\": \"common\"}, {\"x\": 1.152646541595459, \"y\": 4.23631477355957, \"labels\": \"chile\"}, {\"x\": 6.551087856292725, \"y\": 6.294186115264893, \"labels\": \"matters\"}, {\"x\": 5.1830291748046875, \"y\": 7.042321681976318, \"labels\": \"invest\"}, {\"x\": 3.415057897567749, \"y\": 3.506105899810791, \"labels\": \"meringue\"}, {\"x\": 7.519548416137695, \"y\": 6.276424884796143, \"labels\": \"moving\"}, {\"x\": 5.2045392990112305, \"y\": 4.5496320724487305, \"labels\": \"sealer\"}, {\"x\": 8.416895866394043, \"y\": 7.23874568939209, \"labels\": \"wrong\"}, {\"x\": 7.880906105041504, \"y\": 5.774209499359131, \"labels\": \"front\"}, {\"x\": 2.042072057723999, \"y\": 6.814084053039551, \"labels\": \"onto\"}, {\"x\": 7.853475570678711, \"y\": 6.097630023956299, \"labels\": \"unfortunately\"}, {\"x\": 6.809179306030273, \"y\": 7.091353416442871, \"labels\": \"pressed\"}, {\"x\": 5.624813079833984, \"y\": 6.598389148712158, \"labels\": \"aim\"}, {\"x\": 6.8204803466796875, \"y\": 5.149890899658203, \"labels\": \"ingredient\"}, {\"x\": 5.812913417816162, \"y\": 6.187698841094971, \"labels\": \"occasions\"}, {\"x\": 4.88458776473999, \"y\": 7.880486488342285, \"labels\": \"push\"}, {\"x\": 5.356192111968994, \"y\": 6.397581100463867, \"labels\": \"knuckles\"}, {\"x\": 5.517637252807617, \"y\": 4.235540866851807, \"labels\": \"dang\"}, {\"x\": 8.221301078796387, \"y\": 7.456005096435547, \"labels\": \"definitely\"}, {\"x\": 2.772336006164551, \"y\": 6.7991437911987305, \"labels\": \"refrigerate\"}, {\"x\": 1.0318126678466797, \"y\": 3.8359854221343994, \"labels\": \"mushroom\"}, {\"x\": 7.767885684967041, \"y\": 4.530484199523926, \"labels\": \"thanksgiving\"}, {\"x\": 7.017489910125732, \"y\": 4.619518280029297, \"labels\": \"newer\"}, {\"x\": 6.612334728240967, \"y\": 6.581650257110596, \"labels\": \"circumstance\"}, {\"x\": 7.818561553955078, \"y\": 6.218316078186035, \"labels\": \"somewhere\"}, {\"x\": 5.057873249053955, \"y\": 5.760656356811523, \"labels\": \"nutrition\"}, {\"x\": 3.5221266746520996, \"y\": 5.3130693435668945, \"labels\": \"poaching\"}, {\"x\": 7.725841522216797, \"y\": 6.472249984741211, \"labels\": \"mad\"}, {\"x\": 6.770376682281494, \"y\": 6.499268531799316, \"labels\": \"shared\"}, {\"x\": 4.849064350128174, \"y\": 4.494684219360352, \"labels\": \"overcooked\"}, {\"x\": 8.638233184814453, \"y\": 6.938426971435547, \"labels\": \"told\"}, {\"x\": 7.620055198669434, \"y\": 6.4883646965026855, \"labels\": \"known\"}, {\"x\": 5.145924091339111, \"y\": 7.262322425842285, \"labels\": \"react\"}, {\"x\": 4.25627326965332, \"y\": 5.179232597351074, \"labels\": \"gum\"}, {\"x\": 2.4568228721618652, \"y\": 4.131890296936035, \"labels\": \"saffron\"}, {\"x\": 7.073960781097412, \"y\": 4.166972637176514, \"labels\": \"markets\"}, {\"x\": 5.7058281898498535, \"y\": 6.394803524017334, \"labels\": \"thermapen\"}, {\"x\": 5.211705684661865, \"y\": 6.482276916503906, \"labels\": \"flying\"}, {\"x\": 3.904400110244751, \"y\": 7.352304935455322, \"labels\": \"hits\"}, {\"x\": 5.724309921264648, \"y\": 4.206052303314209, \"labels\": \"involves\"}, {\"x\": 5.476912498474121, \"y\": 4.979185581207275, \"labels\": \"papa\"}, {\"x\": 3.870333194732666, \"y\": 5.577037811279297, \"labels\": \"lighter\"}, {\"x\": 6.56058406829834, \"y\": 3.3372623920440674, \"labels\": \"bleep\"}, {\"x\": 7.363778591156006, \"y\": 7.360281944274902, \"labels\": \"ill\"}, {\"x\": 7.490572929382324, \"y\": 5.954354763031006, \"labels\": \"guest\"}, {\"x\": 1.5306708812713623, \"y\": 5.173608303070068, \"labels\": \"rub\"}, {\"x\": 6.636835098266602, \"y\": 5.543436527252197, \"labels\": \"good_luck\"}, {\"x\": 1.2693545818328857, \"y\": 4.310129642486572, \"labels\": \"caramelized\"}, {\"x\": 6.760440349578857, \"y\": 6.47778844833374, \"labels\": \"russian\"}, {\"x\": 4.892501354217529, \"y\": 5.598354816436768, \"labels\": \"crystals\"}, {\"x\": 6.855642795562744, \"y\": 6.990023136138916, \"labels\": \"cross\"}, {\"x\": 1.5189875364303589, \"y\": 5.217122554779053, \"labels\": \"lightly\"}, {\"x\": 5.525235176086426, \"y\": 5.144463062286377, \"labels\": \"land\"}, {\"x\": 4.270115375518799, \"y\": 5.485520362854004, \"labels\": \"delicate\"}, {\"x\": 3.486015558242798, \"y\": 6.684218406677246, \"labels\": \"build\"}, {\"x\": 7.1598663330078125, \"y\": 6.048417091369629, \"labels\": \"casual\"}, {\"x\": 0.6632214784622192, \"y\": 4.440667152404785, \"labels\": \"dijon\"}, {\"x\": 1.5746674537658691, \"y\": 5.1237688064575195, \"labels\": \"eggs\"}, {\"x\": 1.9062401056289673, \"y\": 6.511538982391357, \"labels\": \"cover\"}, {\"x\": 0.9341796636581421, \"y\": 4.379176616668701, \"labels\": \"scallions\"}, {\"x\": 4.103501796722412, \"y\": 4.1019463539123535, \"labels\": \"pate\"}, {\"x\": 4.349558353424072, \"y\": 4.251121520996094, \"labels\": \"mixes\"}, {\"x\": 3.410917043685913, \"y\": 7.133276462554932, \"labels\": \"ss\"}, {\"x\": 3.189382553100586, \"y\": 4.48978328704834, \"labels\": \"carmelized\"}, {\"x\": 5.739688396453857, \"y\": 6.1056365966796875, \"labels\": \"mistakes\"}, {\"x\": 2.3044965267181396, \"y\": 3.906520366668701, \"labels\": \"cranberries\"}, {\"x\": 5.872627258300781, \"y\": 6.561370849609375, \"labels\": \"doors\"}, {\"x\": 3.971301317214966, \"y\": 4.225734710693359, \"labels\": \"tart\"}, {\"x\": 5.7984395027160645, \"y\": 6.76619815826416, \"labels\": \"code\"}, {\"x\": 7.405819892883301, \"y\": 4.094357013702393, \"labels\": \"farmer\"}, {\"x\": 8.574483871459961, \"y\": 6.454123497009277, \"labels\": \"word\"}, {\"x\": 3.4508306980133057, \"y\": 4.335867404937744, \"labels\": \"gooey\"}, {\"x\": 3.804651975631714, \"y\": 5.1139631271362305, \"labels\": \"florets\"}, {\"x\": 4.868759632110596, \"y\": 5.399247646331787, \"labels\": \"crystal\"}, {\"x\": 8.174970626831055, \"y\": 6.877399921417236, \"labels\": \"sad\"}, {\"x\": 3.3784542083740234, \"y\": 4.102039337158203, \"labels\": \"artichokes\"}, {\"x\": 4.630248546600342, \"y\": 7.549937725067139, \"labels\": \"faster\"}, {\"x\": 5.935615062713623, \"y\": 5.1018452644348145, \"labels\": \"jessie\"}, {\"x\": 7.917140483856201, \"y\": 5.532064437866211, \"labels\": \"model\"}, {\"x\": 6.885184288024902, \"y\": 6.352802276611328, \"labels\": \"proud\"}, {\"x\": 4.830353260040283, \"y\": 5.275740146636963, \"labels\": \"harvest\"}, {\"x\": 3.766295909881592, \"y\": 3.6834464073181152, \"labels\": \"combo\"}, {\"x\": 6.023553371429443, \"y\": 6.0018086433410645, \"labels\": \"killing\"}, {\"x\": 4.808135032653809, \"y\": 7.458775997161865, \"labels\": \"breaks\"}, {\"x\": 4.146144390106201, \"y\": 5.392756938934326, \"labels\": \"spots\"}, {\"x\": 5.2790045738220215, \"y\": 5.900180339813232, \"labels\": \"blanket\"}, {\"x\": 2.022073745727539, \"y\": 7.070728302001953, \"labels\": \"paper\"}, {\"x\": 7.102802753448486, \"y\": 5.702422142028809, \"labels\": \"wishes\"}, {\"x\": 6.763720512390137, \"y\": 4.267560005187988, \"labels\": \"list\"}, {\"x\": 3.1161367893218994, \"y\": 5.8542914390563965, \"labels\": \"briefly\"}, {\"x\": 6.161277770996094, \"y\": 6.715807914733887, \"labels\": \"poorly\"}, {\"x\": 7.1425604820251465, \"y\": 6.796468257904053, \"labels\": \"nowhere\"}, {\"x\": 3.041055917739868, \"y\": 5.383742332458496, \"labels\": \"layered\"}, {\"x\": 1.668503999710083, \"y\": 6.31301212310791, \"labels\": \"toss\"}, {\"x\": 6.709963798522949, \"y\": 5.733559608459473, \"labels\": \"bittman\"}, {\"x\": 2.8229000568389893, \"y\": 6.7914347648620605, \"labels\": \"chopping\"}, {\"x\": 4.997493267059326, \"y\": 8.249947547912598, \"labels\": \"came\"}, {\"x\": 7.438246250152588, \"y\": 6.260987281799316, \"labels\": \"awhile\"}, {\"x\": 5.312766075134277, \"y\": 6.172245979309082, \"labels\": \"floor\"}, {\"x\": 5.855847358703613, \"y\": 6.982831001281738, \"labels\": \"changing\"}, {\"x\": 3.8350486755371094, \"y\": 5.977960586547852, \"labels\": \"connective\"}, {\"x\": 6.554490566253662, \"y\": 5.69807243347168, \"labels\": \"solved\"}, {\"x\": 7.5776872634887695, \"y\": 7.283515930175781, \"labels\": \"satisfying\"}, {\"x\": 3.5864267349243164, \"y\": 5.849625110626221, \"labels\": \"saltiness\"}, {\"x\": 6.706211566925049, \"y\": 6.266628265380859, \"labels\": \"prefers\"}, {\"x\": 5.605689525604248, \"y\": 6.584275722503662, \"labels\": \"hassle\"}, {\"x\": 6.306830883026123, \"y\": 4.1462249755859375, \"labels\": \"loads\"}, {\"x\": 2.7167608737945557, \"y\": 6.711920738220215, \"labels\": \"tight\"}, {\"x\": 8.717122077941895, \"y\": 6.642984867095947, \"labels\": \"saying\"}, {\"x\": 7.369681358337402, \"y\": 6.395853519439697, \"labels\": \"fad\"}, {\"x\": 2.3222973346710205, \"y\": 3.942890167236328, \"labels\": \"berries\"}, {\"x\": 1.2638871669769287, \"y\": 4.508968353271484, \"labels\": \"slices\"}, {\"x\": 6.528896331787109, \"y\": 5.6148271560668945, \"labels\": \"nature\"}, {\"x\": 7.397146701812744, \"y\": 6.071317672729492, \"labels\": \"feeding\"}, {\"x\": 3.5318822860717773, \"y\": 6.835032939910889, \"labels\": \"switch\"}, {\"x\": 2.8529083728790283, \"y\": 5.39772367477417, \"labels\": \"texture\"}, {\"x\": 3.8089041709899902, \"y\": 4.351228713989258, \"labels\": \"earl\"}, {\"x\": 4.735340595245361, \"y\": 4.560976028442383, \"labels\": \"sweets\"}, {\"x\": 1.8847293853759766, \"y\": 4.170025825500488, \"labels\": \"chops\"}, {\"x\": 6.967166423797607, \"y\": 7.1617350578308105, \"labels\": \"bothered\"}, {\"x\": 5.64653205871582, \"y\": 6.3628435134887695, \"labels\": \"appetite\"}, {\"x\": 2.8709840774536133, \"y\": 6.629060745239258, \"labels\": \"boils\"}, {\"x\": 8.613277435302734, \"y\": 6.5895771980285645, \"labels\": \"bought\"}, {\"x\": 6.399872779846191, \"y\": 7.427722930908203, \"labels\": \"cooks\"}, {\"x\": 5.572012901306152, \"y\": 7.162171363830566, \"labels\": \"maintaining\"}, {\"x\": 6.233484268188477, \"y\": 5.689359664916992, \"labels\": \"carry\"}, {\"x\": 5.357965469360352, \"y\": 5.003743648529053, \"labels\": \"oooh\"}, {\"x\": 4.277000427246094, \"y\": 5.660331726074219, \"labels\": \"chewy\"}, {\"x\": 4.41644287109375, \"y\": 5.872910976409912, \"labels\": \"finer\"}, {\"x\": 4.949196815490723, \"y\": 4.3867692947387695, \"labels\": \"pizzas\"}, {\"x\": 6.443256855010986, \"y\": 5.591481685638428, \"labels\": \"maine\"}, {\"x\": 3.507075309753418, \"y\": 6.015480041503906, \"labels\": \"fluff\"}, {\"x\": 6.121001243591309, \"y\": 5.2576398849487305, \"labels\": \"roommates\"}, {\"x\": 1.9266936779022217, \"y\": 6.766483306884766, \"labels\": \"layer\"}, {\"x\": 5.4462456703186035, \"y\": 3.9589831829071045, \"labels\": \"flan\"}, {\"x\": 6.63837194442749, \"y\": 3.5649967193603516, \"labels\": \"compose\"}, {\"x\": 3.7579920291900635, \"y\": 7.680686950683594, \"labels\": \"point\"}, {\"x\": 6.764159679412842, \"y\": 7.113883972167969, \"labels\": \"active\"}, {\"x\": 7.010047435760498, \"y\": 4.584557056427002, \"labels\": \"joe\"}, {\"x\": 5.495547771453857, \"y\": 7.258085250854492, \"labels\": \"manage\"}, {\"x\": 6.920475959777832, \"y\": 6.916472434997559, \"labels\": \"contamination\"}, {\"x\": 2.8222761154174805, \"y\": 6.67649507522583, \"labels\": \"kernels\"}, {\"x\": 3.235771417617798, \"y\": 7.447188854217529, \"labels\": \"stainless_steel\"}, {\"x\": 8.571714401245117, \"y\": 6.411210536956787, \"labels\": \"been\"}, {\"x\": 7.771962642669678, \"y\": 4.69899320602417, \"labels\": \"previous\"}, {\"x\": 6.810929298400879, \"y\": 7.259775161743164, \"labels\": \"pasteurized\"}, {\"x\": 6.050509452819824, \"y\": 6.969161510467529, \"labels\": \"affects\"}, {\"x\": 8.535476684570312, \"y\": 6.686547756195068, \"labels\": \"ever\"}, {\"x\": 3.9474236965179443, \"y\": 6.258000373840332, \"labels\": \"grab\"}, {\"x\": 2.597842216491699, \"y\": 5.151651382446289, \"labels\": \"sweetness\"}, {\"x\": 5.6889214515686035, \"y\": 7.185798645019531, \"labels\": \"drive\"}, {\"x\": 3.6743383407592773, \"y\": 4.805727958679199, \"labels\": \"muffins\"}, {\"x\": 0.7498522400856018, \"y\": 4.636831760406494, \"labels\": \"cup\"}, {\"x\": 8.216120719909668, \"y\": 7.075136661529541, \"labels\": \"weird\"}, {\"x\": 7.256562232971191, \"y\": 7.103219985961914, \"labels\": \"heck\"}, {\"x\": 7.164412975311279, \"y\": 6.689873218536377, \"labels\": \"vague\"}, {\"x\": 6.271545886993408, \"y\": 5.298714637756348, \"labels\": \"perspective\"}, {\"x\": 2.2899296283721924, \"y\": 3.9841468334198, \"labels\": \"garden\"}, {\"x\": 5.09116268157959, \"y\": 5.932650566101074, \"labels\": \"corner\"}, {\"x\": 5.242051601409912, \"y\": 5.915433406829834, \"labels\": \"bc\"}, {\"x\": 6.754568576812744, \"y\": 6.705467224121094, \"labels\": \"relative\"}, {\"x\": 7.131527900695801, \"y\": 4.538862228393555, \"labels\": \"target\"}, {\"x\": 7.078652381896973, \"y\": 4.29213285446167, \"labels\": \"farmers\"}, {\"x\": 3.37198543548584, \"y\": 5.944868087768555, \"labels\": \"ideally\"}, {\"x\": 4.949089050292969, \"y\": 4.626619815826416, \"labels\": \"stewing\"}, {\"x\": 5.541515827178955, \"y\": 6.822859287261963, \"labels\": \"mellow\"}, {\"x\": 5.321473121643066, \"y\": 6.4699177742004395, \"labels\": \"protect\"}, {\"x\": 7.347725868225098, \"y\": 5.247928619384766, \"labels\": \"above\"}, {\"x\": 3.5710127353668213, \"y\": 5.5908708572387695, \"labels\": \"layers\"}, {\"x\": 3.5258965492248535, \"y\": 4.03749942779541, \"labels\": \"penne\"}, {\"x\": 3.0606346130371094, \"y\": 6.50576639175415, \"labels\": \"scrape\"}, {\"x\": 8.589530944824219, \"y\": 6.736143589019775, \"labels\": \"why\"}, {\"x\": 3.7952044010162354, \"y\": 6.9230475425720215, \"labels\": \"tramontina\"}, {\"x\": 4.9407782554626465, \"y\": 5.156785011291504, \"labels\": \"shredding\"}, {\"x\": 1.1504615545272827, \"y\": 4.605632305145264, \"labels\": \"pinch\"}, {\"x\": 5.009209632873535, \"y\": 6.249457836151123, \"labels\": \"spine\"}, {\"x\": 6.773486137390137, \"y\": 6.175994873046875, \"labels\": \"unnecessary\"}, {\"x\": 2.35306453704834, \"y\": 7.205097675323486, \"labels\": \"finish\"}, {\"x\": 5.9833903312683105, \"y\": 4.911733627319336, \"labels\": \"heston\"}, {\"x\": 6.14251184463501, \"y\": 7.730346202850342, \"labels\": \"helps\"}, {\"x\": 6.143117427825928, \"y\": 7.661555767059326, \"labels\": \"needed\"}, {\"x\": 8.759098052978516, \"y\": 6.426643371582031, \"labels\": \"sorry\"}, {\"x\": 6.74062967300415, \"y\": 5.653560638427734, \"labels\": \"shame\"}, {\"x\": 7.307412147521973, \"y\": 5.712639808654785, \"labels\": \"calorie\"}, {\"x\": 6.1360249519348145, \"y\": 4.526134014129639, \"labels\": \"substances\"}, {\"x\": 3.0536177158355713, \"y\": 7.538111209869385, \"labels\": \"searing\"}, {\"x\": 6.731529712677002, \"y\": 6.528568744659424, \"labels\": \"alcoholic\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create sentence embeddings from our W2V model\n",
        "\n",
        "The final aim is to use the custom W2V embeddings to vectorize sentences\n",
        "We will look at average vectors and tfidf weighted avg. embeddings"
      ],
      "metadata": {
        "id": "l5PqPdQ-1ZGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sents = ['I love chicken super much with soy',\n",
        "              'I enjoy asian food, especially chicken',\n",
        "              'Give me cake', 'mexican food is amazing', \n",
        "              'I enjoy cuisine italian']"
      ],
      "metadata": {
        "id": "NnMrUI9-DV-x"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average W2V vectors"
      ],
      "metadata": {
        "id": "6rk45Tw82I7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = phrase_model[utils.simple_preprocess(test_sents[0])]"
      ],
      "metadata": {
        "id": "iH7vW_CJEhCh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out only those words that are part of the vocab\n",
        "tokens = [t for t in tokens if t in model.wv.key_to_index.keys()]"
      ],
      "metadata": {
        "id": "49ZKmF_1EwnD"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create average-vectors\n",
        "avg_vec = np.average([model.wv[t] for t in tokens], axis=0)"
      ],
      "metadata": {
        "id": "OjQy6-_8ExU7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's package this process up into a vectorizer-function"
      ],
      "metadata": {
        "id": "eIr84l6s15lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_vectorize(text):\n",
        "  tokens = phrase_model[utils.simple_preprocess(text)] # preprocess just as model inputs\n",
        "  tokens = [t for t in tokens if t in model.wv.key_to_index.keys()] # filter only tokens that are in vocab\n",
        "  return np.average([model.wv[t] for t in tokens], axis=0) # calculate avg vector"
      ],
      "metadata": {
        "id": "AgqwnSESFr__"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it's a goof idea to stack them using numpy into a matrix\n",
        "vecs = np.vstack([w2v_vectorize(s) for s in test_sents])"
      ],
      "metadata": {
        "id": "5oBT2PDuGba4"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick explaininng of the vectors (not really part of the code)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(vecs)"
      ],
      "metadata": {
        "id": "vZrrwfXWGOl7",
        "outputId": "121894f6-019d-4f4f-ab1f-afa5d08f6f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999964, 0.34846756, 0.13731556, 0.26950514, 0.34354964],\n",
              "       [0.34846756, 0.9999999 , 0.19795777, 0.68343115, 0.6109475 ],\n",
              "       [0.13731556, 0.19795777, 1.0000002 , 0.216211  , 0.28588519],\n",
              "       [0.26950514, 0.68343115, 0.216211  , 0.99999994, 0.7157878 ],\n",
              "       [0.34354964, 0.6109475 , 0.28588519, 0.7157878 , 0.9999995 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFIDF weighted W2V Embeddings\n",
        "\n",
        "Very similar to avg-embeddings, however here we will use sklearn TfidfVectorizer (that one we already know) to weight our vecs\n",
        "The approach is a bit \"hacky\" but efficient"
      ],
      "metadata": {
        "id": "_ijrfvUc2Ggg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "CqPGDRipIirt"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that does absolutely nothing...\n",
        "# cause we do prepro and tokenization in one using gensim, we will define it for prepro\n",
        "def dummy_fun(doc):\n",
        "    return doc"
      ],
      "metadata": {
        "id": "AJhijzyt_3D5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[phrase_model[utils.simple_preprocess(text)] for text in test_sents]"
      ],
      "metadata": {
        "id": "WTWxNqKdKAzk",
        "outputId": "6aca6f6a-286f-4c3e-8fe8-6c5dcd899f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['love', 'chicken', 'super', 'much', 'with', 'soy'],\n",
              " ['enjoy', 'asian', 'food', 'especially', 'chicken'],\n",
              " ['give', 'me', 'cake'],\n",
              " ['mexican', 'food', 'is', 'amazing'],\n",
              " ['enjoy', 'cuisine', 'italian']]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we define a preprocessing function to pass into the TfidfVectorizer\n",
        "def gensim_prepro(doc):\n",
        "  return phrase_model[utils.simple_preprocess(doc)]"
      ],
      "metadata": {
        "id": "BRhTvA39Jkzi"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we turn of any preprocessing and align vocabulary with the one\n",
        "# used by our embeddings\n",
        "# that will allow us to use TFIDF vectors to weight the embeddings\n",
        "\n",
        "tfidf_new_text = TfidfVectorizer(\n",
        "    vocabulary=model.wv.key_to_index.keys(), # here using the W2V vocab\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=gensim_prepro,\n",
        "    token_pattern=None)  "
      ],
      "metadata": {
        "id": "4Nr9PLLr_5ox"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TFIDF matrix (we could also just use that one for search)\n",
        "new_tfidf = tfidf_new_text.fit_transform(test_sents)"
      ],
      "metadata": {
        "id": "klAEuO17KK36"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_tfidf"
      ],
      "metadata": {
        "id": "isLYA0oAKNuu",
        "outputId": "28052e28-7206-4b47-a6f6-c057651f6759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5x4857 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 21 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This here is a cool little trick: Since N-columns for the TFIDF is the same as n-rows for our word-embeddings we can simply take a dot-product here.\n",
        "Another cool feature: this can be done sequentially for large datasets (when no space in ram)"
      ],
      "metadata": {
        "id": "h4VM3Bwh24qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating TFIDF-weighted avg. embeddings\n",
        "test_w2v_tfidf = new_tfidf @ model.wv.vectors"
      ],
      "metadata": {
        "id": "6mcA211_KfbX"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_w2v_tfidf.shape"
      ],
      "metadata": {
        "id": "xCFOJaL2DRpf",
        "outputId": "23fd3b2d-1ed0-47b0-a937-95683cd468f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(test_w2v_tfidf)"
      ],
      "metadata": {
        "id": "1a1Iz7K2KsIA",
        "outputId": "9ff58272-0488-4a60-847c-e7d1e14c7421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.29710012, 0.14867027, 0.31735163, 0.34757172],\n",
              "       [0.29710012, 1.        , 0.18192084, 0.66205786, 0.63341578],\n",
              "       [0.14867027, 0.18192084, 1.        , 0.20667902, 0.24786758],\n",
              "       [0.31735163, 0.66205786, 0.20667902, 1.        , 0.7374783 ],\n",
              "       [0.34757172, 0.63341578, 0.24786758, 0.7374783 , 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using these embeddings for semantic search\n",
        "We can use such embeddings (and others) for semantic search (similarity maximization) and also downstream in unsuprvised/supervised tasks."
      ],
      "metadata": {
        "id": "55WP1y523Uzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create TFIDF matrix for all\n",
        "tfidf_all = tfidf_new_text.fit_transform(data['text'])"
      ],
      "metadata": {
        "id": "qnH5ZGW5Rdtj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get vecs by dot-product\n",
        "tfidf_w2v_all = tfidf_all @ model.wv.vectors"
      ],
      "metadata": {
        "id": "fAlFvbJ6RsKD"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make query and transform it into same vector-space\n",
        "\n",
        "query = 'Italian breakfast'\n",
        "\n",
        "tfidf_q = tfidf_new_text.transform([query]) \n",
        "tfidf_w2v_q = tfidf_q @ model.wv.vectors"
      ],
      "metadata": {
        "id": "FpiMq9GQRw0D"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cos-sim between the query and all vecs\n",
        "\n",
        "distances = cosine_similarity(tfidf_w2v_q,tfidf_w2v_all)"
      ],
      "metadata": {
        "id": "I9cwoccNUyz7"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get corresponding texts\n",
        "ids = np.flip(np.argsort(distances))[0]\n",
        "ids"
      ],
      "metadata": {
        "id": "P4Pw36GKUuUv",
        "outputId": "cca498db-bd4f-4f99-baff-6ee26d2ff38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8264, 8693, 9795, ..., 8114,  745, 5984])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "for ix in ids[:10]:\n",
        "  print(data['text'].values[ix])"
      ],
      "metadata": {
        "id": "w0zuI_BQUuKc",
        "outputId": "248dc10d-54be-44d9-844a-6f1422f3d84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arizona: breakfast burritos.\n",
            "Italian struffoli !\n",
            "\"mexican\" lasagna. mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
            "I might have a few for you. Probably nothing Mediterranean though. https://www.copymethat.com/r/hzvRQdG/after-school-antipasto-pinwheel-sandwich/ https://www.copymethat.com/r/bRnMfB2/american-italian-pasta-salad-ar-carol-em/ https://www.copymethat.com/r/T5TGZCE/greek-orzo-salad-ar-patrice/ https://www.copymethat.com/r/GmSceZb/ms-easy-tex-mex-vegan-salad/\n",
            "This is really good: http://cooking.nytimes.com/recipes/1017946-baked-cheesy-pasta-casserole-with-wild-mushrooms\n",
            "Here are some of my favorite (Not super common recipes) 1. Pasta alla Norcina. A delicious cheesy, sausage pasta dish. https://www.the-pasta-project.com/pasta-alla-norcina-sausage-pasta-recipe-from-umbria/ 2. Shrimp Fra Diavolo. A spicy shrimp pasta dish. https://www.allrecipes.com/recipe/238843/chef-johns-shrimp-fra-diavolo/ 3. Spicy Brussell Sprouts. So delicious, just had them. https://food52.com/blog/4857-momofuku-s-roasted-brussels-sprouts-with-fish-sauce-vinaigrette These aren't regional for me. But, they are things I have had that are \"different\" and I really enjoyed.\n",
            "I love my American grandma! Chicken pot pie, baked beans, and blueberry buckle every summer.\n",
            "Chicago Illinois- Italian Beef.\n",
            "Pizza party. get all the fixings out and let them make their own pizza. either use boboli bread crusts. like these https://www.walmart.com/search/?query=boboli%20pizza%20crust&amp;typeahead=Boboli you can take some ideas from this recipe or use the tortillas like in this recipe. https://www.copymethat.com/r/s2F2BUz/tortilla-pizza/ maybe make some garlicky parmesan breadsticks to go along with have some extra warmed marinara for dipping the bread into, maybe even make some cheese sticks &amp;#x200B; soup and salad? with corn bread, garlic toast, crackers etc. mixed green salad maybe make some homemade ranch dressing. or maybe Caesar Salad with garlic bread https://www.copymethat.com/r/Duw1hE0/buttermilk-ranch/ https://www.copymethat.com/r/FxEhNUP/creamy-caesar-dressing/ or grilled cheese sandwiches with this soup. You can make this days in advance and freeze it. Yes, you can freeze this soup! https://www.copymethat.com/r/1F4aIO6/dreamy-vegan-tomato-soup-blissful-basil/ https://www.copymethat.com/r/gAPe4ec/easy-cowboy-beef-soup/ https://www.copymethat.com/r/XE0Voqe/healthy-vegetable-beef-soup/ https://www.copymethat.com/r/cPq2HJk/homemade-crock-pot-chicken-tortilla-soup/\n",
            "Julia Child: The French Chef - Your Own French Onion Soup https://www.youtube.com/watch?v=dw0Ij1Fxgq4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serialization\n",
        "\n",
        "Gensim models can be (ans should be) saved to disk after training."
      ],
      "metadata": {
        "id": "4dNpccay4Dzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_model.save('bigram_model.m')"
      ],
      "metadata": {
        "id": "24HXP-SDQgP2",
        "outputId": "3982a8a6-6174-46fe-f1ac-8e46d3c2c49a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:45:18,220 : INFO : Phrases lifecycle event {'fname_or_handle': 'bigram_model.m', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-01T16:45:18.220589', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'saving'}\n",
            "2022-11-01 16:45:18,519 : INFO : saved bigram_model.m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('w2v_food.m')"
      ],
      "metadata": {
        "id": "h8aZ260jGoK1",
        "outputId": "a3fa4ead-fd1f-4c69-ba3f-65379c02bf1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:45:18,678 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'w2v_food.m', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-01T16:45:18.678195', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'saving'}\n",
            "2022-11-01 16:45:18,690 : INFO : not storing attribute cum_table\n",
            "2022-11-01 16:45:18,778 : INFO : saved w2v_food.m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = Word2Vec.load('/content/w2v_food.m')"
      ],
      "metadata": {
        "id": "7mVoMzqGHhIX",
        "outputId": "d25e7412-758b-433e-eca3-2d1302741346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-01 16:46:13,635 : INFO : loading Word2Vec object from /content/w2v_food.m\n",
            "2022-11-01 16:46:13,682 : INFO : loading wv recursively from /content/w2v_food.m.wv.* with mmap=None\n",
            "2022-11-01 16:46:13,684 : INFO : setting ignored attribute cum_table to None\n",
            "2022-11-01 16:46:13,795 : INFO : Word2Vec lifecycle event {'fname': '/content/w2v_food.m', 'datetime': '2022-11-01T16:46:13.795158', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'loaded'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.wv.most_similar('garlic')"
      ],
      "metadata": {
        "id": "oPJDNFiMHthR",
        "outputId": "dd4c8b0e-e0f5-4a2d-ba62-940547fc3120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unpeeled', 0.7983607649803162),\n",
              " ('celery', 0.7926087379455566),\n",
              " ('cloves', 0.7867130041122437),\n",
              " ('onions', 0.776432454586029),\n",
              " ('chopped', 0.7641382217407227),\n",
              " ('minced', 0.763360321521759),\n",
              " ('ginger', 0.7594746947288513),\n",
              " ('carrots', 0.7548808455467224),\n",
              " ('finely', 0.7508522868156433),\n",
              " ('olive_oil', 0.7437301874160767)]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-HK1uoqFgtf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}