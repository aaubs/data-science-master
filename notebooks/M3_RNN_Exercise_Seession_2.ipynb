{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUadA4Tl019R9vak9oYAHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_RNN_Exercise_Seession_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does PyTorch help to implement an RNN?\n",
        "\n",
        "Let's implement an RNN using PyTorch!"
      ],
      "metadata": {
        "id": "Ym_lp6rZyMvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN with one layer configured as One-to-one"
      ],
      "metadata": {
        "id": "sA0Jw6jw1GGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FHf9wC3T0R7Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with a one-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "uUI9NVqMygdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 1\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 1\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "d_3Uyse-0R7Z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "gerYVJoCzqAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "_ESkv2lszgmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating an RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.3)"
      ],
      "metadata": {
        "id": "2qQdk16m2hyW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zWfVNQfEU3o",
        "outputId": "a0a59f4d-54d1-4c48-a504-89a7bc5ed2ef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 48\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3839],\n",
            "        [ 0.3593],\n",
            "        [ 0.0060],\n",
            "        [-0.3075],\n",
            "        [ 0.0847],\n",
            "        [-0.0992]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.0342, -0.0923,  0.3164, -0.3213, -0.2362,  0.0448],\n",
            "        [ 0.0689, -0.0234,  0.2356, -0.3403, -0.3464, -0.3829],\n",
            "        [ 0.1400,  0.1225, -0.2029,  0.0593, -0.1170,  0.1283],\n",
            "        [-0.2313, -0.0068,  0.2608,  0.1818, -0.1242,  0.3929],\n",
            "        [ 0.0261,  0.2292, -0.1017,  0.1113,  0.1534,  0.0371],\n",
            "        [ 0.1806, -0.1233, -0.1585, -0.3001, -0.1916,  0.2137]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3144, -0.1719, -0.1845,  0.4061,  0.3334, -0.0543]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "seq_length = 1\n",
        "lr = 0.3"
      ],
      "metadata": {
        "id": "V2nwhZnTIqcR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "   \n",
        "   # Initialize the hidden state\n",
        "   h0 = torch.zeros(1, hidden_size)\n",
        "   for j in range(x.size(0)):\n",
        "      input = x[j:(j+1)]\n",
        "      target = y[j:(j+1)]\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input, h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993d9056-9924-4f59-b45d-fc8b2035db76",
        "id": "NmGOaqWb0R7a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 4.663549423217773\n",
            "Epoch: 10 loss 1.7029898166656494\n",
            "Epoch: 20 loss 1.7014976739883423\n",
            "Epoch: 30 loss 1.7004168033599854\n",
            "Epoch: 40 loss 1.6996159553527832\n",
            "Epoch: 50 loss 1.699011206626892\n",
            "Epoch: 60 loss 1.6985478401184082\n",
            "Epoch: 70 loss 1.6981881856918335\n",
            "Epoch: 80 loss 1.6979056596755981\n",
            "Epoch: 90 loss 1.6976819038391113\n",
            "Epoch: 100 loss 1.6975033283233643\n",
            "Epoch: 110 loss 1.6973594427108765\n",
            "Epoch: 120 loss 1.6972427368164062\n",
            "Epoch: 130 loss 1.697148084640503\n",
            "Epoch: 140 loss 1.6970702409744263\n",
            "Epoch: 150 loss 1.6970059871673584\n",
            "Epoch: 160 loss 1.6969528198242188\n",
            "Epoch: 170 loss 1.6969088315963745\n",
            "Epoch: 180 loss 1.6968718767166138\n",
            "Epoch: 190 loss 1.6968406438827515\n",
            "Epoch: 200 loss 1.6968140602111816\n",
            "Epoch: 210 loss 1.6967920064926147\n",
            "Epoch: 220 loss 1.696772813796997\n",
            "Epoch: 230 loss 1.6967568397521973\n",
            "Epoch: 240 loss 1.6967425346374512\n",
            "Epoch: 250 loss 1.6967302560806274\n",
            "Epoch: 260 loss 1.696719765663147\n",
            "Epoch: 270 loss 1.696710467338562\n",
            "Epoch: 280 loss 1.6967023611068726\n",
            "Epoch: 290 loss 1.69669508934021\n",
            "Epoch: 300 loss 1.6966890096664429\n",
            "Epoch: 310 loss 1.6966830492019653\n",
            "Epoch: 320 loss 1.6966781616210938\n",
            "Epoch: 330 loss 1.6966735124588013\n",
            "Epoch: 340 loss 1.6966696977615356\n",
            "Epoch: 350 loss 1.6966657638549805\n",
            "Epoch: 360 loss 1.696662187576294\n",
            "Epoch: 370 loss 1.6966590881347656\n",
            "Epoch: 380 loss 1.6966562271118164\n",
            "Epoch: 390 loss 1.6966536045074463\n",
            "Epoch: 400 loss 1.6966512203216553\n",
            "Epoch: 410 loss 1.6966487169265747\n",
            "Epoch: 420 loss 1.6966466903686523\n",
            "Epoch: 430 loss 1.6966450214385986\n",
            "Epoch: 440 loss 1.6966431140899658\n",
            "Epoch: 450 loss 1.696641206741333\n",
            "Epoch: 460 loss 1.696639895439148\n",
            "Epoch: 470 loss 1.6966384649276733\n",
            "Epoch: 480 loss 1.6966369152069092\n",
            "Epoch: 490 loss 1.6966357231140137\n",
            "Epoch: 500 loss 1.696634292602539\n",
            "Epoch: 510 loss 1.696633219718933\n",
            "Epoch: 520 loss 1.6966322660446167\n",
            "Epoch: 530 loss 1.6966313123703003\n",
            "Epoch: 540 loss 1.6966303586959839\n",
            "Epoch: 550 loss 1.6966291666030884\n",
            "Epoch: 560 loss 1.6966288089752197\n",
            "Epoch: 570 loss 1.6966276168823242\n",
            "Epoch: 580 loss 1.6966270208358765\n",
            "Epoch: 590 loss 1.6966261863708496\n",
            "Epoch: 600 loss 1.6966255903244019\n",
            "Epoch: 610 loss 1.696624755859375\n",
            "Epoch: 620 loss 1.6966243982315063\n",
            "Epoch: 630 loss 1.696623682975769\n",
            "Epoch: 640 loss 1.6966232061386108\n",
            "Epoch: 650 loss 1.696622610092163\n",
            "Epoch: 660 loss 1.6966220140457153\n",
            "Epoch: 670 loss 1.6966216564178467\n",
            "Epoch: 680 loss 1.6966214179992676\n",
            "Epoch: 690 loss 1.6966209411621094\n",
            "Epoch: 700 loss 1.6966203451156616\n",
            "Epoch: 710 loss 1.696620225906372\n",
            "Epoch: 720 loss 1.6966196298599243\n",
            "Epoch: 730 loss 1.6966192722320557\n",
            "Epoch: 740 loss 1.6966193914413452\n",
            "Epoch: 750 loss 1.6966190338134766\n",
            "Epoch: 760 loss 1.6966185569763184\n",
            "Epoch: 770 loss 1.6966184377670288\n",
            "Epoch: 780 loss 1.6966181993484497\n",
            "Epoch: 790 loss 1.6966180801391602\n",
            "Epoch: 800 loss 1.696617841720581\n",
            "Epoch: 810 loss 1.6966174840927124\n",
            "Epoch: 820 loss 1.6966173648834229\n",
            "Epoch: 830 loss 1.6966172456741333\n",
            "Epoch: 840 loss 1.6966170072555542\n",
            "Epoch: 850 loss 1.6966170072555542\n",
            "Epoch: 860 loss 1.696616768836975\n",
            "Epoch: 870 loss 1.6966164112091064\n",
            "Epoch: 880 loss 1.6966166496276855\n",
            "Epoch: 890 loss 1.696616291999817\n",
            "Epoch: 900 loss 1.696616291999817\n",
            "Epoch: 910 loss 1.696616291999817\n",
            "Epoch: 920 loss 1.6966159343719482\n",
            "Epoch: 930 loss 1.6966158151626587\n",
            "Epoch: 940 loss 1.6966159343719482\n",
            "Epoch: 950 loss 1.6966156959533691\n",
            "Epoch: 960 loss 1.6966156959533691\n",
            "Epoch: 970 loss 1.6966156959533691\n",
            "Epoch: 980 loss 1.6966155767440796\n",
            "Epoch: 990 loss 1.6966153383255005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0)):\n",
        "   input = x[i:i+1]\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input, h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "knhdQPnB3-4S"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_time_steps = np.linspace(2, 10, x.shape[0])\n",
        "\n",
        "pl.scatter(data_time_steps[:], y.data.numpy(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[:], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "618a45f6-feec-45c3-818d-1b1fe8e7165a",
        "id": "Lt0EG_uf0R7a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWM1b9iKMkKe",
        "outputId": "8db03ab3-47f0-4d74-983a-27cee564fb11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 48\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.8065],\n",
            "        [ 0.1771],\n",
            "        [-0.8170],\n",
            "        [ 0.8130],\n",
            "        [ 0.8252],\n",
            "        [-0.8257]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-3.2082e-01,  2.5052e-01, -1.2359e-01,  1.7802e-01,  8.7040e-02,\n",
            "         -1.6337e-01],\n",
            "        [-2.3736e-01,  3.7018e-01,  3.4390e-01, -3.2391e-02,  3.6817e-01,\n",
            "         -3.4018e-01],\n",
            "        [-2.9130e-01, -1.4683e-01,  6.7102e-02, -1.1024e-02, -8.6213e-02,\n",
            "          1.6474e-04],\n",
            "        [ 2.3286e-01,  2.3885e-01, -3.5169e-01, -3.4843e-01,  1.0673e-01,\n",
            "         -2.1323e-01],\n",
            "        [ 2.9536e-01,  2.4716e-01, -2.3826e-01, -2.2648e-02,  1.1460e-01,\n",
            "         -3.9898e-01],\n",
            "        [ 2.8494e-01, -3.8583e-01,  6.8416e-02, -2.5032e-01,  2.9895e-01,\n",
            "         -1.7028e-01]], requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1924,  0.0106, -0.2410,  0.2252,  0.2757, -0.2778]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN with one layer configured as Many-to-one"
      ],
      "metadata": {
        "id": "nSM0mLVo1CKt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "LoLoL_Ch4lGy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with a Many-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "I6nhIROx4lG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 2\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 1\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "tWuwKnF34lG0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "sEh2BwiU4lG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "seVVpB6V4lG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating an RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.3)"
      ],
      "metadata": {
        "id": "dcknom2b4lG1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb5927e-1b9d-4c1a-84b6-6aaa08c2fc1b",
        "id": "dMl6mfqJ4lG1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 54\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 2])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1972, -0.2539],\n",
            "        [-0.1686,  0.3213],\n",
            "        [ 0.3860,  0.1619],\n",
            "        [ 0.2199, -0.3887],\n",
            "        [ 0.2631, -0.3738],\n",
            "        [-0.3716,  0.1908]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.2076,  0.1659,  0.1476,  0.1567, -0.2824,  0.2494],\n",
            "        [-0.2183, -0.1542,  0.1734,  0.0442,  0.0307, -0.0092],\n",
            "        [-0.2469, -0.3998, -0.3396,  0.3520,  0.1074,  0.0057],\n",
            "        [-0.2816,  0.3824, -0.0446, -0.1048,  0.2515,  0.1607],\n",
            "        [-0.1352, -0.2461,  0.0843,  0.1480, -0.2529, -0.3741],\n",
            "        [-0.3007, -0.3699,  0.1233,  0.0510, -0.1828, -0.2400]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0460,  0.0649,  0.2891, -0.0740,  0.0914, -0.1281]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "seq_length = 1\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "9xt5Mhxw4lG1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "\n",
        "   # Initialize the hidden state\n",
        "   h0 = torch.zeros(1,  hidden_size)\n",
        "   \n",
        "   for j in range(x.size(0) - 1):\n",
        "      input = x[j:(j+2)]\n",
        "      target = y[j:(j+2)]\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input.t(), h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd4d1d5-5861-449f-b133-340c5376d3dc",
        "id": "hpPy5_y94lG1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 4.4336838722229\n",
            "Epoch: 10 loss 1.7661694288253784\n",
            "Epoch: 20 loss 1.3932373523712158\n",
            "Epoch: 30 loss 1.1979223489761353\n",
            "Epoch: 40 loss 1.0892937183380127\n",
            "Epoch: 50 loss 1.0232353210449219\n",
            "Epoch: 60 loss 0.9800454378128052\n",
            "Epoch: 70 loss 0.9501742124557495\n",
            "Epoch: 80 loss 0.9285774230957031\n",
            "Epoch: 90 loss 0.9123901724815369\n",
            "Epoch: 100 loss 0.899886965751648\n",
            "Epoch: 110 loss 0.8899769186973572\n",
            "Epoch: 120 loss 0.8819431662559509\n",
            "Epoch: 130 loss 0.8752987384796143\n",
            "Epoch: 140 loss 0.8697041869163513\n",
            "Epoch: 150 loss 0.864916980266571\n",
            "Epoch: 160 loss 0.8607602119445801\n",
            "Epoch: 170 loss 0.8571029901504517\n",
            "Epoch: 180 loss 0.853847324848175\n",
            "Epoch: 190 loss 0.8509175777435303\n",
            "Epoch: 200 loss 0.8482558727264404\n",
            "Epoch: 210 loss 0.8458172082901001\n",
            "Epoch: 220 loss 0.8435659408569336\n",
            "Epoch: 230 loss 0.841473400592804\n",
            "Epoch: 240 loss 0.8395176529884338\n",
            "Epoch: 250 loss 0.8376795053482056\n",
            "Epoch: 260 loss 0.8359445929527283\n",
            "Epoch: 270 loss 0.8343004584312439\n",
            "Epoch: 280 loss 0.8327372670173645\n",
            "Epoch: 290 loss 0.8312463760375977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0) - 1):\n",
        "   input = x[i:i+2]\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input.t(), h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "cw6YVtGb4lG2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_time_steps = np.linspace(2, 10, x.shape[0])\n",
        "\n",
        "pl.scatter(data_time_steps[:-1], y.data[:-1].numpy(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[:-1], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8f95dc6b-ec22-4c49-de2c-e7bc3396e786",
        "id": "w_NszNfw4lG2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c9e8b7-7a30-4cdf-c1c0-dd467ddb0649",
        "id": "2XV0zGJl4lG2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 54\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 2])\n",
            "Parameter containing:\n",
            "tensor([[-1.0623,  1.6469],\n",
            "        [-0.2183,  0.4557],\n",
            "        [ 0.0235, -0.9632],\n",
            "        [-0.2005,  1.0576],\n",
            "        [-0.5270, -0.6371],\n",
            "        [ 0.4598, -1.2108]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3402,  0.1997, -0.2267, -0.1469, -0.0959, -0.0933],\n",
            "        [-0.0663,  0.3926,  0.0180, -0.0361,  0.3734, -0.2884],\n",
            "        [ 0.2821,  0.0024,  0.4007,  0.3000,  0.2085, -0.3537],\n",
            "        [-0.0050,  0.3329, -0.3460, -0.0841,  0.1212, -0.2376],\n",
            "        [-0.0543, -0.1468,  0.0025, -0.4041, -0.3034, -0.0545],\n",
            "        [ 0.2107,  0.1552,  0.1369,  0.1960, -0.3657, -0.2092]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3965,  0.0039, -0.3568,  0.2759, -0.0582, -0.2657]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN with two layers configured as One-to-one"
      ],
      "metadata": {
        "id": "C76RCcIt7is9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with 2 layers and a One-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "F8UiN-s074BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use non-linear data with more complexity in this step!"
      ],
      "metadata": {
        "id": "PVCL5Ex99IBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 1\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 2\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "HmEvnoDX74BJ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "3HWQFctV74BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "oMPNEvsa74BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating a RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False, nonlinearity='tanh', num_layers=2)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "m4TOKiExobEv"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ac912f-5ee9-40a4-f09c-252204b96395",
        "id": "nM7eanghobEv"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 120\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1916],\n",
            "        [ 0.2838],\n",
            "        [ 0.4044],\n",
            "        [-0.0497],\n",
            "        [ 0.3326],\n",
            "        [-0.1160]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1140, -0.1597, -0.1740, -0.1036,  0.3144, -0.1587],\n",
            "        [ 0.0776, -0.3044, -0.3879, -0.2759,  0.1232, -0.0356],\n",
            "        [-0.0471,  0.3522,  0.1215, -0.0336, -0.0521,  0.3693],\n",
            "        [ 0.0164,  0.2419,  0.0861,  0.2870,  0.3733, -0.0289],\n",
            "        [ 0.2916, -0.3038, -0.2628, -0.0831, -0.1746,  0.1464],\n",
            "        [-0.0097, -0.3501,  0.2285,  0.0379, -0.0763, -0.0184]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_ih_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.0049,  0.1914,  0.2775, -0.3013,  0.2069, -0.1548],\n",
            "        [-0.0451,  0.2137, -0.3049, -0.3861, -0.0614,  0.3395],\n",
            "        [-0.1410, -0.3598,  0.3195,  0.3657,  0.3815,  0.0606],\n",
            "        [ 0.3494,  0.0859,  0.0376, -0.0108, -0.3805,  0.0630],\n",
            "        [-0.4062,  0.3152,  0.0602,  0.0349,  0.3987,  0.3082],\n",
            "        [ 0.1146, -0.0964, -0.2920, -0.3724, -0.3279, -0.3860]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_hh_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3061, -0.0725,  0.3684, -0.0746, -0.3535,  0.3951],\n",
            "        [ 0.2344, -0.1249, -0.0620,  0.1978, -0.0349,  0.2001],\n",
            "        [-0.3149,  0.2621,  0.1013,  0.1565, -0.3771,  0.0187],\n",
            "        [-0.4067, -0.3177, -0.3469,  0.3927, -0.2126,  0.3454],\n",
            "        [-0.0482, -0.1322,  0.1864, -0.3621,  0.2722, -0.3602],\n",
            "        [-0.1749, -0.1994,  0.3799,  0.3254,  0.2142, -0.2979]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3990,  0.3492,  0.4053,  0.0462, -0.0999, -0.0654]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "fKSW4152obEw"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "\n",
        "   # Initialize the hidden state\n",
        "   h0 = torch.zeros(2, hidden_size)\n",
        "   for j in range(x.size(0)):\n",
        "      input = x[j:(j+1)]\n",
        "      target = y[j:(j+1)]\n",
        "\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input, h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2055953c-0be0-4705-f683-d155e42f9e2d",
        "id": "705R15JoobEw"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 8.374932289123535\n",
            "Epoch: 10 loss 5.686782360076904\n",
            "Epoch: 20 loss 3.5747897624969482\n",
            "Epoch: 30 loss 2.451029062271118\n",
            "Epoch: 40 loss 2.011479377746582\n",
            "Epoch: 50 loss 1.847974181175232\n",
            "Epoch: 60 loss 1.782486915588379\n",
            "Epoch: 70 loss 1.7531312704086304\n",
            "Epoch: 80 loss 1.7382397651672363\n",
            "Epoch: 90 loss 1.7297329902648926\n",
            "Epoch: 100 loss 1.7243576049804688\n",
            "Epoch: 110 loss 1.7206858396530151\n",
            "Epoch: 120 loss 1.7180272340774536\n",
            "Epoch: 130 loss 1.7160139083862305\n",
            "Epoch: 140 loss 1.7144321203231812\n",
            "Epoch: 150 loss 1.7131481170654297\n",
            "Epoch: 160 loss 1.712074637413025\n",
            "Epoch: 170 loss 1.7111529111862183\n",
            "Epoch: 180 loss 1.7103424072265625\n",
            "Epoch: 190 loss 1.709614634513855\n",
            "Epoch: 200 loss 1.7089499235153198\n",
            "Epoch: 210 loss 1.7083337306976318\n",
            "Epoch: 220 loss 1.7077562808990479\n",
            "Epoch: 230 loss 1.7072105407714844\n",
            "Epoch: 240 loss 1.7066905498504639\n",
            "Epoch: 250 loss 1.706193208694458\n",
            "Epoch: 260 loss 1.7057151794433594\n",
            "Epoch: 270 loss 1.705254316329956\n",
            "Epoch: 280 loss 1.7048085927963257\n",
            "Epoch: 290 loss 1.7043774127960205\n",
            "Epoch: 300 loss 1.7039592266082764\n",
            "Epoch: 310 loss 1.7035539150238037\n",
            "Epoch: 320 loss 1.7031595706939697\n",
            "Epoch: 330 loss 1.7027767896652222\n",
            "Epoch: 340 loss 1.7024040222167969\n",
            "Epoch: 350 loss 1.702041506767273\n",
            "Epoch: 360 loss 1.7016887664794922\n",
            "Epoch: 370 loss 1.7013452053070068\n",
            "Epoch: 380 loss 1.7010107040405273\n",
            "Epoch: 390 loss 1.700684666633606\n",
            "Epoch: 400 loss 1.7003668546676636\n",
            "Epoch: 410 loss 1.7000572681427002\n",
            "Epoch: 420 loss 1.699755311012268\n",
            "Epoch: 430 loss 1.699460506439209\n",
            "Epoch: 440 loss 1.699173092842102\n",
            "Epoch: 450 loss 1.698892593383789\n",
            "Epoch: 460 loss 1.6986186504364014\n",
            "Epoch: 470 loss 1.6983513832092285\n",
            "Epoch: 480 loss 1.6980901956558228\n",
            "Epoch: 490 loss 1.6978346109390259\n",
            "Epoch: 500 loss 1.6975857019424438\n",
            "Epoch: 510 loss 1.6973415613174438\n",
            "Epoch: 520 loss 1.6971036195755005\n",
            "Epoch: 530 loss 1.6968704462051392\n",
            "Epoch: 540 loss 1.6966423988342285\n",
            "Epoch: 550 loss 1.6964191198349\n",
            "Epoch: 560 loss 1.696200966835022\n",
            "Epoch: 570 loss 1.6959872245788574\n",
            "Epoch: 580 loss 1.6957778930664062\n",
            "Epoch: 590 loss 1.6955727338790894\n",
            "Epoch: 600 loss 1.6953721046447754\n",
            "Epoch: 610 loss 1.6951751708984375\n",
            "Epoch: 620 loss 1.6949825286865234\n",
            "Epoch: 630 loss 1.6947931051254272\n",
            "Epoch: 640 loss 1.6946077346801758\n",
            "Epoch: 650 loss 1.6944254636764526\n",
            "Epoch: 660 loss 1.6942468881607056\n",
            "Epoch: 670 loss 1.6940715312957764\n",
            "Epoch: 680 loss 1.6938996315002441\n",
            "Epoch: 690 loss 1.693730354309082\n",
            "Epoch: 700 loss 1.6935641765594482\n",
            "Epoch: 710 loss 1.6934008598327637\n",
            "Epoch: 720 loss 1.6932402849197388\n",
            "Epoch: 730 loss 1.693082571029663\n",
            "Epoch: 740 loss 1.6929277181625366\n",
            "Epoch: 750 loss 1.692775011062622\n",
            "Epoch: 760 loss 1.6926250457763672\n",
            "Epoch: 770 loss 1.6924774646759033\n",
            "Epoch: 780 loss 1.6923319101333618\n",
            "Epoch: 790 loss 1.6921886205673218\n",
            "Epoch: 800 loss 1.6920478343963623\n",
            "Epoch: 810 loss 1.691908836364746\n",
            "Epoch: 820 loss 1.6917719841003418\n",
            "Epoch: 830 loss 1.6916372776031494\n",
            "Epoch: 840 loss 1.6915041208267212\n",
            "Epoch: 850 loss 1.6913729906082153\n",
            "Epoch: 860 loss 1.6912437677383423\n",
            "Epoch: 870 loss 1.691116213798523\n",
            "Epoch: 880 loss 1.6909905672073364\n",
            "Epoch: 890 loss 1.6908661127090454\n",
            "Epoch: 900 loss 1.6907434463500977\n",
            "Epoch: 910 loss 1.6906225681304932\n",
            "Epoch: 920 loss 1.6905028820037842\n",
            "Epoch: 930 loss 1.690384864807129\n",
            "Epoch: 940 loss 1.6902681589126587\n",
            "Epoch: 950 loss 1.6901527643203735\n",
            "Epoch: 960 loss 1.6900389194488525\n",
            "Epoch: 970 loss 1.689926028251648\n",
            "Epoch: 980 loss 1.689814805984497\n",
            "Epoch: 990 loss 1.6897046566009521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0)):\n",
        "   input = x[i:i+1]\n",
        "\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input, h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "YBtvHBlXobEw"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.scatter(data_time_steps[:-1], y.data[:].numpy().tolist(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[1:], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "eddaad8d-b8b1-4156-8652-e8c75e86043c",
        "id": "-2BEAEhlobEx"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecf7110-93b6-4153-82e0-b291fc9072b5",
        "id": "ihzVc7T2obEx"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 120\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.8414],\n",
            "        [ 0.9114],\n",
            "        [ 0.9045],\n",
            "        [ 0.4599],\n",
            "        [ 0.2188],\n",
            "        [ 0.1276]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1140, -0.1597, -0.1740, -0.1036,  0.3144, -0.1587],\n",
            "        [ 0.0776, -0.3044, -0.3879, -0.2759,  0.1232, -0.0356],\n",
            "        [-0.0471,  0.3522,  0.1215, -0.0336, -0.0521,  0.3693],\n",
            "        [ 0.0164,  0.2419,  0.0861,  0.2870,  0.3733, -0.0289],\n",
            "        [ 0.2916, -0.3038, -0.2628, -0.0831, -0.1746,  0.1464],\n",
            "        [-0.0097, -0.3501,  0.2285,  0.0379, -0.0763, -0.0184]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_ih_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1744, -0.2518, -0.2931, -0.5115, -0.1677, -0.2222],\n",
            "        [-0.2144,  0.6169,  0.2105, -0.1945,  0.2724,  0.4004],\n",
            "        [-0.1648, -0.1263,  0.6475,  0.4655,  0.6405,  0.0818],\n",
            "        [ 0.2835,  0.1885,  0.1579,  0.0426, -0.3151,  0.0815],\n",
            "        [-0.3008,  0.1396, -0.1487, -0.0558,  0.2798,  0.2776],\n",
            "        [ 0.1344, -0.1535, -0.3663, -0.3994, -0.3796, -0.3939]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_hh_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3061, -0.0725,  0.3684, -0.0746, -0.3535,  0.3951],\n",
            "        [ 0.2344, -0.1249, -0.0620,  0.1978, -0.0349,  0.2001],\n",
            "        [-0.3149,  0.2621,  0.1013,  0.1565, -0.3771,  0.0187],\n",
            "        [-0.4067, -0.3177, -0.3469,  0.3927, -0.2126,  0.3454],\n",
            "        [-0.0482, -0.1322,  0.1864, -0.3621,  0.2722, -0.3602],\n",
            "        [-0.1749, -0.1994,  0.3799,  0.3254,  0.2142, -0.2979]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3990,  0.3492,  0.4053,  0.0462, -0.0999, -0.0654]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unVdvOLh37se"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}