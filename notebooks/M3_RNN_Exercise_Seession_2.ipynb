{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+BjzZOEijeVjsplPocIBd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_RNN_Exercise_Seession_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does PyTorch help to implement an RNN?\n",
        "\n",
        "Let's implement an RNN using PyTorch!"
      ],
      "metadata": {
        "id": "Ym_lp6rZyMvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN with one layer configured as One-to-one"
      ],
      "metadata": {
        "id": "sA0Jw6jw1GGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FHf9wC3T0R7Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with a one-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "uUI9NVqMygdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 1\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 1\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "d_3Uyse-0R7Z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "gerYVJoCzqAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "_ESkv2lszgmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating an RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.3)"
      ],
      "metadata": {
        "id": "2qQdk16m2hyW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zWfVNQfEU3o",
        "outputId": "a0a59f4d-54d1-4c48-a504-89a7bc5ed2ef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 48\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3839],\n",
            "        [ 0.3593],\n",
            "        [ 0.0060],\n",
            "        [-0.3075],\n",
            "        [ 0.0847],\n",
            "        [-0.0992]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.0342, -0.0923,  0.3164, -0.3213, -0.2362,  0.0448],\n",
            "        [ 0.0689, -0.0234,  0.2356, -0.3403, -0.3464, -0.3829],\n",
            "        [ 0.1400,  0.1225, -0.2029,  0.0593, -0.1170,  0.1283],\n",
            "        [-0.2313, -0.0068,  0.2608,  0.1818, -0.1242,  0.3929],\n",
            "        [ 0.0261,  0.2292, -0.1017,  0.1113,  0.1534,  0.0371],\n",
            "        [ 0.1806, -0.1233, -0.1585, -0.3001, -0.1916,  0.2137]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3144, -0.1719, -0.1845,  0.4061,  0.3334, -0.0543]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "seq_length = 1\n",
        "lr = 0.3"
      ],
      "metadata": {
        "id": "V2nwhZnTIqcR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "   \n",
        "   # Initialize the hidden state\n",
        "   h0 = torch.zeros(1, hidden_size)\n",
        "   for j in range(x.size(0)):\n",
        "      input = x[j:(j+1)]\n",
        "      target = y[j:(j+1)]\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input, h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993d9056-9924-4f59-b45d-fc8b2035db76",
        "id": "NmGOaqWb0R7a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 4.663549423217773\n",
            "Epoch: 10 loss 1.7029898166656494\n",
            "Epoch: 20 loss 1.7014976739883423\n",
            "Epoch: 30 loss 1.7004168033599854\n",
            "Epoch: 40 loss 1.6996159553527832\n",
            "Epoch: 50 loss 1.699011206626892\n",
            "Epoch: 60 loss 1.6985478401184082\n",
            "Epoch: 70 loss 1.6981881856918335\n",
            "Epoch: 80 loss 1.6979056596755981\n",
            "Epoch: 90 loss 1.6976819038391113\n",
            "Epoch: 100 loss 1.6975033283233643\n",
            "Epoch: 110 loss 1.6973594427108765\n",
            "Epoch: 120 loss 1.6972427368164062\n",
            "Epoch: 130 loss 1.697148084640503\n",
            "Epoch: 140 loss 1.6970702409744263\n",
            "Epoch: 150 loss 1.6970059871673584\n",
            "Epoch: 160 loss 1.6969528198242188\n",
            "Epoch: 170 loss 1.6969088315963745\n",
            "Epoch: 180 loss 1.6968718767166138\n",
            "Epoch: 190 loss 1.6968406438827515\n",
            "Epoch: 200 loss 1.6968140602111816\n",
            "Epoch: 210 loss 1.6967920064926147\n",
            "Epoch: 220 loss 1.696772813796997\n",
            "Epoch: 230 loss 1.6967568397521973\n",
            "Epoch: 240 loss 1.6967425346374512\n",
            "Epoch: 250 loss 1.6967302560806274\n",
            "Epoch: 260 loss 1.696719765663147\n",
            "Epoch: 270 loss 1.696710467338562\n",
            "Epoch: 280 loss 1.6967023611068726\n",
            "Epoch: 290 loss 1.69669508934021\n",
            "Epoch: 300 loss 1.6966890096664429\n",
            "Epoch: 310 loss 1.6966830492019653\n",
            "Epoch: 320 loss 1.6966781616210938\n",
            "Epoch: 330 loss 1.6966735124588013\n",
            "Epoch: 340 loss 1.6966696977615356\n",
            "Epoch: 350 loss 1.6966657638549805\n",
            "Epoch: 360 loss 1.696662187576294\n",
            "Epoch: 370 loss 1.6966590881347656\n",
            "Epoch: 380 loss 1.6966562271118164\n",
            "Epoch: 390 loss 1.6966536045074463\n",
            "Epoch: 400 loss 1.6966512203216553\n",
            "Epoch: 410 loss 1.6966487169265747\n",
            "Epoch: 420 loss 1.6966466903686523\n",
            "Epoch: 430 loss 1.6966450214385986\n",
            "Epoch: 440 loss 1.6966431140899658\n",
            "Epoch: 450 loss 1.696641206741333\n",
            "Epoch: 460 loss 1.696639895439148\n",
            "Epoch: 470 loss 1.6966384649276733\n",
            "Epoch: 480 loss 1.6966369152069092\n",
            "Epoch: 490 loss 1.6966357231140137\n",
            "Epoch: 500 loss 1.696634292602539\n",
            "Epoch: 510 loss 1.696633219718933\n",
            "Epoch: 520 loss 1.6966322660446167\n",
            "Epoch: 530 loss 1.6966313123703003\n",
            "Epoch: 540 loss 1.6966303586959839\n",
            "Epoch: 550 loss 1.6966291666030884\n",
            "Epoch: 560 loss 1.6966288089752197\n",
            "Epoch: 570 loss 1.6966276168823242\n",
            "Epoch: 580 loss 1.6966270208358765\n",
            "Epoch: 590 loss 1.6966261863708496\n",
            "Epoch: 600 loss 1.6966255903244019\n",
            "Epoch: 610 loss 1.696624755859375\n",
            "Epoch: 620 loss 1.6966243982315063\n",
            "Epoch: 630 loss 1.696623682975769\n",
            "Epoch: 640 loss 1.6966232061386108\n",
            "Epoch: 650 loss 1.696622610092163\n",
            "Epoch: 660 loss 1.6966220140457153\n",
            "Epoch: 670 loss 1.6966216564178467\n",
            "Epoch: 680 loss 1.6966214179992676\n",
            "Epoch: 690 loss 1.6966209411621094\n",
            "Epoch: 700 loss 1.6966203451156616\n",
            "Epoch: 710 loss 1.696620225906372\n",
            "Epoch: 720 loss 1.6966196298599243\n",
            "Epoch: 730 loss 1.6966192722320557\n",
            "Epoch: 740 loss 1.6966193914413452\n",
            "Epoch: 750 loss 1.6966190338134766\n",
            "Epoch: 760 loss 1.6966185569763184\n",
            "Epoch: 770 loss 1.6966184377670288\n",
            "Epoch: 780 loss 1.6966181993484497\n",
            "Epoch: 790 loss 1.6966180801391602\n",
            "Epoch: 800 loss 1.696617841720581\n",
            "Epoch: 810 loss 1.6966174840927124\n",
            "Epoch: 820 loss 1.6966173648834229\n",
            "Epoch: 830 loss 1.6966172456741333\n",
            "Epoch: 840 loss 1.6966170072555542\n",
            "Epoch: 850 loss 1.6966170072555542\n",
            "Epoch: 860 loss 1.696616768836975\n",
            "Epoch: 870 loss 1.6966164112091064\n",
            "Epoch: 880 loss 1.6966166496276855\n",
            "Epoch: 890 loss 1.696616291999817\n",
            "Epoch: 900 loss 1.696616291999817\n",
            "Epoch: 910 loss 1.696616291999817\n",
            "Epoch: 920 loss 1.6966159343719482\n",
            "Epoch: 930 loss 1.6966158151626587\n",
            "Epoch: 940 loss 1.6966159343719482\n",
            "Epoch: 950 loss 1.6966156959533691\n",
            "Epoch: 960 loss 1.6966156959533691\n",
            "Epoch: 970 loss 1.6966156959533691\n",
            "Epoch: 980 loss 1.6966155767440796\n",
            "Epoch: 990 loss 1.6966153383255005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0)):\n",
        "   input = x[i:i+1]\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input, h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "knhdQPnB3-4S"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_time_steps = np.linspace(2, 10, x.shape[0])\n",
        "\n",
        "pl.scatter(data_time_steps[:], y.data.numpy(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[:], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "618a45f6-feec-45c3-818d-1b1fe8e7165a",
        "id": "Lt0EG_uf0R7a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZSU1ZXv8e+mAVFwkLcwStOBMcTYMoDagImALyCSSQSNUbEziU4EkrtC4sTrJOZmFhInmUWcSYwYbxQxI95IK8NoJAlofAEZh4HQGAMIITCI2oRA0xAUUN563z/qaahuuqureJ56fX6ftXpV1alTVQcW9K7nnLP3MXdHRETiq0O+ByAiIvmlQCAiEnMKBCIiMadAICIScwoEIiIx1zHfAzgVvXv39gEDBuR7GCIiRWXNmjW73b1Py/aiDAQDBgygtrY238MQESkqZvZWa+2aGhIRiTkFAhGRmFMgEBGJuaJcIxCR4tHY6LyyuZ75q95m57sf0PcvulA9soLLBvWhQwfL9/CEiAKBmf0U+DSwy90Ht/K8AfcDfwMcBG5199eC524B/jHo+l13nxfFmEQk/3bvP0T1IyvZvvd9Dhw+FrTuY8WW3fTrcTo1Uy+hV7fT8jpGiW5q6DFgQornPwkMCn6mAT8BMLOewN3ASGAEcLeZ9YhoTCISgcZGZ+mmXUx9vJaJP36VqY/XsnTTLhobUxesbGx0qh9Zydb6A0lBIOHA4WNsrT9A9SOr2n0fyb5IrgjcfbmZDUjRZRLwuCdKna40s7PM7GzgcuAFd98DYGYvkAgoNVGMS0TCCfON/pXN9Wzf+z5H2/hFf7TRqdt7kOWb67n8vA9l6U8g6cjVYnE/4J2kx3VBW1vtJzGzaWZWa2a19fX1WRuoiCSE/UY/f+XbJ72upQOHj/HEqrcjG7OcmqLZNeTuc9y9yt2r+vQ5KTFORCKWyTf61ux874O0Pmfnu+n1k+zJVSDYDvRPelwetLXVLiJ5FvYbfd+/6JLW56TbT7InV4FgEfAFS7gE2OfuO4DngfFm1iNYJB4ftIlInoX9Rl89soKunctSvrZr5zI+N7Ii47FJtKLaPlpDYuG3t5nVkdgJ1AnA3R8CFpPYOrqFxPbRvwue22Nm/wSsDt7qnqaFYxHJr8Q39X1p9jvZZYP60K/H6WytP9Dq9FLHDkZ5jzMYM0hTvfkW1a6hm9t53oGvtPHcT4GfRjEOEYlO9cgKVmzZnXJ6KNU3+g4djJqpl1D9yCrq9h5s9j5dO5dR3uMM5k8dqaSyAqDMYhFpVRTf6Ht1O40lt49m+eZ6nkjKLP7cyArGKLO4YFjiy3pxqaqqcpWhFsm+hv2H2v1Gr8zg4mFma9y9qmW7rghEpE36Rh8PCgQiklKHDsbl531I2b8lTIFARAqaqpdmnwKBiBQsVS/NjaIpMSEi8aLqpbmjQCAiBSlsrSNJnwKBiBQkVS/NHQUCESlIybWOJnZ4lVc7f42tp1XzauevMbHDqyf6qXppaFosFilxBbHrZu0CeOke2FcH3cth7AwYcmPKlzTVOprY4VVmdZrLGXYYgHLbzaxOc+EILGocpeqlEVAgEClhBbHrZu0C+MXX4Mj7wce/k3gMKYNBU62jb7DgeBBocoYd5hsdF/ASl6l6aQQ0NSRSogpm181L95wIAk2OvJ9oT6Gp1tE5trvV58+xBlUvjYgCgUiJKphdN/vqMmsPNFUvre/Q+i/6+g69Vb00IvEJBGsXwH2DYeZZidu1C/I9IpGsKphdN93LM2tP0qvbafS59p85VtZ8HeBYWRf6XPvPSiaLSDwCQdMc5b53AD8xR6lgICWsYM4MHjsDOp3evK3T6Yn2NHQYeiNlkx6A7v0Bg+79KZv0AB2Gpl5slvRFdULZBOB+oAyY6+6zWjx/H3BF8PAM4EPuflbw3DFgXfDc2+4+MYoxNZNqjrKdnQsixSrsCWORafo/luGuoZPeQ/9XsyZ0IDCzMuBB4CqgDlhtZovcfUNTH3f/elL/rwIXJr3F++4+LOw4UjrFOUqRYhb2hLFI6Rd5QYtiamgEsMXdt7r7YeBJYFKK/jcDNRF8bvpCzFGKFKumXTcd21hMjdWZwVojTCmKQNAPeCfpcV3QdhIz+zAwEHg5qbmLmdWa2Uozu7atDzGzaUG/2vr6DHc5hJyjFClGTbtuzu3Tja6dy5o917VzGef26RaPXTdaI2xXrhPKJgML3T35WvXD7r7dzP4KeNnM1rn7/7R8obvPAeZA4qjKjD41ijlKkSKkE8bQGmEaoggE24H+SY/Lg7bWTAa+ktzg7tuD261mtozE+sFJgSCMxkbnldMuZ36vv2JnpyDF/rQKLmv0ePxHkFiL/QljWiNsVxSBYDUwyMwGkggAk4Hqlp3M7GNAD+C/k9p6AAfd/ZCZ9QYuBe6NYEzHFUSKvUixO4VaQQWje3kwLdRKuwARrBG4+1FgOvA8sBFY4O5vmNk9Zpa8FXQy8KS7J0/rnA/UmtnvgKXArOTdRmEVTIq9SDEr9jl2rRG2K5I1AndfDCxu0TajxeOZrbxuBfDXUYyhNZmk2Mf2slmkPcU+x641wnaVdPXRTFLsFQhE2lAKc+zKY0ippEtMFEyKvUgxUx5OySvpQJBu6rwOthBJQXPsJa+kA0H1yIqTEmlaylmKvUixGnIjXDO7WdE3rpmtqZYSUtJrBE0p9lvrD7S6YByrFHuRMDTHXtJK+opAKfYiIu0r6SsCiDDFvpgTakRirLHReWVzPfOT/v9Xj6zgsriU2EhDyQcCiCDF/hQP3xaR/FJlgfSU9NRQZE7x8G0RyR9VFkifAkE6SiGhRiRmMqksEHcKBOlQQo1I0cmkskDcKRCkQwk1IkVHlQXSp0CQDiXUiBQdVRZIXyx2DUVCCTUiRaV6ZAUrtuxOOT2UdmWBEt8+risCESlJTZUFOraRK5B2ZYFiP48hDQoEIgWusdFZumkXUx+vZeKPX2Xq47Us3bRL2x7bEVllgRhsH49kasjMJgD3A2XAXHef1eL5W4F/4cRZxj9297nBc7cA/xi0f9fd50UxJpFSoISocCKpLBCD7eOhA4GZlQEPAlcBdcBqM1vUypGTT7n79Bav7QncDVQBDqwJXrs37LhEil1yQlTLvfDJCVFLbh+tUgkphK4sEIMzj6OYGhoBbHH3re5+GHgSmJTma68GXnD3PcEv/xeACRGMSaToKSGqQMRg+3gUgaAfkBwu64K2lq43s7VmttDM+mf4WsxsmpnVmlltfb3+4UvpU0JUgYjB9vFcbR/9BVDj7ofM7EvAPODKTN7A3ecAcwCqqqq0SiYlTwlRBaTEt49HcUWwHeif9LicE4vCALh7g7sfCh7OBS5O97UicRVpQtTaBXDfYJh5VuK2hLY+SnhRBILVwCAzG2hmnYHJwKLkDmZ2dtLDicDG4P7zwHgz62FmPYDxQZtI7EV21GoM9sFLOKEDgbsfBaaT+AW+EVjg7m+Y2T1mNjHo9jUze8PMfgd8Dbg1eO0e4J9IBJPVwD1Bm0jsRZYQFYN98BKOuRffdHtVVZXX1tbmexgiWdew/xDVj6yibu/BZgvHXTuXUd7jDOZPHdl+HsHMs0jszm7JYOafIx2vFDYzW+PuVS3bVWtIpIBFkhAVg33wEo4CgUiBC50QNXZG86NWoeT2wUs4qjUkUupisA9ewtEVgUgclPg+eAlHVwQiIjGnK4I0NDY6r2yuZ37SYl31yAouS3exTkSkgCkQtENlgEWk1GlqKIXkMsAti38llwHWASEiUswUCFJQGWARiQMFghRUBlhE4kCBIIVIywCr+qOIFCgtFqeQKO+7L81+KTRVf2zK7Gyq/gja2y0ieacrghQiKwOs6o8iUsAUCFKIrAzwvrrM2kVEckiBIIUOHYyaqZdwbp9uJ10ZdO1cxrl9ujF/6sj2k8raqvKo6o8iUgC0RtCOSMoAq/qjiBSwSAKBmU0A7gfKgLnuPqvF83cAU4CjQD3wRXd/K3juGLAu6Pq2u0+kwIQuA9y0IPzSPYnpoO7liSCghWIRKQChA4GZlQEPAlcBdcBqM1vk7huSuv0WqHL3g2b2v4B7gZuC595392Fhx1HwVP1RpCjFodZYFFcEI4At7r4VwMyeBCYBxwOBuy9N6r8S+NsIPldEJKviUmssisXifkDyOXh1QVtbbgOWJD3uYma1ZrbSzK5t60VmNi3oV1tfr5IOIpJdcao1ltNdQ2b2t0AV8C9JzR8ODlOuBn5kZue29lp3n+PuVe5e1adPO9s1RURCirTWWIFXFogiEGwH+ic9Lg/amjGzccC3gYnufqip3d23B7dbgWXAhRGMSUQklMhqjTVVFtj3DuAnKgsUUDCIIhCsBgaZ2UAz6wxMBhYldzCzC4GHSQSBXUntPczstOB+b+BSktYWRETyJbJaY0VQWSD0YrG7HzWz6cDzJLaP/tTd3zCze4Bad19EYiqoG/DvZgYntomeDzxsZo0kgtKsFruNRETyIrJaY0VQWSCSPAJ3XwwsbtE2I+n+uDZetwL46yjGICISpeqRFazYsjvl9FBatca6lwfTQq20FwiVmBARaUVktcbGzkhUEkhWYJUFFAhERFoRWa2xITfCNbOhe3/AErfXzC6oBFNzL749sFVVVV5bW5vvYYikJQ6ZqaWssdHD1RorIGa2Jtiu34yKzolkUVwyU0tZ6FpjRUBTQyJZEqfMVCluCgQiWRKnzFQpbgoEIlkSp8xUKW4KBCJZEqfMVCluCgQiWdJuxmm6/YogM1WKmwKBSJZUj6w4af95S2lnpmbSLpIhBQKRLIlTZqoUNwUCkSyJU2aqFDdlFotkWSllpkpxU2axSJ7EITNVipumhkREYk6BQEQk5iIJBGY2wcw2mdkWM7urledPM7OngudXmdmApOe+FbRvMrOroxiPiIikL3QgMLMy4EHgk0AlcLOZVbbodhuw190/AtwHfD94bSWJM44vACYA/zd4PxERyZEorghGAFvcfau7HwaeBCa16DMJmBfcXwiMtcThxZOAJ939kLu/CWwJ3k9ERHIkikDQD0g+kLMuaGu1j7sfJXEidK80XwuAmU0zs1ozq62vT6Nao4iIpKVoto+6+xxgDiTyCPI8nIzohCoRKWRRBILtQP+kx+VBW2t96sysI9AdaEjztUUtshOq1i5IVJvcV5eoMTN2hjJLRSQSUUwNrQYGmdlAM+tMYvF3UYs+i4BbgvufBV72RErzImBysKtoIDAI+E0EYyoIkZ1QpXr0IpJFoQNBMOc/HXge2AgscPc3zOweM5sYdHsU6GVmW4A7gLuC174BLAA2AM8BX3H31Cd5FJHITqhSPXoRyaJI1gjcfTGwuEXbjKT7HwA3tPHa7wHfi2IchSaTE6pSlh9QPXoRySJlFmdRZCdUqR69iGSRAkEWRXZClerRi0gWKRBkUWQnVKkevYhkUdHkERSjphOqttYfaHXBOO0TqiDxS1+/+EUkC3RFkEWRnVAlIpJFuiLIsl7dTmPJ7aN1QpWIFCwFghzQCVUi8VUMJWYUCEREsqRYSsxojUBEJAuKqcSMAoGISBYUU4kZBQIRkSzIpMRMSjkoMaNAICKSBcVUYkaBQEQkC4qpxIwCgYhIFhRTiRltHxURyYJiKjET6orAzHqa2Qtmtjm47dFKn2Fm9t9m9oaZrTWzm5Kee8zM3jSz14OfYWHGIyJSKIqpxIwlTow8xReb3QvscfdZZnYX0MPdv9miz0cBd/fNZnYOsAY4393/bGaPAb9094WZfG5VVZXX1tae8rhFRHKlsdELpsSMma1x96qW7WGnhiYBlwf35wHLgGaBwN3/kHT/j2a2C+gD/DnkZ4vkRCQlArKcGSqFqxhKzIQNBH3dfUdw/09A31SdzWwE0Bn4n6Tm75nZDOAl4C53PxRyTCKRiaREQFNmaFNSUFNmKCgYSEFod43AzF40s/Wt/ExK7ueJOaY255nM7Gzg/wF/5+6NQfO3gI8Bw4GetLiaaPH6aWZWa2a19fXtZOKJRCCyEgE5yAwVCaPdKwJ3H9fWc2a208zOdvcdwS/6XW30+wvgV8C33X1l0ns3XU0cMrN/A+5MMY45wBxIrBG0N26RsDIpEZDysj8HmaEiYYTNI1gE3BLcvwV4tmUHM+sMPAM83nJROAgemJkB1wLrQ45HJDKRlQjIQWaoSBhhA8Es4Coz2wyMCx5jZlVmNjfocyMwBri1lW2iT5jZOmAd0Bv4bsjxiEQmshIBOcgMFQkj1GKxuzcAY1tprwWmBPd/BvysjddfGebzRbIpkfq/L81+KTQtCGvXkBQoZRaLtKF6ZAUrtuxOOT2UVokAyHpmqEgYqjUk0oamEgEd28gVyKhEgEgBUyAQaUMxlQgQCUNTQyIp9Op2GktuH10wJQJEskGBQKQdxVAiQCQMTQ2JiMScAoGISMwpEMTF2gVw32CYeVbidu2CfI9IRAqE1gjiQNUvRSQFBYIiELoefqrqlwoEIrGnQFDgIqmHr+qXIpKC1ggKWGT18FX9UkRSUCAoYJnUw09J1S9FJAUFggIWWT38ITfCNbOhe3/AErfXzNb6gIgAWiMoaJHVwwdVvxSRNumKoIC1W+c+w34iIq0JFQjMrKeZvWBmm4PbHm30O5Z0OtmipPaBZrbKzLaY2VPBsZYSqB5ZcVLVy5bSrocvItKGsFcEdwEvufsg4KXgcWved/dhwc/EpPbvA/e5+0eAvcBtIcdTUlQPX0RyIWwgmATMC+7PI3EAfVqCA+uvBJoOtM/o9XGgevgikgthF4v7uvuO4P6fgL5t9OtiZrXAUWCWu/8c6AX82d2PBn3qgH4hx1NyVA9fJN5CVxZIQ7uBwMxeBP6ylae+nfzA3d3M2sps+rC7bzezvwJeNrN1pHMqePNxTAOmAVRUxGtOXPXwReIpksoCaWh3asjdx7n74FZ+ngV2mtnZAMHtrjbeY3twuxVYBlwINABnmVlTMCoHtqcYxxx3r3L3qj59NCcuIqUtssoCaQi7RrAIuCW4fwvwbMsOZtbDzE4L7vcGLgU2uLsDS4HPpnq9iEgcRVZZIA1hA8Es4Coz2wyMCx5jZlVmNjfocz5Qa2a/I/GLf5a7bwie+yZwh5ltIbFm8GjI8Yhkh85zkByLrLJAGkItFrt7AzC2lfZaYEpwfwXw1228fiswIswYRLJO5zlIHkRaWaAdyiwWaU+q8xxEsiSXlQUUCETao/McJA9yWVlAgUCkPTrPQfIgl5UFFAik5DU2Oks37WLq47VM/PGrTH28lqWbdqW/7U7nOUge5LKygMpQS0mLJCGnaUH4pXsS00HdyxNBQAvFkmW5qixgie38xaWqqspra2vzPQwpcI2NzoT7l7O1/kCre7E7djDO7dONJbePVqkOiQUzW+PuVS3bNTUkJSuXCTkixUyBQNJThAlVuUzIESlmWiOQ9hVpQlUuE3JEipmuCKR9RZpQpaM+RdKjQCDtK9KEKh31KZIeBQJpX5EmVOmoT5H0KBBI+4o0oUpHfYqkR4vF0r4iTqjSUZ8i7VNCmYhITLSVUKYrghjIxeHXIlK8QgUCM+sJPAUMALYBN7r73hZ9rgDuS2r6GDDZ3X9uZo8Bl3HiIPtb3f31MGOS5nJ1+HXBW7ugKKe24ubIkSPU1dXxwQfK7QijS5culJeX06lTp7T6h5oaMrN7gT3uPsvM7gJ6uPs3U/TvCWwByt39YBAIfunuCzP5XE0NpUe1dgItE+Igsdh9zWwFgwLz5ptvcuaZZ9KrVy/MSvjfZBa5Ow0NDbz33nsMHDiw2XPZqjU0CZgX3J8HXNtO/88CS9z9YMjPlTSo1k6gSBPi4uiDDz5QEAjJzOjVq1dGV1VhA0Ffd98R3P8T0Led/pOBmhZt3zOztWZ2n5m1OUdhZtPMrNbMauvrS/wXV0RUaydQpAlxcaUgEF6mf4ftrhGY2YvAX7by1LeTH7i7m1mb80xmdjaJQ+yfT2r+FokA0hmYA3wTaPVrmrvPCfpQVVVVfFud8kC1dgLdyxP1kVprl6KlTRDRafeKwN3HufvgVn6eBXYGv+CbftHvSvFWNwLPuPuRpPfe4QmHgH8DRoT740iygqq1k8/qpUWaECdt273/EBPuX870J17jhQ07WVu3jxc27GT6E68x4f7lNOw/FOr9f/7zn2Nm/P73v0/Z70c/+hEHD576TPdjjz3G9OnTT/n1UQk7NbQIuCW4fwvwbIq+N9NiWigpiBiJ9YX1IccjSQqm1k7TYu2+dwA/Ub00V8FgyI2JheHu/QFL3GqhuGg1NjrVj6xka/2Bk6Y+Dxw+xtb6A1Q/sir9o0hbUVNTw6hRo6ipaTmT3VzYQFAowgaCWcBVZrYZGBc8xsyqzGxuUyczGwD0B15p8fonzGwdsA7oDXw35HgkScHU2imExdohN8LX18PMPyduFQSKVrY3Qezfv59XX32VRx99lCeffBKAY8eOceeddzJ48GCGDBnCAw88wOzZs/njH//IFVdcwRVXXAFAt27djr/PwoULufXWWwH4xS9+wciRI7nwwgsZN24cO3fuPKWxZUuoPAJ3bwDGttJeC0xJerwN6NdKvyvDfL6k1lRrp/qRVdTtPdjs21PXzmWU9zgjN7V2olisVR6ABDLZBHH5eR/K+P2fffZZJkyYwEc/+lF69erFmjVr+M1vfsO2bdt4/fXX6dixI3v27KFnz5788Ic/ZOnSpfTu3Tvle44aNYqVK1diZsydO5d7772XH/zgBxmPLVuUWVziCqLWTtjF2iI9GEeyI9ubIGpqarj99tsBmDx5MjU1Nbz55pt8+ctfpmPHxK/Mnj17ZvSedXV13HTTTezYsYPDhw+ftL8/3xQIYqBDB+Py8z50St+OIjF2RusJXeku1qaaWlIgiJ3E5oZ9afbLzJ49e3j55ZdZt24dZsaxY8cwM4YPH57W65O3bSbv4//qV7/KHXfcwcSJE1m2bBkzZ87MeGzZpDLUkn1hF2uVByBJsrkJYuHChXz+85/nrbfeYtu2bbzzzjsMHDiQoUOH8vDDD3P06FEgETAAzjzzTN57773jr+/bty8bN26ksbGRZ5555nj7vn376NcvMTs+b948Co0CgeRGiMVab2MKqa12KW3Z3ARRU1PDdddd16zt+uuvZ8eOHVRUVDBkyBCGDh3K/PnzAZg2bRoTJkw4vlg8a9YsPv3pT/OJT3yCs88++/h7zJw5kxtuuIGLL7643fWEfFAZailou/cf4pEHZ/H3B3/M6Xb4ePv73pkfnTGdaV+5Kx5F82Ji48aNnH/++e32a9h/qN1NEHH/d9Ha36XKUEvROb5ffN9wdjCFb3RcwDnWwB+9F/cevZHF+4az7JFVpV80T05SEJsgSogCgRSs5P3iixjFosOjWvQ4sV88bwvhkjd53wRRQrRGIAVLRfNEckOBQAqWiuaJ5IamhqRd+arymM394iJyggKBpJTPoy6rR1awYsvulNNDOSmaJ1LiNDUkbcpFlcdUCqZonsRKWVkZw4YNY/Dgwdxwww2hqoveeuutLFyYOIl3ypQpbNiwoc2+y5YtY8WKFRl/xoABA9i9e/cpjxEUCCSFfB912VQ079w+3U7KJO3auYxz+3TLTdE8KVxZOOfi9NNP5/XXX2f9+vV07tyZhx56qNnzTdnFmZo7dy6VlZVtPn+qgSAKCgTSpkLYtdO0X/zBz13EVZV9GVLenasq+/Lg5y5iye2jY580FGs5OOdi9OjRbNmyhWXLljF69GgmTpxIZWUlx44d4x/+4R8YPnw4Q4YM4eGHHwYSB8dPnz6d8847j3HjxrFr14mzui6//HKaEmGfe+45LrroIoYOHcrYsWPZtm0bDz30EPfddx/Dhg3jP//zP6mvr+f6669n+PDhDB8+nP/6r/8CoKGhgfHjx3PBBRcwZcoUokgK1hqBtCmqXTthF5u1X1xaleVihEePHmXJkiVMmDABgNdee43169czcOBA5syZQ/fu3Vm9ejWHDh3i0ksvZfz48fz2t79l06ZNbNiwgZ07d1JZWckXv/jFZu9bX1/P1KlTWb58OQMHDjxe0vrLX/4y3bp148477wSgurqar3/964waNYq3336bq6++mo0bN/Kd73yHUaNGMWPGDH71q1/x6KOPhv6zKhBIm6LYtZPPxWYpcVkqRvj+++8zbNgwIHFFcNttt7FixQpGjBhxvHz0r3/9a9auXXt8/n/fvn1s3ryZ5cuXc/PNN1NWVsY555zDlVeefOTKypUrGTNmzPH3aquk9YsvvthsTeHdd99l//79LF++nKeffhqAT33qU/To0SPUnxdCBgIzuwGYCZwPjAgOpGmt3wTgfqAMmOvuTSeZDQSeBHoBa4DPu/vh1t5Dci/srp3kxeaW6wzJi80qESGnJOw5F21oWiNoqWvXrsfvuzsPPPAAV199dbM+ixcvDvXZyRobG1m5ciVdumR/e3TYNYL1wGeA5W11MLMy4EHgk0AlcLOZNa2YfB+4z90/AuwFbgs5HolQ2F07+V5slhI3dkbiXItkmZxzEcLVV1/NT37yE44cOQLAH/7wBw4cOMCYMWN46qmnOHbsGDt27GDp0qUnvfaSSy5h+fLlvPnmm0DbJa3Hjx/PAw88cPxxU3AaM2bM8eqnS5YsYe/evaH/PKECgbtvdPdN7XQbAWxx963Bt/0ngUnBgfVXAguDfvNIHGAvBSLsrp1CWGyWEhb2nIsQpkyZQmVlJRdddBGDBw/mS1/6EkePHuW6665j0KBBVFZW8oUvfIGPf/zjJ722T58+zJkzh8985jMMHTqUm266CYBrrrmGZ5555vhi8ezZs6mtrWXIkCFUVlYe37109913s3z5ci644AKefvppKirC59FEUobazJYBd7Y2NWRmnwUmuPuU4PHngZEkppRWBlcDmFl/YIm7D27jM6YB0wAqKioufuutt0KPW9LT2OinVOVx4o9fZW1d+2sMQ8q7s2h6y4JyEkfplqGW9kVahtrMXgT+spWnvu3uz57yKDPk7nOAOZA4jyBXnyunvmtHJSJEikO7gcDdx4X8jO1A/6TH5UFbA3CWmXV096NJ7VIiVCJCpDjkIqFsNTDIzAaaWeRaROwAAAUtSURBVGdgMrDIE3NSS4HPBv1uAXJ2hSHZpxIRciqK8dTEQpPp32GoQGBm15lZHfBx4Fdm9nzQfo6ZLQ4GdBSYDjwPbAQWuPsbwVt8E7jDzLaQ2EIaPjNCCoZKREimunTpQkNDg4JBCO5OQ0NDRttOdWaxZN2pLjZL/Bw5coS6ujo++EBnTITRpUsXysvL6dSpU7N2nVkseaMSEZKuTp06Hc+4ldxR0TkRkZhTIBARiTkFAhGRmCvKxWIzqwdONbW4NxDuOJ/s0Lgyo3FlRuPKTKmO68PuftJ+7aIMBGGYWW1rq+b5pnFlRuPKjMaVmbiNS1NDIiIxp0AgIhJzcQwEc/I9gDZoXJnRuDKjcWUmVuOK3RqBiIg0F8crAhERSaJAICISc7EJBGbW38yWmtkGM3vDzG7P95gAzKyLmf3GzH4XjOs7+R5TEzMrM7Pfmtkv8z2WZGa2zczWmdnrZlYw1QfN7CwzW2hmvzezjWZ28jmFuR/TecHfU9PPu2b29/keF4CZfT34N7/ezGrMrCBOKDKz24MxvZHPvysz+6mZ7TKz9UltPc3sBTPbHNz2iOKzYhMIgKPA/3b3SuAS4CtmVpnnMQEcAq5096HAMGCCmV2S5zE1uZ1E6fBCdIW7Dyuwvd73A8+5+8eAoRTA3527bwr+noYBFwMHgWfyPCzMrB/wNaAqOJ62jMRZJXllZoOBqSTOWh8KfNrMPpKn4TwGTGjRdhfwkrsPAl4KHocWm0Dg7jvc/bXg/nsk/pP2y++owBP2Bw87BT95X8E3s3LgU8DcfI+lGJhZd2AMwZka7n7Y3f+c31GdZCzwP+5eKAd+dwRON7OOwBnAH/M8HoDzgVXufjA4S+UV4DP5GIi7Lwf2tGieBMwL7s8Dro3is2ITCJKZ2QDgQmBVfkeSEEzBvA7sAl5w90IY14+AbwCN+R5IKxz4tZmtMbNp+R5MYCBQD/xbMJ0218y65ntQLUwGavI9CAB33w78K/A2sAPY5+6/zu+oAFgPjDazXmZ2BvA3ND9qN9/6uvuO4P6fgL5RvGnsAoGZdQP+A/h7d3833+MBcPdjwaV7OTAiuDzNGzP7NLDL3dfkcxwpjHL3i4BPkpjiG5PvAZH4dnsR8BN3vxA4QESX7VEIjomdCPx7vscCEMxtTyIRQM8BuprZ3+Z3VODuG4HvA78GngNeB9o+dDuPguN+I5k9iFUgMLNOJILAE+7+dL7H01IwlbCUk+cFc+1SYKKZbQOeBK40s5/ld0gnBN8mcfddJOa7R+R3RADUAXVJV3MLSQSGQvFJ4DV335nvgQTGAW+6e727HwGeBj6R5zEB4O6PuvvF7j4G2Av8Id9jSrLTzM4GCG53RfGmsQkEZmYk5m83uvsP8z2eJmbWx8zOCu6fDlwF/D6fY3L3b7l7ubsPIDGd8LK75/3bGoCZdTWzM5vuA+NJXM7nlbv/CXjHzM4LmsYCG/I4pJZupkCmhQJvA5eY2RnB/82xFMDiOoCZfSi4rSCxPjA/vyNqZhFwS3D/FuDZKN40TkdVXgp8HlgXzMcD/B93X5zHMQGcDcwzszISgXmBuxfUds0C0xd4JvG7g47AfHd/Lr9DOu6rwBPBNMxW4O/yPB7geMC8CvhSvsfSxN1XmdlC4DUSO/p+S+GUdfgPM+sFHAG+kq9FfzOrAS4HeptZHXA3MAtYYGa3kSjFf2Mkn6USEyIi8RabqSEREWmdAoGISMwpEIiIxJwCgYhIzCkQiIjEnAKBiEjMKRCIiMTc/wf6WNH/k7wloAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWM1b9iKMkKe",
        "outputId": "8db03ab3-47f0-4d74-983a-27cee564fb11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 48\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.8065],\n",
            "        [ 0.1771],\n",
            "        [-0.8170],\n",
            "        [ 0.8130],\n",
            "        [ 0.8252],\n",
            "        [-0.8257]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-3.2082e-01,  2.5052e-01, -1.2359e-01,  1.7802e-01,  8.7040e-02,\n",
            "         -1.6337e-01],\n",
            "        [-2.3736e-01,  3.7018e-01,  3.4390e-01, -3.2391e-02,  3.6817e-01,\n",
            "         -3.4018e-01],\n",
            "        [-2.9130e-01, -1.4683e-01,  6.7102e-02, -1.1024e-02, -8.6213e-02,\n",
            "          1.6474e-04],\n",
            "        [ 2.3286e-01,  2.3885e-01, -3.5169e-01, -3.4843e-01,  1.0673e-01,\n",
            "         -2.1323e-01],\n",
            "        [ 2.9536e-01,  2.4716e-01, -2.3826e-01, -2.2648e-02,  1.1460e-01,\n",
            "         -3.9898e-01],\n",
            "        [ 2.8494e-01, -3.8583e-01,  6.8416e-02, -2.5032e-01,  2.9895e-01,\n",
            "         -1.7028e-01]], requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1924,  0.0106, -0.2410,  0.2252,  0.2757, -0.2778]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN with one layer configured as Many-to-one"
      ],
      "metadata": {
        "id": "nSM0mLVo1CKt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "LoLoL_Ch4lGy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with a Many-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "I6nhIROx4lG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 2\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 1\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "tWuwKnF34lG0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "sEh2BwiU4lG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "seVVpB6V4lG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating an RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.3)"
      ],
      "metadata": {
        "id": "dcknom2b4lG1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb5927e-1b9d-4c1a-84b6-6aaa08c2fc1b",
        "id": "dMl6mfqJ4lG1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 54\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 2])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1972, -0.2539],\n",
            "        [-0.1686,  0.3213],\n",
            "        [ 0.3860,  0.1619],\n",
            "        [ 0.2199, -0.3887],\n",
            "        [ 0.2631, -0.3738],\n",
            "        [-0.3716,  0.1908]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.2076,  0.1659,  0.1476,  0.1567, -0.2824,  0.2494],\n",
            "        [-0.2183, -0.1542,  0.1734,  0.0442,  0.0307, -0.0092],\n",
            "        [-0.2469, -0.3998, -0.3396,  0.3520,  0.1074,  0.0057],\n",
            "        [-0.2816,  0.3824, -0.0446, -0.1048,  0.2515,  0.1607],\n",
            "        [-0.1352, -0.2461,  0.0843,  0.1480, -0.2529, -0.3741],\n",
            "        [-0.3007, -0.3699,  0.1233,  0.0510, -0.1828, -0.2400]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0460,  0.0649,  0.2891, -0.0740,  0.0914, -0.1281]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "seq_length = 1\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "9xt5Mhxw4lG1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "\n",
        "   # Initialize the hidden state\n",
        "   h0 = torch.zeros(1,  hidden_size)\n",
        "   \n",
        "   for j in range(x.size(0) - 1):\n",
        "      input = x[j:(j+2)]\n",
        "      target = y[j:(j+2)]\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input.t(), h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd4d1d5-5861-449f-b133-340c5376d3dc",
        "id": "hpPy5_y94lG1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 4.4336838722229\n",
            "Epoch: 10 loss 1.7661694288253784\n",
            "Epoch: 20 loss 1.3932373523712158\n",
            "Epoch: 30 loss 1.1979223489761353\n",
            "Epoch: 40 loss 1.0892937183380127\n",
            "Epoch: 50 loss 1.0232353210449219\n",
            "Epoch: 60 loss 0.9800454378128052\n",
            "Epoch: 70 loss 0.9501742124557495\n",
            "Epoch: 80 loss 0.9285774230957031\n",
            "Epoch: 90 loss 0.9123901724815369\n",
            "Epoch: 100 loss 0.899886965751648\n",
            "Epoch: 110 loss 0.8899769186973572\n",
            "Epoch: 120 loss 0.8819431662559509\n",
            "Epoch: 130 loss 0.8752987384796143\n",
            "Epoch: 140 loss 0.8697041869163513\n",
            "Epoch: 150 loss 0.864916980266571\n",
            "Epoch: 160 loss 0.8607602119445801\n",
            "Epoch: 170 loss 0.8571029901504517\n",
            "Epoch: 180 loss 0.853847324848175\n",
            "Epoch: 190 loss 0.8509175777435303\n",
            "Epoch: 200 loss 0.8482558727264404\n",
            "Epoch: 210 loss 0.8458172082901001\n",
            "Epoch: 220 loss 0.8435659408569336\n",
            "Epoch: 230 loss 0.841473400592804\n",
            "Epoch: 240 loss 0.8395176529884338\n",
            "Epoch: 250 loss 0.8376795053482056\n",
            "Epoch: 260 loss 0.8359445929527283\n",
            "Epoch: 270 loss 0.8343004584312439\n",
            "Epoch: 280 loss 0.8327372670173645\n",
            "Epoch: 290 loss 0.8312463760375977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0) - 1):\n",
        "   input = x[i:i+2]\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input.t(), h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "cw6YVtGb4lG2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_time_steps = np.linspace(2, 10, x.shape[0])\n",
        "\n",
        "pl.scatter(data_time_steps[:-1], y.data[:-1].numpy(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[:-1], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8f95dc6b-ec22-4c49-de2c-e7bc3396e786",
        "id": "w_NszNfw4lG2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c9e8b7-7a30-4cdf-c1c0-dd467ddb0649",
        "id": "2XV0zGJl4lG2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 54\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 2])\n",
            "Parameter containing:\n",
            "tensor([[-1.0623,  1.6469],\n",
            "        [-0.2183,  0.4557],\n",
            "        [ 0.0235, -0.9632],\n",
            "        [-0.2005,  1.0576],\n",
            "        [-0.5270, -0.6371],\n",
            "        [ 0.4598, -1.2108]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.3402,  0.1997, -0.2267, -0.1469, -0.0959, -0.0933],\n",
            "        [-0.0663,  0.3926,  0.0180, -0.0361,  0.3734, -0.2884],\n",
            "        [ 0.2821,  0.0024,  0.4007,  0.3000,  0.2085, -0.3537],\n",
            "        [-0.0050,  0.3329, -0.3460, -0.0841,  0.1212, -0.2376],\n",
            "        [-0.0543, -0.1468,  0.0025, -0.4041, -0.3034, -0.0545],\n",
            "        [ 0.2107,  0.1552,  0.1369,  0.1960, -0.3657, -0.2092]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.3965,  0.0039, -0.3568,  0.2759, -0.0582, -0.2657]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN with two layers configured as One-to-one"
      ],
      "metadata": {
        "id": "C76RCcIt7is9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we have sequential data and we are going to implement an RNN with 2 layers and a One-to-one configuration!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/SeqData_RNN.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "F8UiN-s074BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use non-linear data with more complexity in this step!"
      ],
      "metadata": {
        "id": "PVCL5Ex99IBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input size, hidden size and number of outputs\n",
        "input_size = 1\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "num_layers = 2\n",
        "seq_length = 20\n",
        "\n",
        "data_time_steps = np.linspace(2, 10, seq_length + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "data.resize((seq_length + 1, 1))\n",
        "\n",
        "x = Variable(torch.Tensor(data[:-1]).type(torch.FloatTensor), requires_grad=False)\n",
        "y = Variable(torch.Tensor(data[1:]).type(torch.FloatTensor), requires_grad=False)"
      ],
      "metadata": {
        "id": "HmEvnoDX74BJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create an RNN, we follow the same steps as for implementing an ANN!\n",
        "\n",
        "1. Creating a Neural Network\n",
        "2. Network Evaluation\n",
        "3. Gradient Calculation\n",
        "4. Back Propagation\n",
        "5. Training\n"
      ],
      "metadata": {
        "id": "3HWQFctV74BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/rnn_vis.gif\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "oMPNEvsa74BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating a RNN model\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, bias=False, nonlinearity='tanh', num_layers=2)\n",
        "\n",
        "# Initialize the output layer\n",
        "fc = torch.nn.Linear(hidden_size, output_size, bias=False)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "m4TOKiExobEv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "# Print the shapes of the parameters\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df0b999-a2b6-4ba2-bbfd-73bafe1470ed",
        "id": "nM7eanghobEv"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 120\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.2962],\n",
            "        [-0.0924],\n",
            "        [-0.1140],\n",
            "        [ 0.1116],\n",
            "        [-0.1332],\n",
            "        [-0.3197]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0702, -0.3971, -0.1220,  0.3464, -0.4012, -0.1342],\n",
            "        [-0.0741, -0.2294, -0.2343,  0.2221,  0.1027,  0.0859],\n",
            "        [-0.1500,  0.2303, -0.1509, -0.1526,  0.1217,  0.1330],\n",
            "        [-0.2623, -0.1567, -0.3532, -0.1206,  0.1613, -0.2738],\n",
            "        [ 0.3611,  0.1287,  0.1213,  0.3848,  0.1694,  0.0507],\n",
            "        [-0.2864, -0.1079,  0.2135,  0.3350,  0.3289, -0.0052]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_ih_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.2557, -0.1266, -0.0105, -0.0474, -0.3792,  0.0272],\n",
            "        [-0.1698, -0.3576,  0.3857,  0.3411,  0.1472, -0.0063],\n",
            "        [-0.0951,  0.1553, -0.0015, -0.3038,  0.2031,  0.0342],\n",
            "        [ 0.3653, -0.3807, -0.1899, -0.1531, -0.3310,  0.2915],\n",
            "        [ 0.0861, -0.1050,  0.0598,  0.4075, -0.0578,  0.0123],\n",
            "        [-0.1890,  0.1220,  0.3706,  0.1488, -0.3179,  0.3522]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_hh_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0927, -0.3384, -0.2182, -0.2229, -0.1464, -0.0110],\n",
            "        [ 0.1692, -0.0676,  0.0146,  0.3252, -0.1155, -0.2267],\n",
            "        [-0.0482,  0.3331,  0.0579, -0.2706,  0.0171,  0.3930],\n",
            "        [ 0.0613, -0.0247, -0.2617,  0.0233,  0.0802,  0.2453],\n",
            "        [ 0.4007, -0.3648,  0.0061,  0.0429,  0.3116,  0.2397],\n",
            "        [ 0.1728, -0.0131,  0.0154,  0.3645,  0.2591, -0.3280]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1276,  0.0378, -0.1213,  0.1985, -0.3247,  0.2363]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "fKSW4152obEw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the error in the code and explain why it is wrong?"
      ],
      "metadata": {
        "id": "9AlTUdpRyohC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "   total_loss = 0\n",
        "   for j in range(x.size(0)-3):\n",
        "      input = x[j:(j+1)]\n",
        "      target = y[j:(j+1)]\n",
        "\n",
        "      # Initialize the hidden state\n",
        "      h0 = torch.zeros(2, hidden_size)\n",
        "\n",
        "      # Forward pass\n",
        "      out, hn = rnn(input, h0)\n",
        "\n",
        "      # 2. Model Evaluation\n",
        "      y_pred = fc(hn.squeeze(0))\n",
        "      loss = criterion(y_pred.view(-1), target)\n",
        "    \n",
        "      # 3. Gradient Calculation\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Back Propagation\n",
        "      optimizer.step()\n",
        "\n",
        "   # display loss \n",
        "   if i % 10 == 0:\n",
        "      print(\"Epoch: {} loss {}\".format(i, total_loss.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9c4b36-0b34-4af9-b66a-ac503ff7e11d",
        "id": "705R15JoobEw"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss 8.37125301361084\n",
            "Epoch: 10 loss 6.3956685066223145\n",
            "Epoch: 20 loss 4.73377799987793\n",
            "Epoch: 30 loss 3.4398276805877686\n",
            "Epoch: 40 loss 2.59870982170105\n",
            "Epoch: 50 loss 2.109647274017334\n",
            "Epoch: 60 loss 1.8306785821914673\n",
            "Epoch: 70 loss 1.667047142982483\n",
            "Epoch: 80 loss 1.5670651197433472\n",
            "Epoch: 90 loss 1.503443717956543\n",
            "Epoch: 100 loss 1.4614301919937134\n",
            "Epoch: 110 loss 1.4327354431152344\n",
            "Epoch: 120 loss 1.412517786026001\n",
            "Epoch: 130 loss 1.3978482484817505\n",
            "Epoch: 140 loss 1.386900544166565\n",
            "Epoch: 150 loss 1.3785068988800049\n",
            "Epoch: 160 loss 1.3719035387039185\n",
            "Epoch: 170 loss 1.3665800094604492\n",
            "Epoch: 180 loss 1.3621913194656372\n",
            "Epoch: 190 loss 1.3584990501403809\n",
            "Epoch: 200 loss 1.3553358316421509\n",
            "Epoch: 210 loss 1.3525831699371338\n",
            "Epoch: 220 loss 1.3501561880111694\n",
            "Epoch: 230 loss 1.3479923009872437\n",
            "Epoch: 240 loss 1.3460447788238525\n",
            "Epoch: 250 loss 1.344278335571289\n",
            "Epoch: 260 loss 1.342665672302246\n",
            "Epoch: 270 loss 1.3411855697631836\n",
            "Epoch: 280 loss 1.339821219444275\n",
            "Epoch: 290 loss 1.338558316230774\n",
            "Epoch: 300 loss 1.3373857736587524\n",
            "Epoch: 310 loss 1.3362934589385986\n",
            "Epoch: 320 loss 1.3352736234664917\n",
            "Epoch: 330 loss 1.3343188762664795\n",
            "Epoch: 340 loss 1.333423137664795\n",
            "Epoch: 350 loss 1.3325810432434082\n",
            "Epoch: 360 loss 1.331787347793579\n",
            "Epoch: 370 loss 1.331038475036621\n",
            "Epoch: 380 loss 1.3303302526474\n",
            "Epoch: 390 loss 1.329659342765808\n",
            "Epoch: 400 loss 1.3290225267410278\n",
            "Epoch: 410 loss 1.3284175395965576\n",
            "Epoch: 420 loss 1.3278415203094482\n",
            "Epoch: 430 loss 1.3272923231124878\n",
            "Epoch: 440 loss 1.326768159866333\n",
            "Epoch: 450 loss 1.3262666463851929\n",
            "Epoch: 460 loss 1.3257864713668823\n",
            "Epoch: 470 loss 1.3253265619277954\n",
            "Epoch: 480 loss 1.3248848915100098\n",
            "Epoch: 490 loss 1.3244602680206299\n",
            "Epoch: 500 loss 1.324051856994629\n",
            "Epoch: 510 loss 1.3236585855484009\n",
            "Epoch: 520 loss 1.3232793807983398\n",
            "Epoch: 530 loss 1.3229135274887085\n",
            "Epoch: 540 loss 1.3225599527359009\n",
            "Epoch: 550 loss 1.3222180604934692\n",
            "Epoch: 560 loss 1.3218872547149658\n",
            "Epoch: 570 loss 1.3215668201446533\n",
            "Epoch: 580 loss 1.3212566375732422\n",
            "Epoch: 590 loss 1.3209556341171265\n",
            "Epoch: 600 loss 1.3206634521484375\n",
            "Epoch: 610 loss 1.3203798532485962\n",
            "Epoch: 620 loss 1.3201041221618652\n",
            "Epoch: 630 loss 1.3198362588882446\n",
            "Epoch: 640 loss 1.3195750713348389\n",
            "Epoch: 650 loss 1.319321632385254\n",
            "Epoch: 660 loss 1.3190743923187256\n",
            "Epoch: 670 loss 1.3188337087631226\n",
            "Epoch: 680 loss 1.3185992240905762\n",
            "Epoch: 690 loss 1.3183704614639282\n",
            "Epoch: 700 loss 1.31814706325531\n",
            "Epoch: 710 loss 1.3179293870925903\n",
            "Epoch: 720 loss 1.3177169561386108\n",
            "Epoch: 730 loss 1.3175095319747925\n",
            "Epoch: 740 loss 1.3173067569732666\n",
            "Epoch: 750 loss 1.3171087503433228\n",
            "Epoch: 760 loss 1.3169150352478027\n",
            "Epoch: 770 loss 1.3167260885238647\n",
            "Epoch: 780 loss 1.3165411949157715\n",
            "Epoch: 790 loss 1.3163602352142334\n",
            "Epoch: 800 loss 1.31618332862854\n",
            "Epoch: 810 loss 1.3160099983215332\n",
            "Epoch: 820 loss 1.315840482711792\n",
            "Epoch: 830 loss 1.3156746625900269\n",
            "Epoch: 840 loss 1.3155124187469482\n",
            "Epoch: 850 loss 1.315353274345398\n",
            "Epoch: 860 loss 1.3151975870132446\n",
            "Epoch: 870 loss 1.3150451183319092\n",
            "Epoch: 880 loss 1.3148956298828125\n",
            "Epoch: 890 loss 1.3147492408752441\n",
            "Epoch: 900 loss 1.314605712890625\n",
            "Epoch: 910 loss 1.314465045928955\n",
            "Epoch: 920 loss 1.3143272399902344\n",
            "Epoch: 930 loss 1.3141920566558838\n",
            "Epoch: 940 loss 1.3140594959259033\n",
            "Epoch: 950 loss 1.313929557800293\n",
            "Epoch: 960 loss 1.3138022422790527\n",
            "Epoch: 970 loss 1.313677191734314\n",
            "Epoch: 980 loss 1.3135544061660767\n",
            "Epoch: 990 loss 1.3134342432022095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(x.size(0)):\n",
        "   input = x[i:i+1]\n",
        "\n",
        "   # Forward pass\n",
        "   out, hn = rnn(input, h0)\n",
        "   # Pass the hidden state through the output layer\n",
        "   y_pred = fc(hn.squeeze(0))\n",
        "   predictions.append(y_pred.data.numpy().ravel()[0])"
      ],
      "metadata": {
        "id": "YBtvHBlXobEw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7073e0-b9e1-45f2-f586-8fbbd0f4192f",
        "id": "Fc3w_fJFobEx"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.scatter(data_time_steps[:-1], y.data[:].numpy().tolist(), s = 90, label = \"Actual\")\n",
        "pl.scatter(data_time_steps[1:], predictions, label = \"Predicted\")\n",
        "pl.legend()\n",
        "pl.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8ffae0e8-e82d-4460-ef5d-15910c83aa11",
        "id": "-2BEAEhlobEx"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the parameters of the LSTM layer and linear layer\n",
        "params = list(rnn.parameters()) + list(fc.parameters())\n",
        "\n",
        "# Print the number of parameters\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in params))\n",
        "\n",
        "for name, param in rnn.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)\n",
        "# Print the shapes of the parameters\n",
        "for name, param in fc.named_parameters():\n",
        "    print(\"Name: \", name)\n",
        "    print(\"shape: \", param.shape)\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b154c0-bdee-4373-c0c8-a455d8c5ae03",
        "id": "ihzVc7T2obEx"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 120\n",
            "Name:  weight_ih_l0\n",
            "shape:  torch.Size([6, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.9744],\n",
            "        [-0.0609],\n",
            "        [-0.8666],\n",
            "        [ 1.0766],\n",
            "        [-1.2802],\n",
            "        [ 1.0829]], requires_grad=True)\n",
            "Name:  weight_hh_l0\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0702, -0.3971, -0.1220,  0.3464, -0.4012, -0.1342],\n",
            "        [-0.0741, -0.2294, -0.2343,  0.2221,  0.1027,  0.0859],\n",
            "        [-0.1500,  0.2303, -0.1509, -0.1526,  0.1217,  0.1330],\n",
            "        [-0.2623, -0.1567, -0.3532, -0.1206,  0.1613, -0.2738],\n",
            "        [ 0.3611,  0.1287,  0.1213,  0.3848,  0.1694,  0.0507],\n",
            "        [-0.2864, -0.1079,  0.2135,  0.3350,  0.3289, -0.0052]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_ih_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0989, -0.0411,  0.2407, -0.3282,  0.0240, -0.1828],\n",
            "        [-0.2841, -0.3840,  0.3032,  0.4334,  0.0172,  0.0645],\n",
            "        [ 0.1103,  0.2124,  0.1280, -0.4453,  0.4320, -0.0399],\n",
            "        [ 0.0957, -0.4609, -0.3480,  0.0169, -0.6277,  0.3512],\n",
            "        [ 0.5444,  0.0305,  0.3288,  0.1174,  0.4503, -0.0941],\n",
            "        [-0.4267,  0.0447,  0.2456,  0.2791, -0.5715,  0.3566]],\n",
            "       requires_grad=True)\n",
            "Name:  weight_hh_l1\n",
            "shape:  torch.Size([6, 6])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0927, -0.3384, -0.2182, -0.2229, -0.1464, -0.0110],\n",
            "        [ 0.1692, -0.0676,  0.0146,  0.3252, -0.1155, -0.2267],\n",
            "        [-0.0482,  0.3331,  0.0579, -0.2706,  0.0171,  0.3930],\n",
            "        [ 0.0613, -0.0247, -0.2617,  0.0233,  0.0802,  0.2453],\n",
            "        [ 0.4007, -0.3648,  0.0061,  0.0429,  0.3116,  0.2397],\n",
            "        [ 0.1728, -0.0131,  0.0154,  0.3645,  0.2591, -0.3280]],\n",
            "       requires_grad=True)\n",
            "Name:  weight\n",
            "shape:  torch.Size([1, 6])\n",
            "Parameter containing:\n",
            "tensor([[-0.1276,  0.0378, -0.1213,  0.1985, -0.3247,  0.2363]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}