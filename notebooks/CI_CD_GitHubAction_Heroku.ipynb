{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlVfVsbWBPQghbtA5xdg8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/CI_CD_GitHubAction_Heroku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set up a GitHub Action that trains a machine learning model on the Iris dataset, saves it as an artifact, and deploys the app on Heroku, you can follow these steps:"
      ],
      "metadata": {
        "id": "9erXU5RplcBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Make sure your GitHub repository contains the following files:\n",
        "- train_model.py: A Python script to train the model and save it as a .pkl file.- app.py: A Python script containing a Flask or FastAPI app that uses the trained model to make predictions. \n",
        "\n",
        "\n",
        "- requirements.txt: A list of Python dependencies.\n",
        "- Procfile: A Heroku Procfile to specify the app's entry point.\n",
        "- runtime.txt: A file to specify the Python runtime version."
      ],
      "metadata": {
        "id": "9e2c9w_Qlhtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*HY_qNXxMeD3LyUaXZHlcug.jpeg)"
      ],
      "metadata": {
        "id": "rmVh7cATsMaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model.py\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "def train_model():\n",
        "    iris = load_iris()\n",
        "    X, y = iris.data, iris.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    clf = RandomForestClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    return clf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_model()\n",
        "    joblib.dump(model, \"model.pkl\")"
      ],
      "metadata": {
        "id": "VgX3J7_TtfuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#app.py\n",
        "import joblib\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = joblib.load(\"model.pkl\")\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    features = data[\"features\"]\n",
        "    prediction = model.predict([features])\n",
        "    return jsonify({\"prediction\": int(prediction[0])})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "fz6GSIu6nIEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#requirements.txt\n",
        "flask\n",
        "joblib\n",
        "scikit-learn\n",
        "pandas\n",
        "gunicorn"
      ],
      "metadata": {
        "id": "d3TVOIAdnNVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Procfile\n",
        "web: gunicorn app:app"
      ],
      "metadata": {
        "id": "BYPuWjmAnSCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runtime.txt\n",
        "python-3.8"
      ],
      "metadata": {
        "id": "us1rrL1OnWT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create a new file in your repository named .github/workflows/main.yml. This is the GitHub Actions workflow configuration file."
      ],
      "metadata": {
        "id": "7xGq56W4niCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the following content to the main.yml file:\n",
        "\n",
        "name: Train Model and Deploy to Heroku\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches:\n",
        "      - main\n",
        "\n",
        "jobs:\n",
        "  train:\n",
        "    runs-on: ubuntu-latest\n",
        "\n",
        "    steps:\n",
        "    - name: Checkout repository\n",
        "      uses: actions/checkout@v2\n",
        "\n",
        "    - name: Set up Python\n",
        "      uses: actions/setup-python@v2\n",
        "      with:\n",
        "        python-version: 3.8\n",
        "\n",
        "    - name: Install dependencies\n",
        "      run: |\n",
        "        python -m pip install --upgrade pip\n",
        "        pip install -r requirements.txt\n",
        "    - name: Train model\n",
        "      run: python train.py\n",
        "\n",
        "    - name: Save Model\n",
        "      uses: actions/upload-artifact@v2\n",
        "      with:\n",
        "        name: model\n",
        "        path: model.pkl\n",
        "\n",
        "  deploy:\n",
        "    runs-on: ubuntu-latest\n",
        "    needs: train\n",
        "\n",
        "    steps:\n",
        "    - name: Checkout repository\n",
        "      uses: actions/checkout@v2\n",
        "\n",
        "    - name: Download model artifact\n",
        "      uses: actions/download-artifact@v2\n",
        "      with:\n",
        "        name: model\n",
        "        path: model.pkl\n",
        "\n",
        "    - name: Install Heroku CLI\n",
        "      run: curl https://cli-assets.heroku.com/install.sh | sh\n",
        "\n",
        "    - name: Deploy to Heroku\n",
        "      run: |\n",
        "        cd ${{ github.workspace }}\n",
        "        heroku container:login\n",
        "        heroku create iris-heroku-app-mlops\n",
        "        git push heroku HEAD:main\n",
        "      env:\n",
        "        HEROKU_API_KEY: ${{ secrets.HEROKU_API_KEY }}\n",
        "        HEROKU_APP_NAME: \"your-heroku-app-name\"\n",
        "        HEROKU_EMAIL: \"your@email.com\""
      ],
      "metadata": {
        "id": "2g12W0ovn_Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace your-heroku-app-name with your desired Heroku app name and your@email.com with your Heroku account's email address. Add your Heroku API key as a secret in your GitHub repository settings.\n",
        "\n",
        "Commit and push these files to the main branch of your repository. The GitHub Action will train the model, save it as an artifact, and deploy the Flask app to Heroku.\n",
        "\n",
        "You can then make predictions by sending a POST request to your Heroku app at https://your-heroku-app-name.herokuapp.com/predict with the following JSON payload:"
      ],
      "metadata": {
        "id": "Ol-ShLXzod6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"features\": [5.1, 3.5, 1.4, 0.2]\n",
        "}"
      ],
      "metadata": {
        "id": "vUd3ccEzofwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}