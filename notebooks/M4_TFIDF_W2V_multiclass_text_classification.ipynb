{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M4_TFIDF_W2V_multiclass_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQApuhxFCWJj"
      },
      "source": [
        "# Hate Speech Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-28d2hkCWJn"
      },
      "source": [
        "<img src=\"https://blog.colinbreck.com/content/images/size/w2000/2021/01/twitter-a-love-hate-relationship-1.png\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaTavQQtCWJn"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy\n",
        "!python -m spacy download en_core_web_md -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqZlCOK-C_-9",
        "outputId": "5950a7a8-0eb3-4b07-dc0e-858d6bedf886"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-15 09:09:57.888133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-15 09:10:00.393175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-15 09:10:00.393356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-15 09:10:00.393388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-15 09:10:03.882110: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLkaTsWoCWJo",
        "outputId": "f8155ce7-dfe6-4f44-c7ea-2ea08c46c735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "#First download SpaCy's en_core_web_md model then load \n",
        "#!python -m spacy download en_core_web_md\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load() \n",
        "\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier,XGBRFClassifier\n",
        "\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqmlURR4CWJq"
      },
      "source": [
        "Data Description:\n",
        "==============\n",
        "\n",
        "* count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were     determined to be unreliable by CF).\n",
        "\n",
        "* hate_speech = number of CF users who judged the tweet to be hate speech.\n",
        "\n",
        "* offensive_language = number of CF users who judged the tweet to be offensive.\n",
        "\n",
        "* neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
        "\n",
        "* class = class label for majority of CF users.\n",
        "\n",
        "   0 - hate speech\n",
        "   1 - offensive language \n",
        "   2 - neither\n",
        "\n",
        "* tweet = text data(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4s24kBFuCWJq",
        "outputId": "a8ce127c-e170-436d-84a1-9ded80928ab9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "2           2      3            0                   3        0      1   \n",
              "3           3      3            0                   2        1      1   \n",
              "4           4      6            0                   6        0      1   \n",
              "\n",
              "                                               tweet  \n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce0c7b17-092a-4454-8fe5-843972a0a46e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce0c7b17-092a-4454-8fe5-843972a0a46e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce0c7b17-092a-4454-8fe5-843972a0a46e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce0c7b17-092a-4454-8fe5-843972a0a46e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/HateSpeechData.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQk0Pw99CWJx"
      },
      "source": [
        "# Preprocessing of the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "71SNp11yCWJx"
      },
      "outputs": [],
      "source": [
        "# Create our list of stopwords\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "#extending the stopwords to include other words used in twitter such as retweet(rt) etc.\n",
        "#retweet, fav, follow friday\n",
        "\n",
        "nlp.Defaults.stop_words |= {\"#ff\", \"ff\", \"rt\",}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HMBHfY2PCWJx"
      },
      "outputs": [],
      "source": [
        "def preprocess(tweet):  \n",
        "    \n",
        "    # removal of extra spaces\n",
        "    regex_pat = re.compile(r'\\s+')\n",
        "    tweet_space = tweet.str.replace(regex_pat, ' ')\n",
        "\n",
        "    # removal of @name[mention]\n",
        "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
        "    tweet_name = tweet_space.str.replace(regex_pat, '')\n",
        "\n",
        "    # removal of links[https://abc.com]\n",
        "    giant_url_regex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    tweets = tweet_name.str.replace(giant_url_regex, '')\n",
        "    # removal of punctuations and numbers\n",
        "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \") \n",
        "    # remove whitespace with a single space\n",
        "    newtweet=punc_remove.str.replace(r'\\s+', ' ')                   \n",
        "    # remove leading and trailing whitespace \n",
        "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
        "    # replace normal numbers with number  \n",
        "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
        " \n",
        "    # tokenizing\n",
        "    tokenized_tweet = newtweet.apply(lambda x: x.split()) \n",
        "    \n",
        " \n",
        "    for i in range(len(tokenized_tweet)):\n",
        "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "        tweets_p= tokenized_tweet\n",
        "    \n",
        "    return tweets_p\n",
        "   \n",
        "processed_tweets = preprocess(dataset['tweet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vXqbliyfCWJy"
      },
      "outputs": [],
      "source": [
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(processed_tweets):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = nlp(processed_tweets)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words ]\n",
        "\n",
        "    # return preprocessed tokens\n",
        "    return ' '.join(mytokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDDW1rRdCWJy",
        "outputId": "8458fbf3-bcb4-4e3e-e630-7fce950042b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 21s, sys: 775 ms, total: 3min 22s\n",
            "Wall time: 3min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "dataset['final_tweet'] = processed_tweets.apply(lambda x: spacy_tokenizer(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oGr95MlvCWJy",
        "outputId": "ea97c09b-80e6-4683-f088-a52e0a09ed59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0           0      3            0                   0        3      2   \n",
              "1           1      3            0                   3        0      1   \n",
              "2           2      3            0                   3        0      1   \n",
              "3           3      3            0                   2        1      1   \n",
              "4           4      6            0                   6        0      1   \n",
              "\n",
              "                                               tweet  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
              "\n",
              "                                         final_tweet  \n",
              "0  woman shouldn t complain clean house amp man t...  \n",
              "1  boy dats cold tyga dwn bad cuffin dat hoe st p...  \n",
              "2             dawg fuck bitch start cry confuse shit  \n",
              "3                                   look like tranny  \n",
              "4                 shit hear true faker bitch tell ya  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e23248-2320-437b-a2cc-d071665d651e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>final_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>woman shouldn t complain clean house amp man t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>boy dats cold tyga dwn bad cuffin dat hoe st p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>dawg fuck bitch start cry confuse shit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>shit hear true faker bitch tell ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e23248-2320-437b-a2cc-d071665d651e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28e23248-2320-437b-a2cc-d071665d651e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28e23248-2320-437b-a2cc-d071665d651e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRLKU3PACWJz"
      },
      "source": [
        "# TF - IDF   Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25hL-9IDCWJz"
      },
      "source": [
        "TF-IDF weight is composed by two terms: the first computes the normalized Term Frequency (TF), aka. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
        "\n",
        "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
        "\n",
        "* TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
        "\n",
        "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
        "\n",
        "* IDF(t) = log_e(Total number of documents / Number of documents with term t in it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Il1f-zfCWJz",
        "outputId": "e0b5af85-e604-4ed3-b42b-739c404765f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<24783x15000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 189755 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "final_tweet = dataset['final_tweet']\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_features=15000)\n",
        "\n",
        "# TF-IDF feature matrix\n",
        "tfidf = tfidf_vectorizer.fit_transform(final_tweet)\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FJDpvs_xCWJ0"
      },
      "outputs": [],
      "source": [
        "X = tfidf # the features we want to analyze\n",
        "y = dataset['class'] # the labels, or answers, we want to test against"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = X.toarray()\n",
        "dense_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epnSw-VZt80U",
        "outputId": "e18646d4-4608-40c6-850a-880f5aee8da8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24783, 15000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3VM8njdCWJ0"
      },
      "source": [
        "Stratified k-fold cross-validation\n",
        "==========================\n",
        "Specifically, we can split a dataset randomly, although in such a way that maintains the same class distribution in each subset. This is called stratification or stratified sampling and the target variable (y), the class, is used to control the sampling process.\n",
        "\n",
        "For example, we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called stratified k-fold cross-validation and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.\n",
        "\n",
        "It is common, in the case of class imbalances in particular, to use stratified 10-fold cross-validation, which ensures that the proportion of positive to negative examples found in the original distribution is respected in all the folds."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = dense_matrix[:2000]\n",
        "y_train = dataset['class'][:2000]\n",
        "X_test = dense_matrix[2000:2200]\n",
        "y_test = dataset['class'][2000:2200]"
      ],
      "metadata": {
        "id": "2e70PBaeuJcA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vguWYpF0CWJ0"
      },
      "source": [
        "# Running the models Using TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s9_PskiVUeT"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_hHOysHVhjh"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGi8qxtnVozi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7419b1c-a798-4fed-f2bf-3adf46249c90"
      },
      "source": [
        "%%time\n",
        "lr.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 3s, sys: 4.24 s, total: 3min 8s\n",
            "Wall time: 3min 13s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y24-BsmzSkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a838f2-5e72-4f22-8785-fc16408a1c1a"
      },
      "source": [
        "%%time\n",
        "print('Model LogisticRegression' + ' ' + str(lr.score(X_test, y_test)))\n",
        "print('Model RandomForestClassifier' + ' ' + str(rf.score(X_test, y_test)))\n",
        "print('Model XGBClassifier' + ' ' + str(xgb.score(X_test, y_test)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model OLS 0.815\n",
            "Model EL 0.855\n",
            "Model RF 0.925\n",
            "CPU times: user 151 ms, sys: 113 ms, total: 264 ms\n",
            "Wall time: 149 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiMgw83BCWJ0"
      },
      "source": [
        "# Word2vec Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smlBjM1UCWJ0"
      },
      "source": [
        "* Word2vec groups the vector of similar words together in the vector space.\n",
        "* That is it detects similarities mathematically.\n",
        "* Given enough data, usage and contexts, word2vec can make highly accurate guesses about a word’s meaning based on past           appearances.\n",
        "* Those guesses can be used to establish a word’s association with other words eg. “man” is to “boy” what “woman” is to “girl”.\n",
        "* Each word is represented by a vector and in spaCy each vector has 300 dimensions [300 different properties associated,helpful while similarity matching]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V4RbB-LfCWJ1"
      },
      "outputs": [],
      "source": [
        "def get_vec(x):\n",
        "  doc = nlp(x)\n",
        "  return doc.vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Compute the sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for index, row in dataset.iterrows():\n",
        "  sentence_embeddings.append(get_vec(row['final_tweet']))\n",
        "\n",
        "# Convert the sentence embeddings to a tensor\n",
        "sentence_embeddings = np.stack(sentence_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAK-E8IQK3FJ",
        "outputId": "bae6d770-6cdd-4144-e2d8-57f99fb3e5ef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 56s, sys: 749 ms, total: 2min 57s\n",
            "Wall time: 3min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = sentence_embeddings[:2000]\n",
        "y_train = dataset['class'][:2000]\n",
        "X_test = sentence_embeddings[2000:2200]\n",
        "y_test = dataset['class'][2000:2200]"
      ],
      "metadata": {
        "id": "SWQNdDjfyo51"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kqClY0LCWJ2"
      },
      "source": [
        "# Running the models Using Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3dolhuQygrB"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205207ad-d907-4a4c-fc4e-97657b19e5a7",
        "id": "7k5gDEesygrB"
      },
      "source": [
        "%%time\n",
        "lr.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.2 s, sys: 295 ms, total: 13.5 s\n",
            "Wall time: 13.7 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fcdc8c-46d6-44d2-a5d3-c99e05426e44",
        "id": "cX-XYk2CygrC"
      },
      "source": [
        "%%time\n",
        "print('Model LogisticRegression' + ' ' + str(lr.score(X_test, y_test)))\n",
        "print('Model RandomForestClassifier' + ' ' + str(rf.score(X_test, y_test)))\n",
        "print('Model XGBClassifier' + ' ' + str(xgb.score(X_test, y_test)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model LogisticRegression 0.78\n",
            "Model RandomForestClassifier 0.815\n",
            "Model XGBClassifier 0.82\n",
            "CPU times: user 24.5 ms, sys: 2.01 ms, total: 26.5 ms\n",
            "Wall time: 27.2 ms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}