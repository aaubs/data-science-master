{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_LSTM_stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTzQB9K6z16l"
      },
      "source": [
        "# Time Series with LSTM\n",
        "\n",
        "In this notebook we will be using an LSTM architecture to work with stock price (change) prediciton.\n",
        "We will first look at simple 1-step ahead prediction, then at multi-step and finally at multi-step multi-feature prediction, and finally evaluate the performance of the model using a \"naive backtesting\" approach. Here the question is: How much money would we have gained/lost if we followed the predictions of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tB2kQhsLEeB"
      },
      "outputs": [],
      "source": [
        "# First: Let's install the data-reader to get some current stock prices\n",
        "!pip install --upgrade pandas-datareader -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA5uiCmHLYdU"
      },
      "outputs": [],
      "source": [
        "# Import basic packaging\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from pandas_datareader import data as pdr\n",
        "import datetime as dt\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR9hJ3HpLydb"
      },
      "outputs": [],
      "source": [
        "# set timeframe for data extraction\n",
        "\n",
        "start = dt.datetime(2021,1,1)\n",
        "end = dt.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7adBExy_MHSi"
      },
      "outputs": [],
      "source": [
        "# get the data\n",
        "\n",
        "data =  pdr.DataReader(\"^OMXC25\",'yahoo', start=start, end=end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u89CWh1MU4Q"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_avSkRTjMu-S"
      },
      "outputs": [],
      "source": [
        "# calculate diffs - changes to previous period\n",
        "data_diff = data.diff()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGzxsI7qvIWS"
      },
      "outputs": [],
      "source": [
        "# alternatively\n",
        "#data_diff = data.pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udHpeZFVM_3O"
      },
      "outputs": [],
      "source": [
        "data_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Wec1ipz16q"
      },
      "source": [
        "Here we will be using diffs to predict diffs ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2C-YyoUNJD7"
      },
      "outputs": [],
      "source": [
        "# import packaging for Neural Net\n",
        "import math\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqReYP9oz16q"
      },
      "source": [
        "We willpreprocess the data by MinMax scaling between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmnsUdhWOKkU"
      },
      "outputs": [],
      "source": [
        "# normalizing\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_diff['Adj_Close_scaled'] = scaler.fit_transform(data_diff['Adj Close'].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huw77V99O05O"
      },
      "outputs": [],
      "source": [
        "# create targets by shifting\n",
        "data_diff['Adj_Close_scaled+1'] = data_diff.Adj_Close_scaled.shift(-1, fill_value=data_diff.Adj_Close_scaled.iloc[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpRHGChKPZ8P"
      },
      "outputs": [],
      "source": [
        "# get the data as matrix\n",
        "data_p = data_diff.iloc[1:,6:].values.astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxTm6kUjz16r"
      },
      "source": [
        "This is how our dataframe looks. X is change in t; y is change in t+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4sfgJ-FPcBD"
      },
      "outputs": [],
      "source": [
        "data_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq4gVp4nz16s"
      },
      "source": [
        "We will use a manual split. We cannot shuffle anything...because time ðŸ˜…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qI3gImKP55k"
      },
      "outputs": [],
      "source": [
        "# split into train and test sets\n",
        "train_size = int(len(data_p) * 0.67)\n",
        "test_size = len(data_p) - train_size\n",
        "\n",
        "train, test = data_p[0:train_size,:], data_p[train_size:len(data_p),:]\n",
        "print(len(train), len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtBl-D8gQUIK"
      },
      "outputs": [],
      "source": [
        "X_train = train[:,0]\n",
        "y_train = train[:,1]\n",
        "\n",
        "X_test = test[:,0]\n",
        "y_test = test[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA4ngx6Bz16s"
      },
      "source": [
        "To work with Keras, we need to bring data into a 3D (tensor) format\n",
        "samples here means lenght of the series; time steps = how much do we look back; features: how many variables are there in our X?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB1pmH7QQhJr"
      },
      "outputs": [],
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zyb-mWZRFUi"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1BRGgBmwqSZ"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtxTz_4-z16t"
      },
      "source": [
        "## 1-step LSTM\n",
        "\n",
        "We start with a smile net with 4 LSTM cells. The output layer has 1 neuron (because it's a regression problem with one outcome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6-dl2R_RURk"
      },
      "outputs": [],
      "source": [
        "# build the network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EneTng5RdwJ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORP4gUuIR2pX"
      },
      "outputs": [],
      "source": [
        "# let's fit the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=20, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2a934RhR-RX"
      },
      "outputs": [],
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(X_train)\n",
        "testPredict = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q761wpgMSOkM"
      },
      "outputs": [],
      "source": [
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "y_train = scaler.inverse_transform([y_train])\n",
        "\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "y_test = scaler.inverse_transform([y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrbaZv2NShSW"
      },
      "outputs": [],
      "source": [
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(y_train[0], trainPredict[:,0]))\n",
        "print('Train Score: %.4f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(y_test[0], testPredict[:,0]))\n",
        "print('Test Score: %.4f RMSE' % (testScore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ3jnKy7SjDM"
      },
      "outputs": [],
      "source": [
        "data_diff['Adj_close_pred'] = data_diff['Adj Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8wbgl4hS5M0"
      },
      "outputs": [],
      "source": [
        "data_diff['Adj_close_pred'].iloc[-testPredict.shape[0]:] = testPredict.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLeu7H7rS89u"
      },
      "outputs": [],
      "source": [
        "data_diff.loc[:,['Adj Close','Adj_close_pred']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBwFMfwFz16v"
      },
      "source": [
        "Our network is a Chicken...doesn't dare to make real change predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ao-H0x8TLra"
      },
      "outputs": [],
      "source": [
        "# let's look at the sign for the \"mini momevements\" that are produced\n",
        "pred_sign = pd.DataFrame(zip(testPredict.flatten(), y_test.flatten())) > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THSxX3vPz16w"
      },
      "source": [
        "Basically: True if > 0, else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTRiDxRjT-se"
      },
      "outputs": [],
      "source": [
        "pred_sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHrTqlYpz16w"
      },
      "source": [
        "What's the share where the predicted sign (direction of change) was the same as reality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUVzgABITpV0"
      },
      "outputs": [],
      "source": [
        "(pred_sign[0] == pred_sign[1]).sum()/len(pred_sign)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb3fxeXQUhlr"
      },
      "source": [
        "## Introducing multi-step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNXa41p8UfWo"
      },
      "outputs": [],
      "source": [
        "# convert an array of values into a dataset matrix (convenience function to fiddle less around)\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEc9xTn3VlnU"
      },
      "outputs": [],
      "source": [
        "# reshape into X=t and Y=t+1\n",
        "look_back = 5\n",
        "X_train, y_train = create_dataset(train, look_back)\n",
        "X_test, y_test = create_dataset(test, look_back)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg4nG0H3V0mz"
      },
      "outputs": [],
      "source": [
        "# build the network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(16, input_shape=(look_back, 1), return_sequences=True))\n",
        "model.add(LSTM(4, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm4XHnY6WsqB"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9OUHUUdWvEP"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDSTPvtCWzNN"
      },
      "outputs": [],
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(X_train)\n",
        "testPredict = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSbHLsarW7r2"
      },
      "outputs": [],
      "source": [
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "y_train = scaler.inverse_transform([y_train])\n",
        "\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "y_test = scaler.inverse_transform([y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evgsQzu7W99a"
      },
      "outputs": [],
      "source": [
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(y_train[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(y_test[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnncZ6QcXAW6"
      },
      "outputs": [],
      "source": [
        "data_diff['Adj_close_pred'] = data_diff['Adj Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwDqk1QdXJP6"
      },
      "outputs": [],
      "source": [
        "data_diff['Adj_close_pred'].iloc[-testPredict.shape[0]:] = testPredict.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhVXIEJeXKtz"
      },
      "outputs": [],
      "source": [
        "data_diff.loc[:,['Adj_close_pred']].plot()\n",
        "data_diff.loc[:,['Adj Close']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r64XAfWnXNqc"
      },
      "outputs": [],
      "source": [
        "pred_sign = pd.DataFrame(zip(testPredict.flatten(), y_test.flatten())) > 0\n",
        "(pred_sign[0] == pred_sign[1]).sum()/len(pred_sign)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-step & Multi-feature\n",
        "Let's use the built in time-series-generator for a bit more compelx case\n",
        "We are going to predict ETH change from the scaled values of BTC, ADA, DOGE and BNB."
      ],
      "metadata": {
        "id": "iIRnWsIc0xlQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qljrcnLibT16"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoUW3fP0_0G1"
      },
      "outputs": [],
      "source": [
        "start = dt.datetime(2022,5,1)\n",
        "end = dt.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dj9YfN3bnNx"
      },
      "outputs": [],
      "source": [
        "ETH =  pdr.DataReader('ETH-USD','yahoo', start=start, end=end)\n",
        "BTC =  pdr.DataReader('BTC-USD','yahoo', start=start, end=end)\n",
        "ADA =  pdr.DataReader('ADA-USD','yahoo', start=start, end=end)\n",
        "DOGE =  pdr.DataReader('DOGE-USD','yahoo', start=start, end=end)\n",
        "BNB =  pdr.DataReader('BNB-USD','yahoo', start=start, end=end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2RMhcN6b1tK"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({'ETH':ETH['Adj Close'], \n",
        "                     'BTC':BTC['Adj Close'], \n",
        "                     'ADA':ADA['Adj Close'], \n",
        "                     'DOGE': DOGE['Adj Close'], \n",
        "                     'BNB':BNB['Adj Close']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvz5Y7dGcNaI"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aybyZJ8Yca9x"
      },
      "outputs": [],
      "source": [
        "data = data.sort_index(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5snrz0rcw2Z"
      },
      "outputs": [],
      "source": [
        "data['ETH_shift'] = data['ETH'].shift(-1, fill_value=data['ETH'].iloc[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh7S167Zc1ou"
      },
      "outputs": [],
      "source": [
        "test_size = int(len(data) * 0.2) # the test data will be 20% (0.2) of the entire data\n",
        "train = data.iloc[:-test_size,:].copy() \n",
        "# the copy() here is important, it will prevent us from getting: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_index,col_indexer] = value instead\n",
        "test = data.iloc[-test_size:,:].copy()\n",
        "print(train.shape, test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GcTTjPweGEv"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FESbECJRdLcP"
      },
      "outputs": [],
      "source": [
        "X_train = train.iloc[:,:5].values\n",
        "y_train = train.iloc[:,5].values\n",
        "\n",
        "X_test = test.iloc[:,:5].values\n",
        "y_test = test.iloc[:,5].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ScWy-ivdw4D"
      },
      "outputs": [],
      "source": [
        "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hJfAUrd1ia"
      },
      "outputs": [],
      "source": [
        "X_train = x_scaler.fit_transform(X_train)\n",
        "y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
        "\n",
        "X_test = x_scaler.transform(X_test)\n",
        "y_test = y_scaler.transform(y_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f38OnhYCd6SJ"
      },
      "outputs": [],
      "source": [
        "n_input = 5 #how many samples/rows/timesteps to look in the past in order to forecast the next sample\n",
        "n_features= X_train.shape[1] # how many predictors/Xs/features we have to predict y\n",
        "b_size = 32 # Number of timeseries samples in each batch\n",
        "generator = TimeseriesGenerator(X_train, y_train, length=n_input, batch_size=b_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrKisnQdd9F3"
      },
      "outputs": [],
      "source": [
        "print(generator[0][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni5N-z0jeZ7-"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(150, activation='relu', input_shape=(n_input, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlappIDSefyR"
      },
      "outputs": [],
      "source": [
        "model.fit(generator,epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPEQYWO0e7Kc"
      },
      "outputs": [],
      "source": [
        "loss_per_epoch = model.history.history['loss']\n",
        "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp61kkaMe_Ng"
      },
      "outputs": [],
      "source": [
        "test_generator = TimeseriesGenerator(X_test, np.zeros(len(X_test)), length=n_input, batch_size=b_size)\n",
        "print(test_generator[0][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgp9GlJ6fCRB"
      },
      "outputs": [],
      "source": [
        "y_pred_scaled = model.predict(test_generator)\n",
        "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
        "y_test = y_scaler.inverse_transform(y_test)\n",
        "results = pd.DataFrame({'y_true':y_test.flatten()[n_input:],'y_pred':y_pred.flatten()})\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV8XnDrhfLsO"
      },
      "outputs": [],
      "source": [
        "results.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99YdEx1RfZK7"
      },
      "outputs": [],
      "source": [
        "pred_sign = results.diff(1) > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuVYv3k_jF18"
      },
      "outputs": [],
      "source": [
        "pred_sign.y_true == pred_sign.y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RfOAUVlmYkQ"
      },
      "outputs": [],
      "source": [
        "(pred_sign.y_true == pred_sign.y_pred).sum()/len(pred_sign)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvGS4IiyCKrU"
      },
      "source": [
        "## From here some experimental backtesting..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqauAUS-iNCS"
      },
      "outputs": [],
      "source": [
        "data['prediction'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcGpvP6QiAPQ"
      },
      "outputs": [],
      "source": [
        "data['prediction'][-len(results.diff(1).y_pred):] = results.diff(1).y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCFnOOZ9iovD"
      },
      "outputs": [],
      "source": [
        "data['signal'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj55kR8rikAx"
      },
      "outputs": [],
      "source": [
        "data['signal'][-len(results.diff(1).y_pred):] = [-1 if i <= 0 else 1 for i in results.diff(1).y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QF2qljLJY1d"
      },
      "outputs": [],
      "source": [
        "data['ETH_diff'] = data['ETH'].diff(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd7n8vZslVlT"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYeYbxfvmau9"
      },
      "outputs": [],
      "source": [
        "data['signal_adj'] = data.apply(lambda t: 0 if abs(t['prediction']) < 0.02 else t['signal'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0Idqge_nPUJ"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7_tZp4DGDdW"
      },
      "outputs": [],
      "source": [
        "# Set the initial capital\n",
        "initial_capital= float(10000.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2O1YAfKHPqh"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame `positions`\n",
        "positions = pd.DataFrame(index=data.index).fillna(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qp26Q05lr_Z"
      },
      "outputs": [],
      "source": [
        "# Buy a 100 shares\n",
        "positions['ETH'] = 10*data['signal_adj']   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D-UXxrZlzDu"
      },
      "outputs": [],
      "source": [
        "# Initialize the portfolio with value owned   \n",
        "portfolio = positions.multiply(data['ETH'], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N552WDzm2f4L"
      },
      "outputs": [],
      "source": [
        "# Store the difference in shares owned \n",
        "pos_diff = positions.diff()\n",
        "\n",
        "# Add `holdings` to portfolio\n",
        "portfolio['holdings'] = (positions.multiply(data['ETH'], axis=0)).sum(axis=1)\n",
        "\n",
        "# Add `cash` to portfolio\n",
        "portfolio['cash'] = initial_capital - (pos_diff.multiply(data['ETH'], axis=0)).sum(axis=1).cumsum()   \n",
        "\n",
        "# Add `total` to portfolio\n",
        "portfolio['total'] = portfolio['cash'] + portfolio['holdings']\n",
        "\n",
        "# Add `returns` to portfolio\n",
        "portfolio['returns'] = portfolio['total'].pct_change()\n",
        "\n",
        "# Print the first lines of `portfolio`\n",
        "print(portfolio.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqbemF4pmEO_"
      },
      "outputs": [],
      "source": [
        "# Print the last lines of `portfolio`\n",
        "portfolio.tail() "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EtxTz_4-z16t"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}