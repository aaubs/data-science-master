{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddwGX2J0BPPj"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This tutorial guides you through the process of downloading a podcast, transcribing it, analyzing its content, and generating blog posts based on the key topics discussed. We'll use various AI models, starting with local models via Ollama and then moving to more powerful models using the Together API.\n",
        "\n",
        "## Part 1: Podcast Transcription\n",
        "\n",
        "### Step 1: Set up the environment\n",
        "\n",
        "First, we need to install the necessary libraries. Run this cell to install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_aq0y8gBPPm"
      },
      "source": [
        "!pip install faster-whisper openai ollama pydub tqdm -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59SDHS27BPPn"
      },
      "source": [
        "### Step 2: Import required libraries\n",
        "\n",
        "Now, let's import the libraries we'll be using throughout this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQgcFdNFBPPn"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "import openai\n",
        "import subprocess\n",
        "import threading\n",
        "from IPython.display import clear_output, HTML\n",
        "from faster_whisper import WhisperModel\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n",
        "import ollama"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSJ304sCBPPo"
      },
      "source": [
        "### Step 3: Download the podcast\n",
        "\n",
        "We'll download a podcast episode and save it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgYt8IqPBPPo"
      },
      "source": [
        "url = \"https://pdst.fm/e/traffic.megaphone.fm/SCIM6504498504.mp3?updated=1712126745\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the file locally\n",
        "with open(\"podcast.mp3\", \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "print(\"Download complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqPOKbsTBPPo"
      },
      "source": [
        "### Step 4: Transcribe the podcast\n",
        "\n",
        "Now we'll transcribe the downloaded podcast using the Whisper model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5fRMDPeBPPo"
      },
      "source": [
        "def transcribe_with_progress(audio_path, output_json=\"transcription.json\"):\n",
        "    # Load the audio file to get its duration\n",
        "    print(\"Loading audio file to determine duration...\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    total_duration = len(audio) / 1000.0  # Convert milliseconds to seconds\n",
        "    print(f\"Total audio duration: {total_duration:.2f} seconds\")\n",
        "\n",
        "    # Initialize the Whisper model\n",
        "    print(\"Initializing Whisper model...\")\n",
        "    model_size = \"distil-large-v3\"\n",
        "    model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "    # Perform transcription\n",
        "    print(\"Starting transcription...\")\n",
        "    segments, info = model.transcribe(\n",
        "        audio_path,\n",
        "        beam_size=5,\n",
        "        language=\"en\",\n",
        "        condition_on_previous_text=False\n",
        "    )\n",
        "\n",
        "    # Process segments and save to JSON\n",
        "    transcription = []\n",
        "    pbar = tqdm(total=100, desc=\"Transcribing Progress\", unit=\"%\")\n",
        "    last_progress = 0\n",
        "\n",
        "    for segment in segments:\n",
        "        progress = min((segment.end / total_duration) * 100, 100)\n",
        "        delta = max(progress - last_progress, 0)\n",
        "        pbar.update(delta)\n",
        "        last_progress = progress\n",
        "\n",
        "        transcription.append({\n",
        "            \"start\": segment.start,\n",
        "            \"end\": segment.end,\n",
        "            \"text\": segment.text\n",
        "        })\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    # Save the transcription to a JSON file\n",
        "    with open(output_json, 'w') as f:\n",
        "        json.dump(transcription, f, indent=4)\n",
        "\n",
        "    print(f\"Transcription saved to {output_json}\")\n",
        "\n",
        "# Example usage\n",
        "transcribe_with_progress('podcast.mp3', output_json=\"transcription.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCX5IfK0BPPo"
      },
      "source": [
        "## Part 2: Introduction to Ollama\n",
        "\n",
        "### Step 5: Install and Set up Ollama\n",
        "\n",
        "Ollama allows us to run AI models locally. Let's install and set it up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upiPC44PBPPp"
      },
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le16dYNuBPPp"
      },
      "source": [
        "Now, let's start the Ollama server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RFc7x5cBPPp"
      },
      "source": [
        "def start_ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=start_ollama)\n",
        "ollama_thread.start()\n",
        "\n",
        "clear_output()\n",
        "print(\"Ollama server started\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to download a model. In colab it's best to open the terminal and type `ollama run qwen2.5` (Qwen seems right now the best model small where it comes to dealing with long context...)"
      ],
      "metadata": {
        "id": "Bo2_hjuHB6as"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t3mRCeABPPp"
      },
      "source": [
        "### Step 6: Basic Ollama Usage\n",
        "\n",
        "Let's try out Ollama with a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq78jdm-BPPp"
      },
      "source": [
        "# Set up the Ollama chat call\n",
        "response = ollama.chat(\n",
        "    model='qwen2.5',\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You answer everything as if you were a pirate.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What do you think about Aalborg? Just 1 sentence.\",\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Extract and print the response\n",
        "chat_completion = response['message']['content']\n",
        "print(chat_completion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dbdCrclBPPq"
      },
      "source": [
        "## Part 3: Podcast Analysis with Ollama\n",
        "\n",
        "### Step 7: Define JSON structure template\n",
        "\n",
        "Before we analyze the transcript, let's define the JSON structure we want for our output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yVcPDZgBPPq"
      },
      "source": [
        "structure_template = \"\"\"{\n",
        "  \"keyTopics\": [\n",
        "    {\n",
        "      \"name\": \"\", // Title or name of the key topic (e.g., Deep Work)\n",
        "      \"description\": \"\", // A longer description explaining the core idea and its importance in more detail\n",
        "      \"keyPoints\": [\n",
        "        \"\", // Major point 1 discussed under this topic\n",
        "        \"\", // Major point 2\n",
        "        \"\"  // Major point 3\n",
        "      ],\n",
        "      \"actionableStrategy\": {\n",
        "        \"name\": \"\", // Name of the practical strategy or technique\n",
        "        \"steps\": [\n",
        "          \"\", // Specific step or instruction 1\n",
        "          \"\", // Specific step or instruction 2\n",
        "          \"\"  // Specific step or instruction 3\n",
        "        ]\n",
        "      },\n",
        "      \"relatedQuote\": {\n",
        "        \"text\": \"\", // Exact quote from the conversation relevant to this topic\n",
        "        \"context\": \"\" // Brief context explaining when and why this quote was mentioned\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"\", // Another key topic\n",
        "      \"description\": \"\", // A longer description for this topic\n",
        "      \"keyPoints\": [\n",
        "        \"\", // Major point 1\n",
        "        \"\", // Major point 2\n",
        "        \"\"  // Major point 3\n",
        "      ],\n",
        "      \"actionableStrategy\": {\n",
        "        \"name\": \"\",\n",
        "        \"steps\": [\n",
        "          \"\",\n",
        "          \"\",\n",
        "          \"\"\n",
        "        ]\n",
        "      },\n",
        "      \"relatedQuote\": {\n",
        "        \"text\": \"\",\n",
        "        \"context\": \"\"\n",
        "      }\n",
        "    }\n",
        "    // Add additional key topics following this structure\n",
        "  ]\n",
        "} \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8hy2wiDBPPq"
      },
      "source": [
        "### Step 8: Analyze the transcript\n",
        "\n",
        "Now we'll use Ollama to analyze the transcript and extract key topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebIpFQkVBPPr"
      },
      "source": [
        "# Load the transcript\n",
        "with open('transcription.json') as f:\n",
        "    transcript_json = json.load(f)\n",
        "\n",
        "# Extract the text from each transcript segment\n",
        "transcript_text = [segment['text'] for segment in transcript_json]\n",
        "\n",
        "# Join all the extracted text into a single string\n",
        "full_transcript = ' '.join(transcript_text)\n",
        "\n",
        "# Set up the Ollama chat call\n",
        "response = ollama.chat(\n",
        "    model='qwen2.5',\n",
        "    format='json',\n",
        "    options=dict(temperature=0.3),\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"Your task is to assist in analyzing podcast transcripts to extract a maximum of 3 central discussions for writing blog posts. In addition to extracting key topics, abstract the discussion to capture the bigger picture and underlying themes. Focus on identifying major trends, patterns, or overarching messages that would be valuable in creating engaging blog posts. Make sure the identified topics provide deep insights that resonate with broader themes and offer readers practical takeaways.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Analyze the following podcast transcript and abstract the discussion to identify 2-3 key topics. Look for bigger-picture themes that go beyond the specifics of the conversation. Ensure that each topic is explained clearly, includes key points, actionable strategies, and relevant quotes. Focus on providing a higher-level understanding that would support writing compelling blog posts. The transcript to process is: {full_transcript}. Use this structure to guide the extraction: {structure_template}. DO NOT INVENT THINGS! STICK TO THE TRANSCRIPT!\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Extract and print the response\n",
        "chat_completion = response['message']['content']\n",
        "print(chat_completion)\n",
        "\n",
        "# Convert to structured data\n",
        "structure_extract = json.loads(chat_completion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSpzSI2BPPr"
      },
      "source": [
        "### Step 9: Generate blog posts with Ollama\n",
        "\n",
        "Let's use the analysis results to generate blog posts for each key topic."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "def format_structure_name(topic):\n",
        "    return topic['name'].replace(\" \", \"_\").lower()\n",
        "\n",
        "# Convert to structured text - to not confuse the model with the \"json-input\"\n",
        "def format_structure(data):\n",
        "    result = f\"Title: {data['name']}\\n\"\n",
        "    result += f\"Description: {data['description']}\\n\\n\"\n",
        "\n",
        "    result += \"Key Points:\\n\"\n",
        "    for point in data['keyPoints']:\n",
        "        result += f\" - {point}\\n\"\n",
        "\n",
        "    result += f\"\\nActionable Strategy: {data['actionableStrategy']['name']}\\n\"\n",
        "    result += \"Steps:\\n\"\n",
        "    for step in data['actionableStrategy']['steps']:\n",
        "        result += f\"  * {step}\\n\"\n",
        "\n",
        "    result += f\"\\nRelated Quote: \\\"{data['relatedQuote']['text']}\\\"\\n\"\n",
        "    result += f\"Context: {data['relatedQuote']['context']}\\n\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "ls65yGUvISKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4fRUyQUBPPr"
      },
      "source": [
        "# Iterate over each theme using tqdm for progress tracking\n",
        "for index, topic in enumerate(tqdm(structure_extract['keyTopics']), 1):\n",
        "    # Using the theme name formatting function\n",
        "    theme_name = format_structure_name(topic)\n",
        "\n",
        "    # Using the format function for the JSON\n",
        "\n",
        "    theme= format_structure(topic)\n",
        "\n",
        "    # Create the Ollama chat call for each theme\n",
        "    response = ollama.chat(\n",
        "        model='qwen2.5',\n",
        "        options=dict(temperature=0.3),\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a lifestyle blogger writing an article based on a provided podcast transcript. Your task is to create a blog post that flows naturally, avoids being overly segmented, and feels organic while strictly adhering to the content in the transcript. Avoid bullet points and subsections unless absolutely necessary. The blog post should feel like a cohesive narrative that smoothly incorporates ideas from the transcript. No external tools, frameworks, or additional sources should be referenced, and all ideas must come from the transcript. The tone should be professional but engaging, without falling into repetitive or mechanical language.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"The transcript for reference is: {full_transcript}. ### YOUR JOB ### Write a blog post based on the following theme: {theme}. Only use content from the transcript—do not add anything not mentioned. The post should read naturally, with a smooth narrative flow, staying professional and informative while adhering strictly to the transcript content. Write enough content to fill one A4 page.\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the blog post content from the response\n",
        "    chat_completion = response['message']['content']\n",
        "\n",
        "    # Create a filename based on index and formatted theme name\n",
        "    filename = f\"{index}_{theme_name}.md\"\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_dir = \"output_folder\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Write the blog post content to a markdown file\n",
        "    with open(os.path.join(output_dir, filename), 'w') as f:\n",
        "        f.write(chat_completion)\n",
        "\n",
        "    print(f\"Saved: {filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0lb4qYbBPPr"
      },
      "source": [
        "## Part 4: Using a More Powerful Model with Together API\n",
        "\n",
        "### Step 10: Set up Together API\n",
        "\n",
        "Now, let's use a more powerful model through the Together API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37nkQrJ7BPPs"
      },
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Setup OpenAI client with custom API key and base URL\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\",\n",
        "    api_key=TOGETHER_API_KEY\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMBVj0KBPPs"
      },
      "source": [
        "### Step 11: Analyze transcript with Together API\n",
        "\n",
        "We'll use the Together API to perform a more sophisticated analysis of the transcript."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arLC0yqrBPPs"
      },
      "source": [
        "# Set up the OpenAI chat call\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model='meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an AI model tasked with assisting in analyzing podcast transcripts to extract a maximum of 3 central discussions for writing blog posts. In addition to extracting key topics, abstract the discussion to capture the bigger picture and underlying themes. Focus on identifying major trends, patterns, or overarching messages that would be valuable in creating engaging blog posts. Make sure the identified topics provide deep insights that resonate with broader themes and offer readers practical takeaways.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Analyze the following podcast transcript and abstract the discussion to identify 2-3 key topics. Look for bigger-picture themes that go beyond the specifics of the conversation. Ensure that each topic is explained clearly, includes key points, actionable strategies, and relevant quotes. Focus on providing a higher-level understanding that would support writing compelling blog posts. The transcript to process is: {full_transcript}. Use this structure to guide the extraction: {structure_template}. DO NOT INVENT THINGS! STICK TO THE TRANSCRIPT!\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "# Extract and print the response\n",
        "extracted_output = json.loads(chat_completion.choices[0].message.content)\n",
        "print(json.dumps(extracted_output, ensure_ascii=False, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enm5jj_oBPPs"
      },
      "source": [
        "### Step 12: Generate blog posts with Together API\n",
        "\n",
        "Finally, we'll use the Together API to generate more sophisticated blog posts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGbp9ClHBPPs"
      },
      "source": [
        "# Iterate over each theme using tqdm for progress tracking\n",
        "for index, topic in enumerate(tqdm(extracted_output['keyTopics']), 1):\n",
        "    # Using the theme name formatting function\n",
        "    theme_name = format_structure_name(topic)\n",
        "\n",
        "    # Using the format function for the JSON\n",
        "    theme = format_structure(topic)\n",
        "\n",
        "    # Set up the OpenAI chat call\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model='meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a lifestyle blogger writing an article based on a provided \"\n",
        "                    \"podcast transcript. Your task is to create a blog post that flows naturally, \"\n",
        "                    \"avoids being overly segmented, and feels organic while strictly adhering to the \"\n",
        "                    \"content in the transcript. Avoid bullet points and too many subsections unless absolutely necessary. \"\n",
        "                    \"The blog post should feel like a cohesive narrative that smoothly incorporates ideas from the transcript. \"\n",
        "                    \"No external tools, frameworks, or additional sources should be referenced, and all ideas must come from the transcript. \"\n",
        "                    \"The tone should be professional but engaging, without falling into repetitive or mechanical language. Use markdown in your output.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    f\"The transcript for reference is: {full_transcript}. ### YOUR JOB ### \"\n",
        "                    f\"Write a blog post based on the following theme: {theme}. Only use content from the transcript—\"\n",
        "                    \"do not add anything not mentioned. The post should read naturally, with a smooth narrative flow, staying professional \"\n",
        "                    \"and informative while adhering strictly to the transcript content. Write enough content to fill 2 A4 pages.\"\n",
        "                )\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    # Extract the blog post content from the response\n",
        "    chat_completion = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Create a filename based on index and formatted theme name\n",
        "    filename = f\"{index}_{theme_name}.md\"\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_dir = \"output_folder_together\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Write the blog post content to a markdown file\n",
        "    with open(os.path.join(output_dir, filename), 'w') as f:\n",
        "        f.write(chat_completion)\n",
        "\n",
        "    print(f\"Saved: {filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2E8YenMBPPt"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we've learned how to:\n",
        "1. Download and transcribe a podcast\n",
        "2. Set up and use Ollama for local AI model inference\n",
        "3. Analyze podcast transcripts and generate blog posts using Ollama\n",
        "4. Use the Together API for more sophisticated analysis and blog post generation\n",
        "\n",
        "This workflow demonstrates the power of AI in content analysis and creation, and how different models can be used for various levels of sophistication in the results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Image generation\n",
        "\n",
        "For the next 3 months Together is offering Flux1 Schnell for free..."
      ],
      "metadata": {
        "id": "eufxsBqRJFsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.images.generate(\n",
        "    prompt=\"\"\"An illustration of a focused individual at a retro wooden desk, deep in concentration with an open book and typewriter. The office has a mid-century modern design, with muted earth tones and sleek lines. The background includes a rotary phone, a simple clock, and a large window showing a clear, serene landscape outside. A clean, organized space, free of distractions, emphasizes the individual’s intense focus. The text ‘Deep Work’ appears in bold, minimalist 1960s typography, evoking a sense of productivity and efficiency from a bygone era.\"\"\",\n",
        "    model=\"black-forest-labs/FLUX.1-schnell\",\n",
        "    size=\"1024x768\",\n",
        "    n=1,\n",
        "    response_format=\"b64_json\"\n",
        ")\n",
        "print(response.data[0].b64_json)"
      ],
      "metadata": {
        "id": "m2gkM8qbJHYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Decode the base64 string\n",
        "image_data = base64.b64decode(response.data[0].b64_json)\n",
        "\n",
        "# Load the image from the decoded bytes\n",
        "image = Image.open(BytesIO(image_data))\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # No axis for better display\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HdXZiBf0JZgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_img_out = \"\"\" Depict an individual at a vintage wooden desk, purposefully ignoring distractions like a rotary phone ringing or an open newspaper. The workspace should have mid-century modern design elements with muted earth tones and sleek furniture, creating a sense of clarity and focus. In the background, show a simple clock ticking away, with an organized, distraction-free environment. Include the text ‘Avoiding Shallow Work’ in bold, minimalist 1960s typography, reinforcing the idea of staying focused on meaningful tasks rather than being pulled into low-value activities. \"\"\""
      ],
      "metadata": {
        "id": "7TjsCWRkMIdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few shot ollama prompt generation..."
      ],
      "metadata": {
        "id": "oeOpxCB-ON1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Ollama chat call for few-shot generation of prompts for the image model...\n",
        "response = ollama.chat(\n",
        "    model='qwen2.5',\n",
        "    options=dict(temperature=0.3),\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You help generating useful image generation prompts given some data input.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"{\n",
        "      \"name\": \"Avoiding Shallow Work\",\n",
        "      \"description\": \"Newport highlights the detrimental effects of shallow work on productivity and creativity. He advises against engaging in low-value, easily distractible tasks that can be done at any time, thus reducing overall focus and efficiency.\",\n",
        "      \"keyPoints\": [\n",
        "        \"Shallow work includes tasks like constant email checking or social media browsing, which are easy to do but often unproductive.\",\n",
        "        \"Avoiding shallow work is essential for maintaining a clear mind and focusing on more important tasks.\",\n",
        "        \"Newport suggests setting boundaries around when you engage in shallow activities.\"\n",
        "      ],\n",
        "      \"actionableStrategy\": {\n",
        "        \"name\": \"The Shallow Work Ban\",\n",
        "        \"steps\": [\n",
        "          \"Identify specific times during the day when you will not check emails or social media.\",\n",
        "          \"Use tools like website blockers to prevent access to distracting websites during your deep work sessions.\",\n",
        "          \"Set a clear intention that these times are for shallow work only, and resist the urge to engage in deeper tasks.\"\n",
        "        ]\n",
        "      },\n",
        "      \"relatedQuote\": {\n",
        "        \"text\": \"\\\"The key is to create a schedule that allows you to focus on cognitively demanding tasks without distraction, which I call 'deep work.'\\\"\",\n",
        "        \"context\": \"Cal Newport emphasizes the importance of avoiding shallow work and focusing on deep work in his conversation.\"\n",
        "      }\n",
        "    }\"\"\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": few_img_out\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"{\n",
        "      \"name\": \"Deep Work\",\n",
        "      \"description\": \"Deep work refers to the ability to focus without distraction on a cognitively demanding task. It's a skill that allows individuals to produce high-quality work and is essential for making progress in various fields.\",\n",
        "      \"keyPoints\": [\n",
        "        \"Deep work is necessary for producing high-quality work and making progress in various fields.\",\n",
        "        \"It requires the ability to focus without distraction on a cognitively demanding task.\",\n",
        "        \"Deep work is not the same as flow, which is a state of performance rather than a state of practice.\"\n",
        "      ],\n",
        "      \"actionableStrategy\": {\n",
        "        \"name\": \"Implementing Deep Work\",\n",
        "        \"steps\": [\n",
        "          \"Schedule deep work sessions in your calendar.\",\n",
        "          \"Eliminate distractions during deep work sessions.\",\n",
        "          \"Use tools like website blockers or phone apps to help you stay focused.\"\n",
        "        ]\n",
        "      }\"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Extract and print the response\n",
        "chat_completion = response['message']['content']"
      ],
      "metadata": {
        "id": "45OTSWD4MN8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion"
      ],
      "metadata": {
        "id": "ic6VcCp1NFUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DnOXnBvNQI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}